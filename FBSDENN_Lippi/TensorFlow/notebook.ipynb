{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfde48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "class FBSNN(ABC):\n",
    "    def __init__(self, \n",
    "    Xi: tf.Tensor, T: float, M: int, N: int,\n",
    "    D: int, layers: List[int]):\n",
    "        self.Xi = Xi #Tensore di punti iniziali\n",
    "        self.T = T #Tempo finale\n",
    "        self.M = M #Numero di traiettorie\n",
    "        self.N = N #Numero di step temporali\n",
    "        self.D = D #Numero di dimensioni\n",
    "        self.layers = layers #Lista di layer --> D+1 --> 1\n",
    "\n",
    "        #Creo la rete neurale\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "\n",
    "        #Definisco la sessione di TensorFlow --> Sessione: Esecuzione del grafo computazionale\n",
    "        # SPIEGAZIONE SESSIONE TENSORFLOW:\n",
    "        # In TensorFlow 1.x, il codice funziona in due fasi:\n",
    "        # 1. Costruzione del grafo (il progetto): definisci le operazioni (es. tf.placeholder, tf.matmul) ma non le esegui.\n",
    "        # 2. Esecuzione (la sessione): è il \"motore\" che preleva il grafo e lo esegue sull'hardware.\n",
    "        #\n",
    "        # Questa riga specifica `self.sess = tf.Session(...)`:\n",
    "        # - Alloca le risorse (memoria, link a GPU/CPU).\n",
    "        # - Crea il ponte tra il Python (astratto) e il C++ (esecutivo).\n",
    "        # - Mantiene lo stato delle variabili (es. i pesi self.weights) tra una `sess.run()` e l'altra.\n",
    "        #\n",
    "        # Parametri usati:\n",
    "        # - allow_soft_placement=True: se un'op non esiste per GPU, usa la CPU senza crashare.\n",
    "        # - log_device_placement=True: stampa nel terminale dove sta girando ogni operazione.\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        \n",
    "        #Definisco i placeholder --> Variabili che verranno riempite durante l'addestramento\n",
    "        # SPIEGAZIONE PLACEHOLDER:\n",
    "        # In TF 1.x, i placeholder sono come \"buchi\" nel grafo. Non contengono dati di per sé,\n",
    "        # ma definiscono la forma (shape) e il tipo (dtype) dei dati che entreranno.\n",
    "        #\n",
    "        # self.learning_rate: Tasso di apprendimento (scalare).\n",
    "        # self.t_tf: Tiene traccia del tempo. Deve essere una matrice (M, N+1, 1).\n",
    "        # self.W_tf: Tiene traccia del moto Browniano (input stocastico).\n",
    "        # self.Xi_tf: Punto di partenza (costante per tutta la simulazione).\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[M, N+1, 1])\n",
    "        self.W_tf = tf.placeholder(tf.float32, shape=[M, N+1, D])\n",
    "        self.Xi_tf = tf.placeholder(tf.float32, shape=[1, D])\n",
    "\n",
    "        #Definisco il grafo computazionale --> Operazioni che verranno eseguite\n",
    "        # SPIEGAZIONE GRAFO COMPUTAZIONALE:\n",
    "        # È come una ricetta. Definisce cosa fare con i dati, ma non li esegue ancora.\n",
    "        # In TF 1.x, tutto è un grafo statico. Una volta definito, non puoi cambiare le operazioni.\n",
    "        #\n",
    "        # self.loss: La funzione di costo (errore) che vogliamo minimizzare.\n",
    "        # self.X_pred, self.Y_pred: Le soluzioni predette dalla rete.\n",
    "        # self.Y0_pred: La soluzione al tempo t=0 (il nostro target da confrontare con Xi).\n",
    "        self.loss, self.X_pred, self.Y_pred, self.Y0_pred = self.loss_function(self.t_tf, self.W_tf, self.Xi_tf)\n",
    "\n",
    "       #Definisco l'ottimizzatore --> Algoritmo che aggiorna i pesi della rete\n",
    "       # SPIEGAZIONE OTTIMIZZATORE:\n",
    "       # È il motore che corregge gli errori. In questo caso, usiamo Adam.\n",
    "       # - learning_rate: Quanto \"grande\" è il passo che fa per correggere gli errori.\n",
    "       # - minimize(self.loss): Dice all'ottimizzatore: \"Trova i pesi che rendono self.loss più piccolo possibile\".\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "       #Inizializzo le variabili --> Assegno valori iniziali ai pesi e ai bias\n",
    "       # SPIEGAZIONE INIZIALIZZAZIONE:\n",
    "       # I pesi non possono partire da 0, altrimenti la rete non impara nulla.\n",
    "       # Usiamo Xavier initialization: distribuisce i pesi in modo che la varianza rimanga costante tra i layer.\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    # SPIEGAZIONE INIZIALIZZAZIONE RETE NEURALE:\n",
    "    #\n",
    "    # SCOPO:\n",
    "    # Costruisce le variabili TensorFlow (Tensori) che rappresentano i parametri\n",
    "    # apprendibili della rete: Pesi (Weights, W) e Bias (b).\n",
    "    #\n",
    "    # FUNZIONAMENTO:\n",
    "    # 1. Input: 'layers' è una lista di interi che definisce l'architettura.\n",
    "    #    Es: [D+1, 256, 256, 1] significa:\n",
    "    #    - Input layer: D+1 neuroni (t + X)\n",
    "    #    - Hidden layers: 2 strati da 256 neuroni\n",
    "    #    - Output layer: 1 neurone (u)\n",
    "    # 2. Iterazione: Per ogni connessione tra due layer adiacenti (l -> l+1):\n",
    "    #    - Crea una matrice di pesi W di dimensione [N_in, N_out] usando Xavier Init.\n",
    "    #    - Crea un vettore di bias b di dimensione [1, N_out] inizializzato a zero.\n",
    "    # 3. Return: Restituisce le liste di tutte le variabili W e b create.\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = [] # Lista per salvare i tensori dei pesi\n",
    "        biases = []  # Lista per salvare i tensori dei bias\n",
    "        num_layers = len(layers) \n",
    "        \n",
    "        # Ciclo su tutti i layer tranne l'ultimo (perché i pesi connettono l -> l+1)\n",
    "        for l in range(0, num_layers-1):\n",
    "            # Inizializzazione Pesi (W):\n",
    "            # Usa Xavier initialization per stabilità numerica.\n",
    "            W = self.xavier_init(size = [layers[l], layers[l+1]])\n",
    "            \n",
    "            # Inizializzazione Bias (b):\n",
    "            # Inizializzati a zero. tf.Variable li rende modificabili dall'ottimizzatore.\n",
    "            b = tf.Variable(tf.zeros([1, layers[l+1]], dtype=tf.float32))\n",
    "            \n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "       \n",
    "    # SPIEGAZIONE XAVIER/GLOROT INITIALIZATION:\n",
    "    # \n",
    "    # LOGICA GENERALE:\n",
    "    # L'inizializzazione Xavier (o Glorot) serve a risolvere il problema della scomparsa o esplosione\n",
    "    # dei gradienti nelle reti neurali profonde. L'obiettivo è mantenere la varianza dei segnali di\n",
    "    # attivazione circa costante attraverso i vari layer della rete durante la propagazione in avanti,\n",
    "    # e mantenere costante la varianza dei gradienti durante la retropropagazione.\n",
    "    # Se i pesi sono troppo piccoli, il segnale svanisce (vanishes); se troppo grandi, esplode.\n",
    "    # Xavier trova un bilanciamento ideale basandosi sulle dimensioni di input e output del layer.\n",
    "    #\n",
    "    # FUNZIONAMENTO SPECIFICO DEL CODICE:\n",
    "    # 1. Input: Riceve 'size', una tupla (in_dim, out_dim) che rappresenta le connessioni del layer\n",
    "    #    (es. neuroni strato precedente -> neuroni strato successivo).\n",
    "    # 2. Calcolo Deviazione Standard (stddev): Applica la formula di Glorot per la distribuzione Normal:\n",
    "    #    stddev = sqrt(2 / (fan_in + fan_out))\n",
    "    #    dove fan_in = in_dim e fan_out = out_dim.\n",
    "    # 3. Generazione Pesi: Crea un tensore di forma [in_dim, out_dim] usando una distribuzione \n",
    "    #    normale troncata ('truncated_normal') con media 0 e la stddev calcolata.\n",
    "    #    La normale troncata scarta valori molto distanti dalla media (oltre 2 deviazioni standard),\n",
    "    #    garantendo stabilità numerica ed evitando pesi outlier troppo grandi.\n",
    "    # 4. Return: Restituisce una tf.Variable inizializzata con questi valori, pronta per essere\n",
    "    #    ottimizzata durante il training.\n",
    "    def xavier_init(self, size: Tuple[int, int]) -> tf.Variable:\n",
    "        in_dim = size[0] #Dimensione input\n",
    "        out_dim = size[1] #Dimensione output\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim)) #Deviazione standard\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "\n",
    "    # SPIEGAZIONE FEED-FORWARD NEURAL NETWORK:\n",
    "    #\n",
    "    # LOGICA GENERALE:\n",
    "    # Questa funzione implementa la propagazione in avanti (forward pass) di una rete neurale\n",
    "    # completamente connessa (Dense Neural Network o MLP).\n",
    "    # L'input X attraversa i vari strati (hidden layers). In ogni strato, avviene una trasformazione\n",
    "    # lineare (prodotto matriciale Input * Pesi + Bias) seguita da una funzione di attivazione non lineare.\n",
    "    # L'ultimo strato solitamente non ha funzione di attivazione (o ne ha una diversa) per permettere\n",
    "    # alla rete di predire valori in un range arbitrario (regressione).\n",
    "    #\n",
    "    # FUNZIONAMENTO SPECIFICO DEL CODICE:\n",
    "    # 1. Input: Riceve i dati di input X e le liste di tensori per pesi (weights) e bias.\n",
    "    # 2. Hidden Layers (Ciclo for):\n",
    "    #    Itera attraverso tutti gli strati tranne l'ultimo.\n",
    "    #    Calcola H = sin(H * W + b).\n",
    "    #    Nota: L'uso di sin() come funzione di attivazione è tipico nelle Physics-Informed Neural Networks (PINNs)\n",
    "    #    o nella risoluzione di equazioni differenziali, poiché il seno è una funzione infinitamente derivabile,\n",
    "    #    al contrario di ReLU che non è derivabile nello zero (o tanh/sigmoid che possono saturare).\n",
    "    # 3. Output Layer:\n",
    "    #    L'ultimo strato applica solo la trasformazione lineare Y = H * W + b.\n",
    "    #    Non c'è funzione di attivazione (attivazione lineare) per non limitare il range dell'output.\n",
    "    # 4. Return: Restituisce il tensore Y che rappresenta la predizione della rete.\n",
    "    def neural_net(self, X: tf.Tensor, weights: List[tf.Variable], biases: List[tf.Variable]) -> tf.Tensor:\n",
    "        num_layers = len(weights) + 1 #Numero di layer: utilizziamo il numero di pesi piu' 1 per contare anche l'input\n",
    "\n",
    "        H = X #Definisco H come X, inizialmente sono uguali ma poi H diventerà il risultato\n",
    "        for l in range(0, num_layers-2): #Ciclo per tutti i layer tranne l'ultimo\n",
    "            W = weights[l] #definisco il peso alla layer l-esima\n",
    "            b = biases[l] #definisco il bias alla layer l-esima\n",
    "            H = tf.sin(tf.add(tf.matmul(H, W), b)) #Applico la funzione di attivazione sin\n",
    "        W = weights[-1] #definisco il peso alla layer finale\n",
    "        b = biases[-1] #definisco il bias alla layer finale\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y #Restituisco Y --> Output della rete\n",
    "        \n",
    "    # SPIEGAZIONE APPROSSIMAZIONE SOLUZIONE E GRADIENTE:\n",
    "    #\n",
    "    # LOGICA GENERALE:\n",
    "    # Questa funzione utilizza la rete neurale per approssimare la soluzione u(t, x) dell'equazione differenziale.\n",
    "    # Inoltre, calcola il gradiente spaziale Du = ∇u(t, x) rispetto alla variabile di stato X.\n",
    "    # In molti problemi FBSDE, il termine di diffusione Z è legato proprio al gradiente della soluzione u (Z = ∇u * sigma).\n",
    "    #\n",
    "    # FUNZIONAMENTO SPECIFICO DEL CODICE:\n",
    "    # 1. Input: Prende in ingresso il tempo t e lo stato X.\n",
    "    # 2. Concatenazione: Unisce t e X in un unico tensore di input [t, X] per la rete neurale.\n",
    "    #    Questo perché la soluzione u dipende sia dal tempo che dallo spazio.\n",
    "    # 3. Forward Pass: Chiama self.neural_net per ottenere il valore u.\n",
    "    # 4. Calcolo Gradiente: Utilizza la differenziazione automatica (tf.gradients) per calcolare\n",
    "    #    le derivate parziali di u rispetto a X.\n",
    "    #    tf.gradients(u, X)[0] restituisce il vettore gradiente ∇_x u.\n",
    "    # 5. Return: Restituisce la coppia (u, Du).\n",
    "    def net_u(self, t: tf.Tensor, X: tf.Tensor) -> tf.Tensor:\n",
    "        u = self.neural_net(tf.concat([t, X], 1), self.weights, self.biases) #Calcolo u\n",
    "        Du = tf.gradients(u, X)[0] #Calcolo Du \n",
    "\n",
    "        return u, Du #Restituisco u e Du\n",
    "    \n",
    "    # SPIEGAZIONE GRADIENTE DELLA CONDIZIONE TERMINALE:\n",
    "    #\n",
    "    # LOGICA GENERALE:\n",
    "    # Nei problemi FBSDE, la condizione finale dell'equazione Backward è spesso data da una funzione \n",
    "    # g(X_T) al tempo terminale T. La condizione per il processo Z al tempo T è data dal gradiente\n",
    "    # di questa funzione g rispetto allo stato X: Z_T = ∇g(X_T) * sigma.\n",
    "    # Questa funzione calcola tale gradiente, che serve come \"target\" o condizione al contorno\n",
    "    # finale durante l'addestramento della rete.\n",
    "    #\n",
    "    # FUNZIONAMENTO SPECIFICO DEL CODICE:\n",
    "    # 1. Input: Riceve lo stato X (tipicamente al tempo finale T).\n",
    "    # 2. Calcolo g(X): Chiama la funzione self.g(X) (definita altrove nel codice, rappresenta la condizione terminale).\n",
    "    # 3. Differenziazione Automatica: Usa tf.gradients per calcolare le derivate parziali di g(X) rispetto a X.\n",
    "    #    Questo evita di dover calcolare a mano il gradiente di g, rendendo il codice flessibile per diverse g.\n",
    "    # 4. Return: Restituisce il gradiente ∇g(X).\n",
    "    def Dg_tf(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        return tf.gradients(self.g_tf(X), X)[0] #Calcolo Dg ovvero il gradiente di g rispetto a X\n",
    "\n",
    "    # SPIEGAZIONE FUNZIONE DI COSTO (SOLUZIONE FBSDE):\n",
    "    #\n",
    "    # LOGICA GENERALE:\n",
    "    # Questa funzione è il cuore dell'algoritmo. Risolve l'equazione differenziale stocastica forward-backward (FBSDE)\n",
    "    # minimizzando la discrepanza tra due modi di calcolare la soluzione Y:\n",
    "    # 1. Tramite la rete neurale: Y = u(t, X)\n",
    "    # 2. Tramite l'evoluzione stocastica (schema di Eulero-Maruyama) dell'equazione Backward.\n",
    "    # L'idea fondamentale è che se la rete u(t, X) è corretta, deve soddisfare l'equazione stocastica passo-passo.\n",
    "    #\n",
    "    # STRUTTURA A DUE PARTI:\n",
    "    # PARTE 1: Evoluzione temporale (Ciclo for)\n",
    "    #    Simula le traiettorie del processo Forward X e Backward Y nel tempo.\n",
    "    #    Ad ogni passo, impone che il valore predetto dalla rete al tempo t+1 (Y1) coincida con quello\n",
    "    #    ottenuto evolvendo l'equazione differenziale dal tempo t (Y1_tilde).\n",
    "    # PARTE 2: Condizione Terminale\n",
    "    #    Al tempo finale T, impone che la soluzione Y coincida con la condizione terminale nota g(X_T).\n",
    "    #\n",
    "    # FUNZIONAMENTO SPECIFICO DEL CODICE (RIGA PER RIGA):\n",
    "    def loss_function(self, t: tf.Tensor, W: tf.Tensor, Xi: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        loss = 0 # Inizializzo loss a 0. Accumulerà gli errori commessi ad ogni passo temporale.\n",
    "        X_list = [] # Lista per salvare la storia delle traiettorie di X (memoria per visualizzazione/analisi).\n",
    "        Y_list = [] # Lista per salvare la storia delle traiettorie di Y.\n",
    "\n",
    "        # PARTE INIZIALE (Tempo t=0)\n",
    "        t0 = t[:,0,:] # Tempo iniziale (per tutte le traiettorie M).\n",
    "        W0 = W[:,0,:] # Valore iniziale del moto Browniano.\n",
    "        X0 = tf.tile(Xi, [self.M, 1]) # Punto di partenza X0 duplicato per le M traiettorie simulate (M x D).\n",
    "        \n",
    "        # Calcolo Y0 e Z0 al tempo 0 usando la rete neurale.\n",
    "        # Questa è la stima iniziale della soluzione che vogliamo ottimizzare.\n",
    "        Y0, Z0 = self.net_u(t0, X0) \n",
    "\n",
    "        X_list.append(X0) # Salvo X0 nello storico.\n",
    "        Y_list.append(Y0) # Salvo Y0 nello storico.\n",
    "\n",
    "        # PARTE 1: CICLO TEMPORALE (Eulero-Maruyama)\n",
    "        for n in range(0, self.N):\n",
    "            # Estrazione valori al passo successivo n+1\n",
    "            t1 = t[:, n+1, :] # Tempo t_{n+1}\n",
    "            W1 = W[:, n+1, :] # Moto Browniano W_{n+1}\n",
    "            \n",
    "            # --- EQUAZIONE FORWARD (X) ---\n",
    "            # X_{n+1} = X_n + mu(X_n)*dt + sigma(X_n)*dW\n",
    "            # Calcolo la nuova posizione X1 usando lo schema di Eulero.\n",
    "            # self.mu_tf(...): termine di drift (velocità deterministica).\n",
    "            # self.sigma_tf(...): termine di diffusione (volatilità).\n",
    "            # (W1 - W0): incremento del moto Browniano dW.\n",
    "            X1 = X0 + self.mu_tf(t0,X0,Y0,Z0)*(t1-t0) + tf.squeeze(tf.matmul(self.sigma_tf(t0,X0,Y0),tf.expand_dims(W1-W0,-1)), axis=[-1])\n",
    "            \n",
    "            # --- EQUAZIONE BACKWARD (Y) - Target \"Fisico\" ---\n",
    "            # Y_{n+1}_tilde = Y_n + phi(...) * dt + Z_n * dW\n",
    "            # Calcolo dove \"dovrebbe\" essere Y al passo successivo secondo l'equazione differenziale.\n",
    "            # Y1_tilde è il nostro target stocastico basato sulla fisica del problema.\n",
    "            Y1_tilde = Y0 + self.phi_tf(t0,X0,Y0,Z0)*(t1-t0) + tf.reduce_sum(Z0*tf.squeeze(tf.matmul(self.sigma_tf(t0,X0,Y0),tf.expand_dims(W1-W0,-1))), axis=1, keepdims = True)\n",
    "            \n",
    "            # --- PREDIZIONE RETE NEURALE ---\n",
    "            # Calcolo la predizione della rete per il nuovo stato X1 al tempo t1.\n",
    "            Y1, Z1 = self.net_u(t1, X1)\n",
    "            \n",
    "            # --- CALCOLO LOSS LOCALE ---\n",
    "            # La rete deve essere coerente con l'equazione: Y predettto (Y1) deve essere uguale a Y calcolato (Y1_tilde).\n",
    "            # Sommo l'errore quadratico medio su tutte le traiettorie.\n",
    "            loss += tf.reduce_sum(tf.square(Y1 - Y1_tilde))\n",
    "\n",
    "            # Aggiornamento variabili per il passo successivo\n",
    "            t0 = t1\n",
    "            W0 = W1\n",
    "            X0 = X1\n",
    "            Y0 = Y1\n",
    "            Z0 = Z1\n",
    "\n",
    "            # Salvataggio nello storico\n",
    "            X_list.append(X0)\n",
    "            Y_list.append(Y0)\n",
    "\n",
    "        # PARTE 2: CONDIZIONE TERMINALE\n",
    "        # Alla fine del tempo T (dopo N passi), la soluzione Y deve rispettare la condizione al contorno g(X_T).\n",
    "        # loss_terminal_Y: Penalizza la differenza tra Y finale predetto e g(X_finale).\n",
    "        loss += tf.reduce_sum(tf.square(Y1 - self.g_tf(X1)))\n",
    "        \n",
    "        # loss_terminal_Z: Penalizza la differenza tra Z finale (gradiente della rete) e il gradiente di g.\n",
    "        # Questo aiuta a stabilizzare l'apprendimento del gradiente Z.\n",
    "        loss += tf.reduce_sum(tf.square(Z1 - self.Dg_tf(X1)))\n",
    "\n",
    "        # Pack dei risultati per il ritorno\n",
    "        X = tf.stack(X_list, axis=1) # Tensore [M, N+1, D]\n",
    "        Y = tf.stack(Y_list, axis=1) # Tensore [M, N+1, 1]\n",
    "\n",
    "        # Ritorna:\n",
    "        # loss: scalare da minimizzare\n",
    "        # X, Y: traiettorie complete (per plot/analisi)\n",
    "        # Y[0,0,0]: il valore iniziale Y0 della prima traiettoria (spesso il valore che cerchiamo, es. prezzo opzione).\n",
    "        return loss, X, Y, Y[0,0,0]\n",
    "\n",
    "\n",
    "    # SPIEGAZIONE GENERAZIONE BATCH (SIMULAZIONE STOCASTICA):\n",
    "    #\n",
    "    # LOGICA GENERALE:\n",
    "    # Questa funzione genera i dati per una iterazione di training (\"minibatch\").\n",
    "    # Nel contesto delle equazioni differenziali stocastiche, i \"dati\" non sono fissi, ma vengono\n",
    "    # generati simulando nuove traiettorie del moto Browniano ogni volta.\n",
    "    # Questo permette alla rete di esplorare l'intero spazio delle possibili evoluzioni del sistema.\n",
    "    #\n",
    "    # FUNZIONAMENTO SPECIFICO DEL CODICE:\n",
    "    # 1. Recupero Parametri: Ottiene T, M (numero traiettorie), N (step temporali), D (dimensioni).\n",
    "    # 2. Inizializzazione: Crea array di zeri per gli incrementi temporali (Dt) e del moto Browniano (DW).\n",
    "    # 3. Calcolo Incrementi:\n",
    "    #    - dt = T / N (passo temporale costante).\n",
    "    #    - DW: Genera incrementi casuali secondo la distribuzione normale N(0, dt).\n",
    "    #      La varianza è dt, quindi la deviazione standard è sqrt(dt).\n",
    "    #      Nota: Il primo punto (indice 0) rimane a 0 perché il processo parte dall'origine relativa.\n",
    "    # 4. Somma Cumulativa (Cumsum):\n",
    "    #    - t: Costruisce la griglia temporale sommando i dt.\n",
    "    #    - W: Costruisce le traiettorie del moto Browniano sommando gli incrementi DW.\n",
    "    # 5. Return: Restituisce i tensori completi t e W di dimensione [M, N+1, ...].\n",
    "    def fetch_minibatch(self):\n",
    "        T = self.T\n",
    "        M = self.M\n",
    "        N = self.N\n",
    "        D = self.D\n",
    "\n",
    "        Dt = np.zeros((M, N+1, 1))\n",
    "        DW = np.zeros((M, N+1, D))\n",
    "        \n",
    "        dt = T/N\n",
    "\n",
    "        Dt[:,1:,:] = dt\n",
    "        DW[:,1:, :] = np.sqrt(dt)*np.random.normal(size=(M,N,D))\n",
    "\n",
    "        t = np.cumsum(Dt, axis=1)\n",
    "        W = np.cumsum(DW, axis=1)\n",
    "\n",
    "        return t, W\n",
    "\n",
    "    # SPIEGAZIONE METODO TRAIN (ADDESTRAMENTO):\n",
    "    #\n",
    "    # CONTESTO GENERALE:\n",
    "    # Questo metodo gestisce il ciclo di addestramento della rete neurale. \n",
    "    # In questo framework FBSDE, l'addestramento non avviene su un dataset fisso (come immagini o testi),\n",
    "    # ma su traiettorie stocastiche generate dinamicamente ad ogni iterazione.\n",
    "    # L'obiettivo è minimizzare la loss function definita precedentemente, che misura quanto bene\n",
    "    # la rete soddisfa l'equazione differenziale stocastica e le condizioni al contorno.\n",
    "    # \n",
    "    # UTILIZZO SPECIFICO:\n",
    "    # Viene chiamato dall'utente dopo aver istanziato la classe. Esegue 'epochs' iterazioni \n",
    "    # di discesa del gradiente (Adam optimizer).\n",
    "    def train(self, epochs: int, learning_rate: float):\n",
    "        # Inizializzo il timer per monitorare quanto tempo impiegano le iterazioni.\n",
    "        # Utile per capire la velocità di addestramento (iterazioni/secondo).\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # CICLO DI TRAINING\n",
    "        # Itera per il numero di epoche specificato.\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # 1. GENERAZIONE DEI DATI (BATCH)\n",
    "            # Ad ogni epoca, generiamo un nuovo set di traiettorie del moto Browniano.\n",
    "            # self.fetch_minibatch() restituisce:\n",
    "            # - t_batch: griglia temporale [M, N+1, 1]\n",
    "            # - W_batch: traiettorie del moto Browniano [M, N+1, D]\n",
    "            # Questo è cruciale: la rete non memorizza dati, ma impara la dinamica dell'equazione\n",
    "            # vedendo sempre nuove realizzazioni del processo stocastico.\n",
    "            t_batch, W_batch = self.fetch_minibatch()\n",
    "            \n",
    "            # 2. DIZIONARIO DI ALIMENTAZIONE (FEED DICT)\n",
    "            # Mappiamo i dati Python (numpy array) ai Placeholder di TensorFlow definiti in __init__.\n",
    "            # - self.Xi_tf: punto iniziale (fisso).\n",
    "            # - self.t_tf: i tempi generati.\n",
    "            # - self.W_tf: i moti Browniani generati.\n",
    "            # - self.learning_rate: il passo di apprendimento passato come argomento.\n",
    "            tf_dict = {self.Xi_tf: self.Xi, self.t_tf: t_batch, self.W_tf: W_batch, self.learning_rate: learning_rate}\n",
    "            \n",
    "            # 3. ESECUZIONE DELLO STEP DI OTTIMIZZAZIONE\n",
    "            # Questa è l'istruzione chiave. sess.run esegue il grafo computazionale.\n",
    "            # Chiediamo di eseguire 'self.train_op': questa operazione calcola i gradienti della loss\n",
    "            # rispetto ai pesi e li aggiorna (minimizza l'errore).\n",
    "            # Non ci serve il valore di ritorno qui, ci interessa l'effetto collaterale (aggiornamento pesi).\n",
    "            self.sess.run(self.train_op, tf_dict)\n",
    "\n",
    "            # 4. MONITORAGGIO E LOGGING (Ogni 100 epoche)\n",
    "            # Per non rallentare troppo il processo, calcoliamo e stampiamo le metriche solo ogni 100 passi.\n",
    "            # (Nota: nel codice originale era 10, ma spesso si aumenta per velocità).\n",
    "            if epoch % 10 == 0:\n",
    "                # Calcoliamo il tempo trascorso per queste 10 iterazioni.\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                # Eseguiamo nuovamente sess.run, ma questa volta chiediamo valori specifici per monitorare:\n",
    "                # - self.loss: il valore attuale dell'errore (deve scendere).\n",
    "                # - self.Y0_pred: la stima del valore iniziale (es. prezzo opzione). Deve convergere.\n",
    "                # - self.learning_rate: per conferma.\n",
    "                # Nota: passiamo lo stesso tf_dict, quindi ricalcola su QUESTO batch corrente.\n",
    "                loss_value, Y0_value, learning_rate_value = self.sess.run([self.loss, self.Y0_pred, self.learning_rate], tf_dict)\n",
    "                \n",
    "                # Stampiamo i risultati formattati:\n",
    "                # - %.3e: notazione scientifica con 3 decimali (utile per loss molto piccole).\n",
    "                # - %.3f: float con 3 decimali (utile per Y0).\n",
    "                print(\"Epoch: %d, Loss: %.3e, Y0: %.3f, Learning Rate: %.3e, Time: %.2fs\" % (epoch, loss_value, Y0_value, learning_rate_value, elapsed))\n",
    "                \n",
    "                # Resettiamo il timer per misurare il prossimo blocco di iterazioni.\n",
    "                start_time = time.time()\n",
    "    \n",
    "    # SPIEGAZIONE METODO PREDICT (INFERENZA/TEST):\n",
    "    #\n",
    "    # CONTESTO GENERALE:\n",
    "    # Questo metodo viene utilizzato DOPO l'addestramento per valutare il modello su nuovi dati \n",
    "    # o per esaminare le traiettorie predette. A differenza di 'train', qui non avviene nessuna\n",
    "    # ottimizzazione dei pesi (i pesi sono congelati).\n",
    "    # Serve a rispondere alla domanda: \"Data una certa evoluzione del moto Browniano W e un tempo t,\n",
    "    # quali sono le traiettorie X (Forward) e Y (Backward) che la rete prevede?\"\n",
    "    #\n",
    "    # UTILIZZO SPECIFICO:\n",
    "    # Riceve in input dei dati di test (spesso generati allo stesso modo di fetch_minibatch, \n",
    "    # ma tenuti separati come test set) e restituisce le matrici delle soluzioni.\n",
    "    def predict(self, Xi_star: np.ndarray, t_star: np.ndarray, W_star: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "        # 1. PREPARAZIONE DEI DATI\n",
    "        # Creiamo il dizionario per alimentare i placeholder.\n",
    "        # Notiamo che NON passiamo 'learning_rate' perche' non stiamo addestrando (non usiamo train_op).\n",
    "        # Xi_star: punto di partenza.\n",
    "        # t_star: griglia temporale di test.\n",
    "        # W_star: realizzazioni del moto Browniano di test.\n",
    "        tf_dict = {self.Xi_tf: Xi_star, self.t_tf: t_star, self.W_tf: W_star}\n",
    "\n",
    "        # 2. ESECUZIONE DELLA PREDIZIONE\n",
    "        # Eseguiamo la sessione chiedendo in output:\n",
    "        # - self.X_pred: la traiettoria del processo Forward.\n",
    "        # - self.Y_pred: la traiettoria del processo Backward (soluzione dell'EQ).\n",
    "        # Questi nodi del grafo usano i pesi ormai addestrati per calcolare l'output.\n",
    "        #\n",
    "        # Nota: Potremmo fare una sola chiamata sess.run([self.X_pred, self.Y_pred], tf_dict)\n",
    "        # per efficienza, ma separarli funziona ugualmente.\n",
    "        X_star = self.sess.run(self.X_pred, tf_dict)\n",
    "        Y_star = self.sess.run(self.Y_pred, tf_dict)\n",
    "\n",
    "        # 3. RITORNO DEI RISULTATI\n",
    "        # Restituisce le matrici numpy con i valori predetti.\n",
    "        # Shape tipica: [M, N+1, D] o [M, N+1, 1]\n",
    "        return X_star, Y_star\n",
    "\n",
    "    # METODI ASTRATTI PER LA DEFINIZIONE DEL PROBLEMA:\n",
    "    # Questi metodi devono essere implementati nelle sottoclassi per definire \n",
    "    # la specifica equazione differenziale (PDE) che si vuole risolvere.\n",
    "    \n",
    "    # SPIEGAZIONE PHI (GENERATORE BACKWARD):\n",
    "    # Rappresenta il termine di \"drift\" dell'equazione Backward, o il termine non lineare della PDE.\n",
    "    # Nell'equazione: dY_t = -phi(t, X_t, Y_t, Z_t)dt + Z_t dW_t\n",
    "    # Corrisponde alla funzione f(t, x, y, z) nei paper accademici.\n",
    "    # Input: Tempo t, Stato X, Valore Y, Gradiente Z.\n",
    "    @abstractmethod\n",
    "    def phi_tf(self, t, X, Y, Z):\n",
    "        pass\n",
    "\n",
    "    # SPIEGAZIONE G (CONDIZIONE TERMINALE):\n",
    "    # Rappresenta la condizione al contorno finale al tempo T.\n",
    "    # Y_T = g(X_T).\n",
    "    # Esempio: Nel pricing di opzioni, questa è la funzione di Payoff (es. max(X-K, 0)).\n",
    "    @abstractmethod\n",
    "    def g_tf(self, X):\n",
    "        pass\n",
    "\n",
    "    # SPIEGAZIONE MU (DRIFT FORWARD):\n",
    "    # Rappresenta la parte deterministica dell'evoluzione dello stato X.\n",
    "    # Nell'equazione: dX_t = mu(t, X_t, Y_t, Z_t)dt + sigma(...)dW_t\n",
    "    # Input: Tempo t, Stato X, e talvolta anche Y, Z (nei problemi fully coupled).\n",
    "    # Default: Ritorna 0 (nessun drift).\n",
    "    @abstractmethod\n",
    "    def mu_tf(self, t, X, Y, Z):\n",
    "        M = self.M\n",
    "        D = self.D\n",
    "        return np.zeros([M, D])\n",
    "\n",
    "    # SPIEGAZIONE SIGMA (DIFFUSIONE FORWARD):\n",
    "    # Rappresenta la volatilità o la parte stocastica dell'evoluzione dello stato X.\n",
    "    # Matrice DxD che moltiplica il moto Browniano dW.\n",
    "    # Default: Ritorna matrice identità (moto Browniano standard non scalato).\n",
    "    @abstractmethod\n",
    "    def sigma_tf(self, t, X, Y):\n",
    "        M = self.M\n",
    "        D = self.D\n",
    "        return tf.matrix_diag(tf.ones([M, D]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0d9791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "\n",
      "Epoch: 0, Loss: 5.090e+05, Y0: 3.615, Learning Rate: 1.000e-03, Time: 5.38s\n",
      "Epoch: 10, Loss: 3.441e+05, Y0: 17.906, Learning Rate: 1.000e-03, Time: 0.90s\n",
      "Epoch: 20, Loss: 3.173e+05, Y0: 20.711, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 30, Loss: 2.869e+05, Y0: 23.426, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 40, Loss: 2.605e+05, Y0: 26.064, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 50, Loss: 2.297e+05, Y0: 28.648, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 60, Loss: 2.170e+05, Y0: 31.107, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 70, Loss: 1.907e+05, Y0: 33.280, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 80, Loss: 1.758e+05, Y0: 35.772, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 90, Loss: 1.477e+05, Y0: 38.000, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 100, Loss: 1.460e+05, Y0: 40.056, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 110, Loss: 1.260e+05, Y0: 42.099, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 120, Loss: 1.218e+05, Y0: 43.924, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 130, Loss: 1.020e+05, Y0: 46.004, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 140, Loss: 9.984e+04, Y0: 47.331, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 150, Loss: 8.491e+04, Y0: 49.070, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 160, Loss: 7.365e+04, Y0: 50.811, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 170, Loss: 7.565e+04, Y0: 52.902, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 180, Loss: 7.210e+04, Y0: 54.206, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 190, Loss: 5.275e+04, Y0: 55.768, Learning Rate: 1.000e-03, Time: 0.67s\n",
      "Epoch: 200, Loss: 5.399e+04, Y0: 57.251, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 210, Loss: 4.697e+04, Y0: 58.697, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 220, Loss: 4.810e+04, Y0: 59.119, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 230, Loss: 4.264e+04, Y0: 60.314, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 240, Loss: 3.999e+04, Y0: 61.169, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 250, Loss: 3.904e+04, Y0: 63.237, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 260, Loss: 3.132e+04, Y0: 62.191, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 270, Loss: 2.865e+04, Y0: 64.988, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 280, Loss: 2.499e+04, Y0: 64.451, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 290, Loss: 2.400e+04, Y0: 66.248, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 300, Loss: 2.238e+04, Y0: 68.106, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 310, Loss: 2.172e+04, Y0: 64.929, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 320, Loss: 2.293e+04, Y0: 68.827, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 330, Loss: 1.942e+04, Y0: 68.768, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 340, Loss: 1.707e+04, Y0: 70.530, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 350, Loss: 1.423e+04, Y0: 70.346, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 360, Loss: 1.507e+04, Y0: 69.283, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 370, Loss: 1.160e+04, Y0: 70.031, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 380, Loss: 1.500e+04, Y0: 70.885, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 390, Loss: 1.441e+04, Y0: 73.239, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 400, Loss: 1.155e+04, Y0: 72.675, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 410, Loss: 1.051e+04, Y0: 72.952, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 420, Loss: 1.034e+04, Y0: 70.699, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 430, Loss: 1.122e+04, Y0: 70.640, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 440, Loss: 9.354e+03, Y0: 72.408, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 450, Loss: 8.110e+03, Y0: 72.622, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 460, Loss: 1.421e+04, Y0: 67.167, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 470, Loss: 9.881e+03, Y0: 70.343, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 480, Loss: 1.008e+04, Y0: 75.750, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 490, Loss: 8.821e+03, Y0: 73.246, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 500, Loss: 8.789e+03, Y0: 70.204, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 510, Loss: 7.226e+03, Y0: 72.994, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 520, Loss: 6.604e+03, Y0: 73.236, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 530, Loss: 9.163e+03, Y0: 70.040, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 540, Loss: 8.718e+03, Y0: 71.311, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 550, Loss: 5.721e+03, Y0: 75.949, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 560, Loss: 6.644e+03, Y0: 75.709, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 570, Loss: 5.929e+03, Y0: 76.459, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 580, Loss: 7.476e+03, Y0: 76.156, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 590, Loss: 5.730e+03, Y0: 74.025, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 600, Loss: 5.549e+03, Y0: 72.178, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 610, Loss: 5.042e+03, Y0: 73.260, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 620, Loss: 6.782e+03, Y0: 71.159, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 630, Loss: 4.522e+03, Y0: 72.530, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 640, Loss: 5.176e+03, Y0: 75.917, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 650, Loss: 4.910e+03, Y0: 75.355, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 660, Loss: 5.924e+03, Y0: 75.019, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 670, Loss: 5.879e+03, Y0: 76.258, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 680, Loss: 4.436e+03, Y0: 74.363, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 690, Loss: 5.264e+03, Y0: 72.144, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 700, Loss: 4.589e+03, Y0: 75.005, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 710, Loss: 4.344e+03, Y0: 74.770, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 720, Loss: 3.674e+03, Y0: 76.033, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 730, Loss: 4.162e+03, Y0: 72.614, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 740, Loss: 4.730e+03, Y0: 76.127, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 750, Loss: 3.990e+03, Y0: 75.824, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 760, Loss: 4.174e+03, Y0: 73.260, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 770, Loss: 3.929e+03, Y0: 73.355, Learning Rate: 1.000e-03, Time: 0.69s\n",
      "Epoch: 780, Loss: 3.196e+03, Y0: 75.858, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 790, Loss: 2.967e+03, Y0: 75.410, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 800, Loss: 4.126e+03, Y0: 72.662, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 810, Loss: 4.515e+03, Y0: 74.331, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 820, Loss: 3.298e+03, Y0: 73.517, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 830, Loss: 3.401e+03, Y0: 74.111, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 840, Loss: 3.338e+03, Y0: 74.056, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 850, Loss: 3.584e+03, Y0: 76.159, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 860, Loss: 2.944e+03, Y0: 75.757, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 870, Loss: 3.429e+03, Y0: 74.453, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 880, Loss: 2.679e+03, Y0: 74.368, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 890, Loss: 4.771e+03, Y0: 71.754, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 900, Loss: 2.862e+03, Y0: 72.689, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 910, Loss: 3.641e+03, Y0: 72.701, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 920, Loss: 6.290e+03, Y0: 70.141, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 930, Loss: 4.378e+03, Y0: 78.740, Learning Rate: 1.000e-03, Time: 0.67s\n",
      "Epoch: 940, Loss: 3.275e+03, Y0: 73.805, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 950, Loss: 4.206e+03, Y0: 70.017, Learning Rate: 1.000e-03, Time: 0.90s\n",
      "Epoch: 960, Loss: 2.512e+03, Y0: 74.206, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 970, Loss: 2.875e+03, Y0: 74.672, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 980, Loss: 2.094e+03, Y0: 74.962, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 990, Loss: 2.662e+03, Y0: 73.881, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1000, Loss: 1.650e+03, Y0: 75.448, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1010, Loss: 2.778e+03, Y0: 72.224, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1020, Loss: 3.211e+03, Y0: 77.954, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1030, Loss: 3.393e+03, Y0: 75.531, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1040, Loss: 2.131e+03, Y0: 74.249, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1050, Loss: 2.207e+03, Y0: 73.087, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1060, Loss: 1.916e+03, Y0: 74.011, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1070, Loss: 1.854e+03, Y0: 76.083, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1080, Loss: 2.104e+03, Y0: 73.484, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1090, Loss: 1.879e+03, Y0: 74.021, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1100, Loss: 1.833e+03, Y0: 76.758, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1110, Loss: 2.136e+03, Y0: 73.985, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1120, Loss: 1.532e+03, Y0: 75.691, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 1130, Loss: 1.634e+03, Y0: 73.914, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 1140, Loss: 2.078e+03, Y0: 73.818, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 1150, Loss: 1.337e+03, Y0: 75.995, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1160, Loss: 1.343e+03, Y0: 74.618, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1170, Loss: 1.128e+03, Y0: 75.038, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1180, Loss: 1.060e+03, Y0: 76.118, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1190, Loss: 2.003e+03, Y0: 78.128, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1200, Loss: 1.201e+03, Y0: 75.911, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1210, Loss: 1.268e+03, Y0: 76.056, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1220, Loss: 1.681e+03, Y0: 74.261, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1230, Loss: 1.295e+03, Y0: 76.338, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1240, Loss: 1.060e+03, Y0: 76.272, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1250, Loss: 1.062e+03, Y0: 75.137, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1260, Loss: 1.488e+03, Y0: 74.898, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1270, Loss: 1.321e+03, Y0: 75.750, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1280, Loss: 1.411e+03, Y0: 73.674, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1290, Loss: 1.785e+03, Y0: 72.489, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1300, Loss: 3.002e+03, Y0: 80.312, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1310, Loss: 1.469e+03, Y0: 74.532, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 1320, Loss: 1.285e+03, Y0: 73.455, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 1330, Loss: 1.630e+03, Y0: 75.621, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 1340, Loss: 9.968e+02, Y0: 75.063, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1350, Loss: 9.132e+02, Y0: 75.656, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1360, Loss: 1.042e+03, Y0: 74.725, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1370, Loss: 1.192e+03, Y0: 75.469, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1380, Loss: 1.006e+03, Y0: 75.878, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1390, Loss: 1.622e+03, Y0: 78.735, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1400, Loss: 1.482e+03, Y0: 75.905, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1410, Loss: 1.790e+03, Y0: 72.657, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1420, Loss: 1.557e+03, Y0: 76.337, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 1430, Loss: 8.752e+02, Y0: 75.270, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1440, Loss: 1.491e+03, Y0: 75.003, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1450, Loss: 2.010e+03, Y0: 75.117, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1460, Loss: 1.272e+03, Y0: 78.167, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1470, Loss: 9.365e+02, Y0: 76.246, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1480, Loss: 1.023e+03, Y0: 74.521, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1490, Loss: 9.412e+02, Y0: 75.700, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 1500, Loss: 2.438e+03, Y0: 74.330, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 1510, Loss: 1.056e+03, Y0: 77.405, Learning Rate: 1.000e-03, Time: 0.79s\n",
      "Epoch: 1520, Loss: 1.125e+03, Y0: 74.431, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1530, Loss: 1.420e+03, Y0: 75.130, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1540, Loss: 1.255e+03, Y0: 74.953, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1550, Loss: 7.949e+02, Y0: 75.764, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1560, Loss: 6.913e+02, Y0: 76.188, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1570, Loss: 8.145e+02, Y0: 77.451, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1580, Loss: 1.035e+03, Y0: 74.821, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1590, Loss: 8.649e+02, Y0: 77.918, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1600, Loss: 1.636e+03, Y0: 72.182, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1610, Loss: 8.730e+02, Y0: 75.792, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1620, Loss: 1.010e+03, Y0: 76.015, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1630, Loss: 9.438e+02, Y0: 74.616, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1640, Loss: 8.849e+02, Y0: 75.515, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1650, Loss: 1.236e+03, Y0: 78.400, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1660, Loss: 8.821e+02, Y0: 75.001, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1670, Loss: 9.131e+02, Y0: 77.362, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1680, Loss: 6.809e+02, Y0: 75.363, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 1690, Loss: 9.023e+02, Y0: 75.168, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 1700, Loss: 1.107e+03, Y0: 78.489, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 1710, Loss: 1.005e+03, Y0: 73.699, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 1720, Loss: 8.727e+02, Y0: 75.585, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1730, Loss: 6.185e+02, Y0: 75.533, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1740, Loss: 5.517e+02, Y0: 76.665, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1750, Loss: 8.102e+02, Y0: 77.136, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1760, Loss: 6.854e+02, Y0: 76.946, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1770, Loss: 6.868e+02, Y0: 77.208, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1780, Loss: 6.984e+02, Y0: 76.745, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1790, Loss: 8.977e+02, Y0: 77.331, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1800, Loss: 7.019e+02, Y0: 75.878, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1810, Loss: 6.343e+02, Y0: 76.527, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 1820, Loss: 8.103e+02, Y0: 77.930, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1830, Loss: 6.308e+02, Y0: 75.665, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1840, Loss: 6.861e+02, Y0: 75.137, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1850, Loss: 7.186e+02, Y0: 76.865, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1860, Loss: 1.132e+03, Y0: 79.099, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 1870, Loss: 7.692e+02, Y0: 75.208, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 1880, Loss: 9.509e+02, Y0: 74.491, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 1890, Loss: 6.449e+02, Y0: 76.706, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 1900, Loss: 5.591e+02, Y0: 75.415, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1910, Loss: 7.256e+02, Y0: 76.459, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1920, Loss: 5.303e+02, Y0: 75.649, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1930, Loss: 6.472e+02, Y0: 76.029, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 1940, Loss: 7.304e+02, Y0: 77.803, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1950, Loss: 1.113e+03, Y0: 77.449, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 1960, Loss: 9.863e+02, Y0: 74.172, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 1970, Loss: 5.106e+02, Y0: 76.835, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 1980, Loss: 7.462e+02, Y0: 77.728, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 1990, Loss: 4.935e+02, Y0: 75.170, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2000, Loss: 6.029e+02, Y0: 77.106, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2010, Loss: 9.315e+02, Y0: 75.880, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2020, Loss: 6.170e+02, Y0: 74.953, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2030, Loss: 4.129e+02, Y0: 76.569, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2040, Loss: 4.013e+02, Y0: 76.168, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2050, Loss: 5.661e+02, Y0: 75.293, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 2060, Loss: 4.286e+02, Y0: 75.477, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 2070, Loss: 8.415e+02, Y0: 74.956, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 2080, Loss: 5.645e+02, Y0: 74.536, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2090, Loss: 1.990e+03, Y0: 73.883, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2100, Loss: 1.097e+03, Y0: 73.145, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2110, Loss: 1.085e+03, Y0: 75.090, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 2120, Loss: 9.753e+02, Y0: 75.320, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2130, Loss: 5.711e+02, Y0: 77.048, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2140, Loss: 9.101e+02, Y0: 73.602, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2150, Loss: 7.775e+02, Y0: 77.590, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2160, Loss: 6.952e+02, Y0: 76.812, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 2170, Loss: 5.600e+02, Y0: 76.942, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2180, Loss: 5.013e+02, Y0: 75.134, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 2190, Loss: 5.478e+02, Y0: 76.412, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2200, Loss: 4.440e+02, Y0: 76.552, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2210, Loss: 6.117e+02, Y0: 75.056, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2220, Loss: 8.654e+02, Y0: 77.878, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2230, Loss: 3.983e+02, Y0: 75.654, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 2240, Loss: 5.910e+02, Y0: 74.596, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 2250, Loss: 4.705e+02, Y0: 76.312, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 2260, Loss: 5.633e+02, Y0: 77.542, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2270, Loss: 4.880e+02, Y0: 76.572, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2280, Loss: 6.570e+02, Y0: 74.341, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2290, Loss: 4.240e+02, Y0: 77.185, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2300, Loss: 3.204e+02, Y0: 75.637, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2310, Loss: 3.525e+02, Y0: 75.683, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2320, Loss: 2.989e+02, Y0: 75.718, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 2330, Loss: 5.068e+02, Y0: 77.470, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2340, Loss: 3.535e+02, Y0: 75.703, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2350, Loss: 4.408e+02, Y0: 75.290, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2360, Loss: 3.215e+02, Y0: 76.380, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2370, Loss: 3.539e+02, Y0: 76.301, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 2380, Loss: 4.817e+02, Y0: 75.459, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2390, Loss: 4.441e+02, Y0: 76.125, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2400, Loss: 3.259e+02, Y0: 75.811, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2410, Loss: 3.337e+02, Y0: 76.397, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 2420, Loss: 3.612e+02, Y0: 75.470, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 2430, Loss: 4.232e+02, Y0: 76.373, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 2440, Loss: 5.155e+02, Y0: 77.989, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 2450, Loss: 7.322e+02, Y0: 77.220, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2460, Loss: 3.926e+02, Y0: 76.748, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2470, Loss: 2.188e+03, Y0: 79.801, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2480, Loss: 6.989e+02, Y0: 74.831, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2490, Loss: 5.052e+02, Y0: 75.039, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2500, Loss: 3.540e+02, Y0: 75.953, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2510, Loss: 4.071e+02, Y0: 76.650, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2520, Loss: 3.423e+02, Y0: 76.359, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2530, Loss: 3.042e+02, Y0: 76.122, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2540, Loss: 4.698e+02, Y0: 77.706, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2550, Loss: 3.345e+02, Y0: 75.513, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2560, Loss: 3.686e+02, Y0: 75.125, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2570, Loss: 1.467e+03, Y0: 74.606, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2580, Loss: 3.386e+02, Y0: 75.756, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2590, Loss: 3.078e+02, Y0: 76.583, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2600, Loss: 1.067e+03, Y0: 78.972, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2610, Loss: 3.603e+02, Y0: 77.246, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 2620, Loss: 8.497e+02, Y0: 78.336, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 2630, Loss: 4.884e+02, Y0: 76.843, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 2640, Loss: 6.062e+02, Y0: 74.434, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2650, Loss: 1.417e+03, Y0: 74.153, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 2660, Loss: 3.777e+02, Y0: 77.134, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 2670, Loss: 3.504e+02, Y0: 76.400, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2680, Loss: 2.809e+02, Y0: 75.969, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2690, Loss: 1.049e+03, Y0: 78.313, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2700, Loss: 4.394e+02, Y0: 75.250, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2710, Loss: 2.574e+02, Y0: 76.508, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2720, Loss: 5.117e+02, Y0: 77.513, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 2730, Loss: 5.949e+02, Y0: 74.694, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2740, Loss: 6.205e+02, Y0: 74.374, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2750, Loss: 2.935e+02, Y0: 76.567, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2760, Loss: 3.663e+02, Y0: 77.275, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2770, Loss: 5.911e+02, Y0: 75.299, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2780, Loss: 5.213e+02, Y0: 74.550, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2790, Loss: 3.585e+02, Y0: 77.162, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 2800, Loss: 2.654e+02, Y0: 76.254, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 2810, Loss: 4.087e+02, Y0: 75.606, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 2820, Loss: 3.129e+02, Y0: 75.872, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2830, Loss: 3.159e+02, Y0: 77.104, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2840, Loss: 2.452e+02, Y0: 76.765, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 2850, Loss: 2.475e+02, Y0: 76.989, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 2860, Loss: 2.302e+02, Y0: 76.527, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2870, Loss: 2.439e+02, Y0: 76.567, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2880, Loss: 2.018e+02, Y0: 75.803, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2890, Loss: 1.823e+02, Y0: 76.332, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2900, Loss: 3.534e+02, Y0: 75.536, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2910, Loss: 2.368e+02, Y0: 75.743, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2920, Loss: 6.858e+02, Y0: 74.179, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2930, Loss: 7.760e+02, Y0: 75.071, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 2940, Loss: 4.765e+02, Y0: 76.433, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2950, Loss: 7.860e+02, Y0: 78.506, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2960, Loss: 1.008e+03, Y0: 78.995, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 2970, Loss: 6.624e+02, Y0: 77.034, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 2980, Loss: 7.012e+02, Y0: 74.248, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 2990, Loss: 4.448e+02, Y0: 77.312, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 3000, Loss: 2.456e+02, Y0: 76.117, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 3010, Loss: 2.945e+02, Y0: 75.744, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3020, Loss: 2.753e+02, Y0: 75.925, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3030, Loss: 2.527e+02, Y0: 76.653, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3040, Loss: 2.501e+02, Y0: 76.232, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3050, Loss: 2.172e+02, Y0: 75.870, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3060, Loss: 3.484e+02, Y0: 77.473, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3070, Loss: 5.579e+02, Y0: 78.168, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3080, Loss: 1.560e+03, Y0: 73.407, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3090, Loss: 4.869e+02, Y0: 76.772, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3100, Loss: 4.844e+02, Y0: 77.865, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3110, Loss: 3.368e+02, Y0: 75.382, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3120, Loss: 3.194e+02, Y0: 76.395, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3130, Loss: 1.801e+02, Y0: 76.165, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3140, Loss: 1.944e+02, Y0: 76.548, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3150, Loss: 6.063e+02, Y0: 75.867, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3160, Loss: 4.595e+02, Y0: 76.897, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3170, Loss: 5.316e+02, Y0: 77.256, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 3180, Loss: 7.446e+02, Y0: 76.341, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 3190, Loss: 2.213e+02, Y0: 76.208, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3200, Loss: 7.683e+02, Y0: 74.090, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 3210, Loss: 2.224e+02, Y0: 76.449, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3220, Loss: 5.555e+02, Y0: 78.093, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3230, Loss: 3.819e+02, Y0: 77.563, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3240, Loss: 2.643e+02, Y0: 75.608, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3250, Loss: 2.363e+02, Y0: 76.265, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3260, Loss: 1.973e+02, Y0: 76.171, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 3270, Loss: 3.302e+02, Y0: 75.377, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3280, Loss: 2.335e+02, Y0: 75.650, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3290, Loss: 2.456e+02, Y0: 76.408, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3300, Loss: 1.026e+03, Y0: 78.749, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3310, Loss: 3.119e+02, Y0: 78.090, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3320, Loss: 2.343e+02, Y0: 77.045, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 3330, Loss: 2.655e+02, Y0: 77.131, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3340, Loss: 2.238e+02, Y0: 75.137, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3350, Loss: 2.409e+02, Y0: 75.416, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 3360, Loss: 1.637e+02, Y0: 76.234, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 3370, Loss: 1.886e+02, Y0: 75.966, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 3380, Loss: 1.614e+02, Y0: 76.434, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3390, Loss: 1.505e+02, Y0: 76.519, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 3400, Loss: 2.830e+02, Y0: 77.484, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3410, Loss: 1.624e+02, Y0: 76.686, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3420, Loss: 6.638e+02, Y0: 75.183, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3430, Loss: 4.282e+02, Y0: 74.729, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3440, Loss: 4.738e+02, Y0: 74.371, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3450, Loss: 2.030e+02, Y0: 76.494, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3460, Loss: 4.726e+02, Y0: 78.004, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3470, Loss: 3.195e+02, Y0: 76.895, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3480, Loss: 1.909e+02, Y0: 76.185, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3490, Loss: 2.230e+02, Y0: 76.633, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3500, Loss: 1.671e+02, Y0: 76.731, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3510, Loss: 9.739e+02, Y0: 79.358, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3520, Loss: 6.368e+02, Y0: 77.785, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 3530, Loss: 1.023e+03, Y0: 74.382, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3540, Loss: 1.295e+03, Y0: 73.757, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 3550, Loss: 5.272e+02, Y0: 77.865, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 3560, Loss: 3.412e+02, Y0: 75.052, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 3570, Loss: 1.984e+02, Y0: 76.518, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 3580, Loss: 1.591e+02, Y0: 76.302, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3590, Loss: 1.518e+02, Y0: 76.011, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3600, Loss: 1.240e+02, Y0: 76.399, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3610, Loss: 1.330e+02, Y0: 76.402, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3620, Loss: 3.164e+02, Y0: 78.093, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3630, Loss: 3.137e+02, Y0: 76.443, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3640, Loss: 2.311e+02, Y0: 76.817, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3650, Loss: 1.847e+02, Y0: 76.161, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3660, Loss: 2.423e+02, Y0: 76.415, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3670, Loss: 2.099e+02, Y0: 76.829, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3680, Loss: 1.823e+02, Y0: 76.690, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3690, Loss: 1.458e+02, Y0: 76.144, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3700, Loss: 1.659e+02, Y0: 75.933, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3710, Loss: 2.976e+02, Y0: 77.631, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3720, Loss: 2.111e+02, Y0: 77.119, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3730, Loss: 3.858e+02, Y0: 77.976, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 3740, Loss: 2.610e+02, Y0: 76.985, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 3750, Loss: 1.596e+02, Y0: 75.919, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 3760, Loss: 2.162e+02, Y0: 75.909, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3770, Loss: 3.671e+02, Y0: 75.259, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3780, Loss: 2.144e+02, Y0: 75.848, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3790, Loss: 1.647e+02, Y0: 76.671, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 3800, Loss: 1.561e+02, Y0: 76.670, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3810, Loss: 1.514e+02, Y0: 76.681, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 3820, Loss: 2.466e+02, Y0: 77.150, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3830, Loss: 2.288e+02, Y0: 77.434, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3840, Loss: 1.821e+02, Y0: 76.754, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 3850, Loss: 2.040e+02, Y0: 76.975, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3860, Loss: 1.807e+02, Y0: 76.231, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 3870, Loss: 3.675e+02, Y0: 78.259, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3880, Loss: 2.109e+02, Y0: 76.370, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3890, Loss: 2.015e+02, Y0: 77.113, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3900, Loss: 2.106e+02, Y0: 77.220, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 3910, Loss: 1.507e+02, Y0: 76.638, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 3920, Loss: 1.456e+02, Y0: 76.175, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 3930, Loss: 1.341e+02, Y0: 76.132, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 3940, Loss: 3.275e+02, Y0: 75.324, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3950, Loss: 5.374e+02, Y0: 74.365, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 3960, Loss: 2.729e+02, Y0: 75.204, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 3970, Loss: 1.472e+02, Y0: 76.790, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 3980, Loss: 3.457e+02, Y0: 75.413, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 3990, Loss: 1.535e+02, Y0: 76.247, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4000, Loss: 2.231e+02, Y0: 77.242, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4010, Loss: 2.419e+02, Y0: 77.301, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4020, Loss: 1.374e+02, Y0: 76.456, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4030, Loss: 1.825e+02, Y0: 76.174, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4040, Loss: 1.580e+02, Y0: 76.428, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4050, Loss: 2.197e+02, Y0: 75.633, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4060, Loss: 1.889e+02, Y0: 75.697, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4070, Loss: 5.543e+02, Y0: 75.245, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4080, Loss: 2.204e+02, Y0: 75.923, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4090, Loss: 1.884e+02, Y0: 76.004, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4100, Loss: 1.415e+02, Y0: 76.247, Learning Rate: 1.000e-03, Time: 0.79s\n",
      "Epoch: 4110, Loss: 2.333e+02, Y0: 77.785, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 4120, Loss: 1.383e+02, Y0: 76.516, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 4130, Loss: 1.439e+02, Y0: 76.269, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4140, Loss: 1.438e+02, Y0: 76.339, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4150, Loss: 8.254e+02, Y0: 74.056, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4160, Loss: 2.299e+02, Y0: 77.691, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4170, Loss: 1.625e+02, Y0: 76.661, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4180, Loss: 1.840e+02, Y0: 75.820, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4190, Loss: 8.392e+02, Y0: 78.399, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4200, Loss: 2.894e+02, Y0: 76.516, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4210, Loss: 1.749e+02, Y0: 76.105, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4220, Loss: 2.979e+02, Y0: 75.330, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4230, Loss: 1.631e+02, Y0: 77.085, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4240, Loss: 1.238e+02, Y0: 75.977, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4250, Loss: 1.572e+02, Y0: 77.040, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4260, Loss: 1.515e+02, Y0: 76.167, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4270, Loss: 3.404e+02, Y0: 75.471, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 4280, Loss: 2.427e+02, Y0: 77.283, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4290, Loss: 2.113e+02, Y0: 75.963, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 4300, Loss: 1.427e+02, Y0: 76.085, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 4310, Loss: 1.070e+02, Y0: 76.442, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4320, Loss: 4.429e+02, Y0: 74.864, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4330, Loss: 9.852e+02, Y0: 73.831, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4340, Loss: 1.933e+02, Y0: 76.107, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4350, Loss: 2.104e+02, Y0: 77.031, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4360, Loss: 3.234e+02, Y0: 77.787, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4370, Loss: 1.632e+02, Y0: 76.520, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4380, Loss: 3.366e+02, Y0: 75.301, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4390, Loss: 1.929e+02, Y0: 75.853, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 4400, Loss: 1.612e+02, Y0: 76.140, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4410, Loss: 1.460e+02, Y0: 77.218, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4420, Loss: 1.235e+02, Y0: 76.284, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4430, Loss: 2.194e+02, Y0: 75.805, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4440, Loss: 3.744e+02, Y0: 77.820, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4450, Loss: 2.358e+04, Y0: 84.060, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4460, Loss: 1.770e+04, Y0: 87.828, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4470, Loss: 2.827e+04, Y0: 68.851, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 4480, Loss: 3.728e+04, Y0: 82.196, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 4490, Loss: 5.751e+04, Y0: 86.364, Learning Rate: 1.000e-03, Time: 0.77s\n",
      "Epoch: 4500, Loss: 1.953e+04, Y0: 80.096, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4510, Loss: 6.316e+03, Y0: 73.316, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4520, Loss: 3.872e+03, Y0: 71.310, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4530, Loss: 3.335e+03, Y0: 71.430, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4540, Loss: 2.630e+03, Y0: 68.978, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4550, Loss: 2.216e+03, Y0: 67.124, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 4560, Loss: 2.095e+03, Y0: 67.973, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4570, Loss: 1.820e+03, Y0: 66.882, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4580, Loss: 1.654e+03, Y0: 68.492, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4590, Loss: 1.502e+03, Y0: 68.536, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4600, Loss: 1.348e+03, Y0: 68.698, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4610, Loss: 1.314e+03, Y0: 69.050, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4620, Loss: 1.248e+03, Y0: 70.477, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4630, Loss: 1.181e+03, Y0: 70.100, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4640, Loss: 1.086e+03, Y0: 69.327, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4650, Loss: 1.126e+03, Y0: 71.465, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4660, Loss: 1.074e+03, Y0: 71.351, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 4670, Loss: 1.082e+03, Y0: 70.362, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 4680, Loss: 1.130e+03, Y0: 70.335, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 4690, Loss: 1.038e+03, Y0: 70.346, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4700, Loss: 1.109e+03, Y0: 70.389, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 4710, Loss: 9.873e+02, Y0: 70.805, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4720, Loss: 1.017e+03, Y0: 71.093, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4730, Loss: 8.991e+02, Y0: 71.956, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4740, Loss: 1.313e+03, Y0: 71.443, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 4750, Loss: 9.020e+02, Y0: 74.109, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4760, Loss: 1.314e+03, Y0: 75.270, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4770, Loss: 9.919e+02, Y0: 74.366, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4780, Loss: 1.383e+03, Y0: 74.348, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4790, Loss: 7.310e+02, Y0: 74.105, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4800, Loss: 6.216e+02, Y0: 73.526, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4810, Loss: 6.838e+02, Y0: 74.334, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4820, Loss: 6.496e+02, Y0: 74.076, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4830, Loss: 6.314e+02, Y0: 73.213, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 4840, Loss: 7.210e+02, Y0: 72.898, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 4850, Loss: 8.229e+02, Y0: 75.580, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 4860, Loss: 6.880e+02, Y0: 75.353, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 4870, Loss: 6.568e+02, Y0: 74.508, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 4880, Loss: 7.168e+02, Y0: 73.307, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4890, Loss: 7.033e+02, Y0: 75.740, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4900, Loss: 4.716e+02, Y0: 74.741, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4910, Loss: 7.453e+02, Y0: 76.183, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 4920, Loss: 5.099e+02, Y0: 74.410, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4930, Loss: 4.283e+02, Y0: 74.813, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4940, Loss: 1.203e+03, Y0: 73.448, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4950, Loss: 7.441e+02, Y0: 76.823, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 4960, Loss: 4.646e+02, Y0: 75.636, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4970, Loss: 6.724e+02, Y0: 73.534, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4980, Loss: 3.938e+02, Y0: 75.280, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 4990, Loss: 7.155e+02, Y0: 76.521, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5000, Loss: 7.457e+02, Y0: 73.007, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5010, Loss: 4.154e+02, Y0: 74.964, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5020, Loss: 3.856e+02, Y0: 74.560, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5030, Loss: 5.867e+02, Y0: 73.964, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 5040, Loss: 4.231e+02, Y0: 74.475, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 5050, Loss: 4.345e+02, Y0: 74.392, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 5060, Loss: 3.736e+02, Y0: 75.078, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5070, Loss: 3.506e+02, Y0: 75.409, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5080, Loss: 3.418e+02, Y0: 76.074, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5090, Loss: 3.396e+02, Y0: 75.706, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5100, Loss: 3.688e+02, Y0: 74.877, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5110, Loss: 2.955e+02, Y0: 75.700, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5120, Loss: 4.524e+02, Y0: 76.963, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5130, Loss: 7.542e+02, Y0: 73.963, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5140, Loss: 4.837e+02, Y0: 75.220, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 5150, Loss: 2.758e+02, Y0: 75.993, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5160, Loss: 3.395e+02, Y0: 76.494, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5170, Loss: 2.574e+02, Y0: 75.631, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5180, Loss: 2.786e+02, Y0: 75.577, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5190, Loss: 3.226e+02, Y0: 75.087, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5200, Loss: 3.448e+02, Y0: 74.833, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5210, Loss: 3.274e+02, Y0: 76.787, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 5220, Loss: 4.592e+02, Y0: 77.102, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 5230, Loss: 2.647e+02, Y0: 75.968, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 5240, Loss: 2.384e+02, Y0: 76.024, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5250, Loss: 2.338e+02, Y0: 76.324, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5260, Loss: 5.219e+02, Y0: 75.123, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5270, Loss: 3.145e+02, Y0: 76.990, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5280, Loss: 5.559e+02, Y0: 74.183, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5290, Loss: 2.120e+02, Y0: 75.689, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5300, Loss: 2.194e+02, Y0: 76.204, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5310, Loss: 2.829e+02, Y0: 75.789, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5320, Loss: 2.108e+02, Y0: 75.901, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 5330, Loss: 1.888e+02, Y0: 76.170, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5340, Loss: 4.852e+02, Y0: 77.700, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 5350, Loss: 3.267e+02, Y0: 74.816, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5360, Loss: 4.756e+02, Y0: 74.438, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5370, Loss: 1.989e+02, Y0: 75.846, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 5380, Loss: 2.301e+02, Y0: 76.686, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5390, Loss: 3.289e+02, Y0: 74.770, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5400, Loss: 2.128e+02, Y0: 76.782, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 5410, Loss: 1.814e+02, Y0: 76.628, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 5420, Loss: 2.016e+02, Y0: 75.410, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 5430, Loss: 2.167e+02, Y0: 76.692, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5440, Loss: 1.984e+02, Y0: 75.876, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5450, Loss: 3.125e+02, Y0: 77.265, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5460, Loss: 2.715e+02, Y0: 75.068, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5470, Loss: 1.692e+02, Y0: 75.751, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5480, Loss: 1.868e+02, Y0: 75.455, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5490, Loss: 1.416e+02, Y0: 76.331, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5500, Loss: 2.148e+02, Y0: 75.273, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5510, Loss: 5.299e+02, Y0: 76.081, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5520, Loss: 1.569e+02, Y0: 76.607, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5530, Loss: 7.792e+02, Y0: 78.810, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5540, Loss: 3.506e+02, Y0: 77.401, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5550, Loss: 1.602e+02, Y0: 75.506, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5560, Loss: 2.047e+02, Y0: 77.066, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5570, Loss: 2.429e+02, Y0: 75.015, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5580, Loss: 2.948e+02, Y0: 77.479, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5590, Loss: 1.713e+02, Y0: 75.432, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 5600, Loss: 5.734e+02, Y0: 78.198, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 5610, Loss: 3.506e+02, Y0: 77.686, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 5620, Loss: 1.324e+02, Y0: 76.004, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5630, Loss: 1.870e+02, Y0: 76.728, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5640, Loss: 8.138e+02, Y0: 78.623, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5650, Loss: 3.325e+02, Y0: 77.322, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5660, Loss: 2.930e+02, Y0: 77.006, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5670, Loss: 1.715e+02, Y0: 76.657, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5680, Loss: 1.031e+02, Y0: 75.998, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5690, Loss: 1.112e+02, Y0: 76.114, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 5700, Loss: 1.388e+02, Y0: 75.480, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5710, Loss: 1.949e+02, Y0: 76.626, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5720, Loss: 1.670e+02, Y0: 75.415, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5730, Loss: 1.455e+02, Y0: 76.474, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5740, Loss: 2.911e+02, Y0: 75.615, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5750, Loss: 2.299e+02, Y0: 77.311, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5760, Loss: 1.109e+02, Y0: 75.977, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5770, Loss: 1.095e+02, Y0: 76.604, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 5780, Loss: 1.482e+02, Y0: 76.968, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 5790, Loss: 9.315e+01, Y0: 76.484, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 5800, Loss: 1.162e+02, Y0: 76.889, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5810, Loss: 1.678e+02, Y0: 76.635, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5820, Loss: 4.217e+02, Y0: 77.544, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5830, Loss: 4.141e+02, Y0: 77.081, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5840, Loss: 4.251e+02, Y0: 74.346, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5850, Loss: 1.392e+02, Y0: 75.617, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5860, Loss: 2.474e+02, Y0: 77.183, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 5870, Loss: 1.379e+02, Y0: 76.550, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5880, Loss: 2.709e+02, Y0: 74.827, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5890, Loss: 8.988e+01, Y0: 75.910, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5900, Loss: 9.753e+01, Y0: 76.558, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5910, Loss: 8.833e+01, Y0: 76.425, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5920, Loss: 1.587e+02, Y0: 75.282, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 5930, Loss: 1.793e+02, Y0: 77.329, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5940, Loss: 1.300e+02, Y0: 75.482, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 5950, Loss: 1.637e+02, Y0: 76.114, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 5960, Loss: 7.320e+01, Y0: 76.421, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 5970, Loss: 1.451e+02, Y0: 75.494, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 5980, Loss: 2.027e+02, Y0: 75.192, Learning Rate: 1.000e-03, Time: 0.67s\n",
      "Epoch: 5990, Loss: 3.131e+02, Y0: 77.881, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6000, Loss: 1.034e+03, Y0: 79.041, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6010, Loss: 2.811e+02, Y0: 77.202, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6020, Loss: 1.627e+02, Y0: 75.646, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6030, Loss: 1.987e+02, Y0: 74.996, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6040, Loss: 7.847e+01, Y0: 76.010, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6050, Loss: 9.313e+01, Y0: 75.929, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6060, Loss: 7.038e+01, Y0: 76.239, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6070, Loss: 8.598e+01, Y0: 76.341, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6080, Loss: 9.149e+01, Y0: 76.585, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6090, Loss: 8.887e+01, Y0: 75.953, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6100, Loss: 8.320e+01, Y0: 76.794, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6110, Loss: 8.372e+01, Y0: 76.200, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6120, Loss: 7.410e+01, Y0: 76.590, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6130, Loss: 3.442e+02, Y0: 74.699, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6140, Loss: 8.118e+01, Y0: 76.365, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 6150, Loss: 3.251e+02, Y0: 76.235, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 6160, Loss: 7.665e+01, Y0: 76.242, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 6170, Loss: 6.588e+01, Y0: 76.474, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6180, Loss: 1.708e+02, Y0: 75.322, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6190, Loss: 2.170e+02, Y0: 77.658, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6200, Loss: 8.341e+01, Y0: 75.808, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6210, Loss: 1.042e+02, Y0: 75.742, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6220, Loss: 8.662e+01, Y0: 76.840, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6230, Loss: 8.710e+01, Y0: 76.732, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6240, Loss: 2.707e+02, Y0: 74.886, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6250, Loss: 2.886e+02, Y0: 77.747, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6260, Loss: 1.145e+02, Y0: 75.735, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6270, Loss: 8.391e+01, Y0: 76.506, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6280, Loss: 1.200e+02, Y0: 76.929, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6290, Loss: 7.786e+01, Y0: 76.394, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6300, Loss: 1.266e+02, Y0: 75.482, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6310, Loss: 8.893e+01, Y0: 76.855, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6320, Loss: 7.944e+01, Y0: 75.930, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6330, Loss: 6.314e+01, Y0: 76.363, Learning Rate: 1.000e-03, Time: 0.71s\n",
      "Epoch: 6340, Loss: 1.657e+02, Y0: 77.356, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 6350, Loss: 2.103e+02, Y0: 75.062, Learning Rate: 1.000e-03, Time: 0.79s\n",
      "Epoch: 6360, Loss: 2.065e+02, Y0: 77.541, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6370, Loss: 2.456e+02, Y0: 75.058, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 6380, Loss: 3.940e+02, Y0: 77.818, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6390, Loss: 1.671e+02, Y0: 77.154, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6400, Loss: 1.516e+02, Y0: 75.927, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6410, Loss: 1.765e+02, Y0: 75.206, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6420, Loss: 2.575e+02, Y0: 77.542, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6430, Loss: 1.862e+02, Y0: 77.331, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6440, Loss: 8.030e+01, Y0: 75.705, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6450, Loss: 7.899e+01, Y0: 75.841, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6460, Loss: 6.221e+01, Y0: 76.270, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6470, Loss: 6.659e+01, Y0: 76.529, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6480, Loss: 6.034e+01, Y0: 75.978, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 6490, Loss: 7.324e+01, Y0: 76.531, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6500, Loss: 6.278e+01, Y0: 76.353, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6510, Loss: 7.758e+01, Y0: 76.044, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6520, Loss: 1.646e+02, Y0: 75.297, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 6530, Loss: 7.282e+01, Y0: 76.354, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 6540, Loss: 1.084e+02, Y0: 76.710, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 6550, Loss: 1.854e+02, Y0: 77.284, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 6560, Loss: 2.127e+02, Y0: 77.558, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6570, Loss: 8.166e+01, Y0: 75.891, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6580, Loss: 4.536e+02, Y0: 74.068, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 6590, Loss: 2.937e+02, Y0: 74.730, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6600, Loss: 7.475e+01, Y0: 75.896, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6610, Loss: 4.395e+02, Y0: 74.505, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 6620, Loss: 2.359e+02, Y0: 75.458, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6630, Loss: 1.519e+02, Y0: 77.205, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6640, Loss: 7.237e+01, Y0: 76.437, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 6650, Loss: 7.886e+01, Y0: 76.121, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6660, Loss: 1.453e+02, Y0: 75.378, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6670, Loss: 7.221e+01, Y0: 76.714, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 6680, Loss: 6.135e+01, Y0: 76.278, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6690, Loss: 8.196e+01, Y0: 76.961, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6700, Loss: 1.067e+02, Y0: 75.631, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 6710, Loss: 1.051e+02, Y0: 77.168, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 6720, Loss: 6.579e+01, Y0: 76.718, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 6730, Loss: 8.323e+01, Y0: 76.815, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6740, Loss: 2.125e+02, Y0: 77.661, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6750, Loss: 2.620e+02, Y0: 75.052, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6760, Loss: 1.211e+02, Y0: 77.210, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6770, Loss: 5.399e+01, Y0: 76.054, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6780, Loss: 1.294e+02, Y0: 75.415, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6790, Loss: 5.230e+01, Y0: 76.249, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6800, Loss: 1.957e+02, Y0: 75.477, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6810, Loss: 4.589e+01, Y0: 76.487, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6820, Loss: 4.639e+01, Y0: 76.511, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 6830, Loss: 1.559e+02, Y0: 75.415, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6840, Loss: 1.308e+02, Y0: 77.180, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6850, Loss: 4.641e+02, Y0: 74.234, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 6860, Loss: 7.960e+01, Y0: 76.264, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6870, Loss: 1.470e+02, Y0: 76.920, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6880, Loss: 6.447e+01, Y0: 76.219, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6890, Loss: 6.611e+01, Y0: 76.563, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 6900, Loss: 5.136e+01, Y0: 76.154, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 6910, Loss: 1.107e+02, Y0: 75.940, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 6920, Loss: 1.251e+02, Y0: 77.019, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 6930, Loss: 6.481e+01, Y0: 75.866, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6940, Loss: 5.822e+01, Y0: 75.980, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 6950, Loss: 1.522e+02, Y0: 76.330, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6960, Loss: 8.954e+01, Y0: 75.742, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6970, Loss: 7.929e+01, Y0: 76.531, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 6980, Loss: 8.391e+01, Y0: 77.079, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 6990, Loss: 2.727e+02, Y0: 75.605, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7000, Loss: 3.081e+02, Y0: 77.894, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 7010, Loss: 1.773e+02, Y0: 75.236, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7020, Loss: 1.090e+02, Y0: 76.445, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 7030, Loss: 5.701e+01, Y0: 76.249, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7040, Loss: 6.542e+01, Y0: 76.705, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7050, Loss: 8.571e+01, Y0: 75.788, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 7060, Loss: 1.076e+02, Y0: 76.963, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7070, Loss: 3.112e+02, Y0: 74.712, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7080, Loss: 6.281e+01, Y0: 76.613, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 7090, Loss: 7.700e+01, Y0: 76.785, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 7100, Loss: 4.519e+01, Y0: 76.072, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 7110, Loss: 5.996e+01, Y0: 75.870, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7120, Loss: 2.167e+02, Y0: 77.626, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7130, Loss: 1.607e+02, Y0: 76.747, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7140, Loss: 8.943e+01, Y0: 76.748, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7150, Loss: 1.599e+02, Y0: 77.117, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7160, Loss: 3.040e+02, Y0: 77.636, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7170, Loss: 1.500e+02, Y0: 77.157, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7180, Loss: 5.931e+01, Y0: 76.251, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7190, Loss: 6.383e+01, Y0: 75.839, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7200, Loss: 1.393e+02, Y0: 75.250, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7210, Loss: 6.231e+01, Y0: 75.984, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7220, Loss: 9.500e+01, Y0: 76.752, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7230, Loss: 6.364e+01, Y0: 76.244, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7240, Loss: 4.713e+01, Y0: 76.438, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7250, Loss: 4.185e+01, Y0: 76.508, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7260, Loss: 4.361e+01, Y0: 76.329, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7270, Loss: 4.646e+01, Y0: 76.735, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 7280, Loss: 2.063e+02, Y0: 75.670, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 7290, Loss: 2.952e+02, Y0: 77.952, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 7300, Loss: 2.430e+02, Y0: 74.829, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7310, Loss: 1.011e+02, Y0: 75.582, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7320, Loss: 1.981e+02, Y0: 77.509, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7330, Loss: 2.312e+02, Y0: 75.165, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7340, Loss: 8.232e+01, Y0: 76.858, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7350, Loss: 4.401e+01, Y0: 76.320, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7360, Loss: 5.524e+01, Y0: 76.570, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7370, Loss: 1.577e+02, Y0: 75.403, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7380, Loss: 6.257e+01, Y0: 75.995, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7390, Loss: 7.502e+01, Y0: 76.475, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7400, Loss: 7.365e+01, Y0: 76.081, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 7410, Loss: 9.676e+01, Y0: 77.044, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 7420, Loss: 2.704e+02, Y0: 74.710, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 7430, Loss: 2.888e+02, Y0: 76.932, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7440, Loss: 4.200e+02, Y0: 77.860, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 7450, Loss: 7.783e+01, Y0: 76.223, Learning Rate: 1.000e-03, Time: 0.71s\n",
      "Epoch: 7460, Loss: 7.585e+01, Y0: 75.690, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 7470, Loss: 1.151e+02, Y0: 77.092, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 7480, Loss: 1.001e+02, Y0: 75.547, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 7490, Loss: 1.114e+02, Y0: 77.100, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7500, Loss: 1.143e+02, Y0: 75.456, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7510, Loss: 1.068e+02, Y0: 75.856, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 7520, Loss: 1.024e+02, Y0: 75.534, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7530, Loss: 1.645e+02, Y0: 77.273, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7540, Loss: 9.094e+01, Y0: 75.694, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7550, Loss: 5.158e+01, Y0: 76.406, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7560, Loss: 3.897e+03, Y0: 76.924, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 7570, Loss: 5.083e+02, Y0: 74.794, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 7580, Loss: 3.403e+03, Y0: 74.846, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7590, Loss: 1.106e+03, Y0: 76.135, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 7600, Loss: 1.225e+03, Y0: 77.038, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7610, Loss: 2.585e+02, Y0: 74.284, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7620, Loss: 2.381e+02, Y0: 76.257, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 7630, Loss: 1.188e+02, Y0: 75.201, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 7640, Loss: 1.204e+02, Y0: 74.953, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 7650, Loss: 7.110e+01, Y0: 75.752, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 7660, Loss: 6.318e+01, Y0: 75.307, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7670, Loss: 5.920e+01, Y0: 75.965, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7680, Loss: 5.017e+01, Y0: 76.085, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7690, Loss: 5.343e+01, Y0: 75.760, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7700, Loss: 4.601e+01, Y0: 75.978, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7710, Loss: 7.973e+01, Y0: 75.873, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 7720, Loss: 8.335e+01, Y0: 76.035, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7730, Loss: 4.426e+01, Y0: 76.220, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7740, Loss: 6.666e+01, Y0: 75.866, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 7750, Loss: 5.067e+01, Y0: 76.056, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7760, Loss: 5.700e+01, Y0: 76.680, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7770, Loss: 4.161e+01, Y0: 76.438, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7780, Loss: 3.929e+01, Y0: 76.382, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7790, Loss: 4.462e+01, Y0: 76.325, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7800, Loss: 4.413e+01, Y0: 76.159, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7810, Loss: 4.457e+01, Y0: 76.111, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7820, Loss: 1.544e+02, Y0: 75.911, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 7830, Loss: 8.027e+01, Y0: 77.014, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 7840, Loss: 4.118e+01, Y0: 76.391, Learning Rate: 1.000e-03, Time: 0.67s\n",
      "Epoch: 7850, Loss: 9.030e+01, Y0: 75.667, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7860, Loss: 6.537e+01, Y0: 76.824, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7870, Loss: 4.957e+01, Y0: 76.560, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7880, Loss: 4.467e+01, Y0: 76.129, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 7890, Loss: 5.269e+01, Y0: 76.736, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7900, Loss: 1.579e+02, Y0: 76.474, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7910, Loss: 1.334e+02, Y0: 75.311, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7920, Loss: 1.256e+02, Y0: 75.534, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7930, Loss: 5.178e+01, Y0: 76.641, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7940, Loss: 4.114e+01, Y0: 76.270, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7950, Loss: 1.264e+02, Y0: 77.253, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 7960, Loss: 2.254e+02, Y0: 74.876, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 7970, Loss: 8.398e+01, Y0: 76.890, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 7980, Loss: 7.133e+01, Y0: 76.915, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 7990, Loss: 1.074e+02, Y0: 75.474, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8000, Loss: 6.593e+01, Y0: 75.815, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 8010, Loss: 6.047e+01, Y0: 76.762, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 8020, Loss: 3.722e+01, Y0: 76.370, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 8030, Loss: 3.971e+01, Y0: 76.251, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8040, Loss: 3.919e+01, Y0: 76.402, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8050, Loss: 3.989e+01, Y0: 76.407, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 8060, Loss: 4.577e+01, Y0: 76.104, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8070, Loss: 4.875e+01, Y0: 76.768, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8080, Loss: 5.984e+01, Y0: 75.812, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8090, Loss: 4.454e+02, Y0: 78.209, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 8100, Loss: 9.080e+01, Y0: 76.694, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8110, Loss: 8.887e+01, Y0: 75.371, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 8120, Loss: 1.070e+02, Y0: 75.307, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8130, Loss: 6.831e+01, Y0: 75.775, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8140, Loss: 4.693e+01, Y0: 75.842, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 8150, Loss: 2.120e+02, Y0: 75.792, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8160, Loss: 4.242e+01, Y0: 76.365, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8170, Loss: 4.581e+01, Y0: 76.422, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 8180, Loss: 4.159e+01, Y0: 76.412, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 8190, Loss: 4.354e+01, Y0: 76.073, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 8200, Loss: 6.399e+01, Y0: 76.855, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 8210, Loss: 9.205e+01, Y0: 75.571, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8220, Loss: 1.335e+02, Y0: 75.462, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8230, Loss: 4.416e+01, Y0: 76.434, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8240, Loss: 4.949e+01, Y0: 76.581, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8250, Loss: 8.358e+01, Y0: 75.568, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8260, Loss: 6.467e+01, Y0: 76.876, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8270, Loss: 1.667e+02, Y0: 75.088, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8280, Loss: 8.557e+01, Y0: 76.948, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8290, Loss: 8.196e+01, Y0: 76.843, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8300, Loss: 7.578e+01, Y0: 75.735, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8310, Loss: 6.903e+01, Y0: 76.756, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 8320, Loss: 5.716e+01, Y0: 76.098, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8330, Loss: 3.595e+01, Y0: 76.153, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8340, Loss: 3.717e+01, Y0: 76.490, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8350, Loss: 7.989e+01, Y0: 75.711, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8360, Loss: 6.386e+01, Y0: 76.989, Learning Rate: 1.000e-03, Time: 0.67s\n",
      "Epoch: 8370, Loss: 8.408e+01, Y0: 75.665, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 8380, Loss: 2.165e+02, Y0: 77.687, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 8390, Loss: 6.191e+01, Y0: 75.844, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8400, Loss: 3.553e+01, Y0: 76.075, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 8410, Loss: 3.925e+01, Y0: 76.510, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8420, Loss: 3.583e+01, Y0: 76.462, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8430, Loss: 7.706e+01, Y0: 76.851, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8440, Loss: 7.796e+01, Y0: 75.605, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8450, Loss: 5.431e+01, Y0: 76.518, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8460, Loss: 3.324e+01, Y0: 76.215, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8470, Loss: 5.274e+01, Y0: 76.809, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8480, Loss: 4.099e+01, Y0: 76.190, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8490, Loss: 1.491e+02, Y0: 75.285, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8500, Loss: 3.258e+01, Y0: 76.419, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8510, Loss: 7.091e+01, Y0: 75.743, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 8520, Loss: 3.500e+01, Y0: 76.292, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 8530, Loss: 1.437e+02, Y0: 77.286, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8540, Loss: 2.496e+02, Y0: 74.706, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 8550, Loss: 4.985e+01, Y0: 76.049, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 8560, Loss: 1.522e+02, Y0: 77.256, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 8570, Loss: 5.768e+01, Y0: 76.614, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8580, Loss: 7.460e+01, Y0: 75.567, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8590, Loss: 6.355e+01, Y0: 76.659, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 8600, Loss: 7.725e+01, Y0: 75.567, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8610, Loss: 5.045e+01, Y0: 76.599, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8620, Loss: 7.880e+01, Y0: 75.669, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 8630, Loss: 9.618e+01, Y0: 77.135, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8640, Loss: 1.782e+02, Y0: 75.094, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 8650, Loss: 1.887e+02, Y0: 77.408, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8660, Loss: 9.192e+01, Y0: 77.002, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8670, Loss: 1.241e+02, Y0: 75.366, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8680, Loss: 4.785e+01, Y0: 76.524, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8690, Loss: 4.383e+01, Y0: 76.656, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8700, Loss: 8.860e+01, Y0: 75.571, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8710, Loss: 4.311e+01, Y0: 76.386, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8720, Loss: 4.733e+01, Y0: 76.228, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8730, Loss: 4.313e+01, Y0: 76.704, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 8740, Loss: 4.092e+01, Y0: 76.734, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 8750, Loss: 3.919e+01, Y0: 76.658, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 8760, Loss: 1.392e+02, Y0: 77.449, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8770, Loss: 1.577e+02, Y0: 75.290, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8780, Loss: 1.118e+02, Y0: 76.008, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 8790, Loss: 8.824e+01, Y0: 75.399, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8800, Loss: 7.400e+01, Y0: 75.592, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8810, Loss: 9.902e+01, Y0: 75.255, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8820, Loss: 4.418e+01, Y0: 76.223, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 8830, Loss: 4.692e+01, Y0: 76.450, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8840, Loss: 6.159e+01, Y0: 76.492, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8850, Loss: 3.205e+01, Y0: 76.219, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8860, Loss: 2.998e+01, Y0: 76.360, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8870, Loss: 4.425e+01, Y0: 76.018, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 8880, Loss: 3.382e+01, Y0: 76.262, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8890, Loss: 3.567e+01, Y0: 76.162, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8900, Loss: 4.772e+01, Y0: 76.731, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8910, Loss: 3.141e+01, Y0: 76.233, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8920, Loss: 3.504e+01, Y0: 76.563, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 8930, Loss: 7.982e+01, Y0: 75.667, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 8940, Loss: 2.624e+02, Y0: 77.830, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 8950, Loss: 4.838e+02, Y0: 74.031, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8960, Loss: 2.161e+02, Y0: 74.689, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 8970, Loss: 2.157e+02, Y0: 77.026, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 8980, Loss: 1.211e+02, Y0: 76.562, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 8990, Loss: 3.858e+01, Y0: 75.937, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9000, Loss: 3.522e+01, Y0: 75.933, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9010, Loss: 3.353e+01, Y0: 75.932, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9020, Loss: 3.632e+01, Y0: 75.997, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9030, Loss: 2.878e+01, Y0: 76.173, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9040, Loss: 3.131e+01, Y0: 76.326, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9050, Loss: 3.157e+01, Y0: 76.379, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9060, Loss: 2.965e+01, Y0: 76.401, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9070, Loss: 3.021e+01, Y0: 76.288, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 9080, Loss: 3.455e+01, Y0: 76.594, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9090, Loss: 7.436e+01, Y0: 75.895, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9100, Loss: 1.785e+02, Y0: 77.023, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 9110, Loss: 7.522e+01, Y0: 76.825, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 9120, Loss: 6.658e+01, Y0: 75.936, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 9130, Loss: 2.967e+01, Y0: 76.143, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9140, Loss: 4.942e+01, Y0: 76.531, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9150, Loss: 6.079e+01, Y0: 75.838, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9160, Loss: 3.989e+01, Y0: 76.662, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9170, Loss: 3.328e+01, Y0: 76.250, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9180, Loss: 4.203e+01, Y0: 76.070, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9190, Loss: 1.135e+02, Y0: 77.146, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9200, Loss: 4.269e+01, Y0: 76.461, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9210, Loss: 4.642e+01, Y0: 76.722, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9220, Loss: 4.548e+01, Y0: 76.732, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9230, Loss: 7.742e+01, Y0: 77.047, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9240, Loss: 7.384e+01, Y0: 76.084, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9250, Loss: 7.072e+01, Y0: 76.905, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9260, Loss: 3.747e+02, Y0: 74.385, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9270, Loss: 2.859e+02, Y0: 74.671, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9280, Loss: 4.982e+02, Y0: 73.822, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9290, Loss: 3.894e+02, Y0: 73.946, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 9300, Loss: 9.399e+01, Y0: 76.044, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 9310, Loss: 6.701e+01, Y0: 76.360, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9320, Loss: 6.008e+01, Y0: 76.309, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9330, Loss: 4.741e+01, Y0: 75.807, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9340, Loss: 3.496e+01, Y0: 76.190, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9350, Loss: 3.622e+01, Y0: 76.173, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9360, Loss: 4.742e+01, Y0: 75.967, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9370, Loss: 3.395e+01, Y0: 76.227, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9380, Loss: 2.947e+01, Y0: 76.421, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9390, Loss: 2.980e+01, Y0: 76.314, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9400, Loss: 8.461e+01, Y0: 76.089, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9410, Loss: 1.456e+02, Y0: 75.422, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9420, Loss: 6.474e+01, Y0: 75.688, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9430, Loss: 4.273e+01, Y0: 76.047, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9440, Loss: 5.452e+01, Y0: 76.512, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9450, Loss: 1.292e+02, Y0: 76.161, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9460, Loss: 3.312e+01, Y0: 76.233, Learning Rate: 1.000e-03, Time: 0.67s\n",
      "Epoch: 9470, Loss: 3.355e+01, Y0: 76.487, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 9480, Loss: 4.027e+01, Y0: 75.949, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 9490, Loss: 3.864e+01, Y0: 76.026, Learning Rate: 1.000e-03, Time: 0.71s\n",
      "Epoch: 9500, Loss: 6.758e+01, Y0: 76.992, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9510, Loss: 5.233e+01, Y0: 75.817, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9520, Loss: 3.705e+01, Y0: 76.148, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9530, Loss: 3.480e+01, Y0: 76.433, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9540, Loss: 3.154e+01, Y0: 76.368, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9550, Loss: 7.538e+01, Y0: 75.914, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9560, Loss: 3.797e+01, Y0: 76.599, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9570, Loss: 3.663e+01, Y0: 76.136, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9580, Loss: 4.591e+01, Y0: 76.629, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9590, Loss: 1.979e+02, Y0: 75.037, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 9600, Loss: 2.524e+02, Y0: 77.439, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9610, Loss: 1.608e+02, Y0: 77.047, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9620, Loss: 7.189e+01, Y0: 76.563, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9630, Loss: 4.790e+01, Y0: 76.146, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9640, Loss: 3.193e+01, Y0: 75.899, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9650, Loss: 3.168e+01, Y0: 76.311, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9660, Loss: 3.041e+01, Y0: 76.218, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 9670, Loss: 3.238e+01, Y0: 76.512, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 9680, Loss: 4.549e+01, Y0: 75.887, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9690, Loss: 6.099e+01, Y0: 76.781, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9700, Loss: 9.836e+01, Y0: 75.604, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9710, Loss: 5.537e+01, Y0: 76.727, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 9720, Loss: 3.702e+01, Y0: 76.046, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9730, Loss: 3.379e+01, Y0: 76.207, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9740, Loss: 3.013e+02, Y0: 78.011, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9750, Loss: 2.003e+02, Y0: 77.334, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9760, Loss: 9.139e+01, Y0: 76.567, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9770, Loss: 5.907e+01, Y0: 76.326, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9780, Loss: 5.733e+01, Y0: 76.436, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9790, Loss: 7.430e+01, Y0: 76.616, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9800, Loss: 6.236e+01, Y0: 76.743, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9810, Loss: 3.153e+01, Y0: 75.960, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9820, Loss: 3.805e+01, Y0: 76.001, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9830, Loss: 3.028e+01, Y0: 76.404, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9840, Loss: 3.179e+01, Y0: 76.182, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 9850, Loss: 3.089e+01, Y0: 76.494, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 9860, Loss: 1.709e+02, Y0: 77.289, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 9870, Loss: 8.537e+02, Y0: 76.496, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9880, Loss: 2.837e+04, Y0: 65.187, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9890, Loss: 2.129e+04, Y0: 76.802, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9900, Loss: 1.589e+04, Y0: 78.593, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9910, Loss: 9.539e+03, Y0: 74.877, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9920, Loss: 5.955e+03, Y0: 74.230, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9930, Loss: 5.074e+03, Y0: 72.861, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 9940, Loss: 4.495e+03, Y0: 73.994, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 9950, Loss: 3.996e+03, Y0: 72.083, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 9960, Loss: 3.681e+03, Y0: 71.567, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9970, Loss: 3.345e+03, Y0: 71.138, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 9980, Loss: 3.171e+03, Y0: 70.673, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 9990, Loss: 3.177e+03, Y0: 71.202, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10000, Loss: 2.835e+03, Y0: 71.278, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10010, Loss: 2.420e+03, Y0: 70.667, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10020, Loss: 2.501e+03, Y0: 70.879, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10030, Loss: 2.287e+03, Y0: 68.434, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 10040, Loss: 1.881e+03, Y0: 67.399, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 10050, Loss: 2.190e+03, Y0: 72.031, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 10060, Loss: 1.737e+03, Y0: 68.227, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10070, Loss: 1.448e+03, Y0: 68.465, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10080, Loss: 1.345e+03, Y0: 68.378, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10090, Loss: 1.452e+03, Y0: 70.161, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10100, Loss: 1.802e+03, Y0: 71.040, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10110, Loss: 1.146e+03, Y0: 69.200, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10120, Loss: 2.986e+03, Y0: 74.632, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10130, Loss: 1.136e+03, Y0: 70.091, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10140, Loss: 1.001e+03, Y0: 69.714, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10150, Loss: 1.033e+03, Y0: 71.442, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10160, Loss: 9.100e+02, Y0: 70.491, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10170, Loss: 3.168e+03, Y0: 75.626, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10180, Loss: 1.969e+03, Y0: 68.352, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10190, Loss: 1.060e+03, Y0: 72.828, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10200, Loss: 9.262e+02, Y0: 70.432, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10210, Loss: 1.028e+03, Y0: 72.890, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10220, Loss: 8.933e+02, Y0: 70.042, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 10230, Loss: 8.496e+02, Y0: 70.034, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 10240, Loss: 8.580e+02, Y0: 70.322, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10250, Loss: 7.385e+02, Y0: 70.963, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10260, Loss: 9.217e+02, Y0: 73.531, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10270, Loss: 7.134e+02, Y0: 72.939, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10280, Loss: 6.465e+02, Y0: 72.601, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10290, Loss: 7.856e+02, Y0: 71.587, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10300, Loss: 6.248e+02, Y0: 73.397, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10310, Loss: 8.494e+02, Y0: 70.900, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10320, Loss: 7.261e+02, Y0: 71.513, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10330, Loss: 8.983e+02, Y0: 71.253, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 10340, Loss: 7.161e+02, Y0: 71.599, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10350, Loss: 9.899e+02, Y0: 74.935, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10360, Loss: 5.330e+02, Y0: 73.732, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10370, Loss: 4.753e+02, Y0: 73.069, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10380, Loss: 5.956e+02, Y0: 72.358, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10390, Loss: 6.590e+02, Y0: 74.816, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10400, Loss: 6.101e+02, Y0: 71.987, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 10410, Loss: 4.525e+02, Y0: 74.482, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 10420, Loss: 1.173e+03, Y0: 76.529, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 10430, Loss: 5.073e+02, Y0: 74.980, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10440, Loss: 4.924e+02, Y0: 74.271, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10450, Loss: 8.133e+02, Y0: 71.639, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10460, Loss: 5.731e+02, Y0: 72.857, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10470, Loss: 4.878e+02, Y0: 73.133, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10480, Loss: 4.529e+02, Y0: 74.557, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10490, Loss: 4.525e+02, Y0: 73.907, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10500, Loss: 7.135e+02, Y0: 76.169, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10510, Loss: 8.854e+02, Y0: 76.735, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10520, Loss: 4.142e+02, Y0: 75.003, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10530, Loss: 4.254e+02, Y0: 73.492, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10540, Loss: 4.432e+02, Y0: 75.510, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10550, Loss: 4.062e+02, Y0: 75.353, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10560, Loss: 4.664e+02, Y0: 73.317, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10570, Loss: 3.609e+02, Y0: 74.567, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10580, Loss: 3.557e+02, Y0: 75.059, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10590, Loss: 6.104e+02, Y0: 76.418, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 10600, Loss: 3.562e+02, Y0: 74.246, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 10610, Loss: 3.077e+02, Y0: 74.393, Learning Rate: 1.000e-03, Time: 0.69s\n",
      "Epoch: 10620, Loss: 5.506e+02, Y0: 73.568, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 10630, Loss: 3.267e+02, Y0: 74.589, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10640, Loss: 8.137e+02, Y0: 72.583, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10650, Loss: 6.112e+02, Y0: 73.050, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10660, Loss: 3.341e+02, Y0: 74.258, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10670, Loss: 4.845e+02, Y0: 74.140, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10680, Loss: 3.428e+02, Y0: 75.975, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10690, Loss: 3.874e+02, Y0: 73.996, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10700, Loss: 3.482e+02, Y0: 76.181, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10710, Loss: 2.990e+02, Y0: 74.645, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10720, Loss: 2.537e+02, Y0: 74.894, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10730, Loss: 1.041e+03, Y0: 72.431, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10740, Loss: 4.174e+02, Y0: 74.139, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10750, Loss: 2.783e+02, Y0: 75.881, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10760, Loss: 2.795e+02, Y0: 76.086, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10770, Loss: 3.283e+02, Y0: 74.765, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 10780, Loss: 3.407e+02, Y0: 74.276, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 10790, Loss: 2.681e+02, Y0: 76.110, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 10800, Loss: 7.644e+02, Y0: 73.144, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10810, Loss: 3.358e+02, Y0: 74.439, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10820, Loss: 3.433e+02, Y0: 76.626, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10830, Loss: 2.696e+02, Y0: 75.081, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10840, Loss: 2.854e+02, Y0: 76.103, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 10850, Loss: 2.088e+02, Y0: 75.624, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10860, Loss: 3.537e+02, Y0: 76.919, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10870, Loss: 3.446e+02, Y0: 74.404, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10880, Loss: 4.428e+02, Y0: 73.899, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 10890, Loss: 3.187e+02, Y0: 76.250, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10900, Loss: 2.342e+02, Y0: 74.965, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10910, Loss: 2.340e+02, Y0: 74.855, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 10920, Loss: 4.926e+02, Y0: 77.347, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 10930, Loss: 4.344e+02, Y0: 73.978, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 10940, Loss: 2.359e+02, Y0: 76.437, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10950, Loss: 3.880e+02, Y0: 74.098, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 10960, Loss: 2.950e+02, Y0: 76.835, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 10970, Loss: 2.424e+02, Y0: 75.063, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 10980, Loss: 4.660e+02, Y0: 77.533, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 10990, Loss: 2.685e+02, Y0: 75.594, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11000, Loss: 2.520e+02, Y0: 75.195, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11010, Loss: 3.335e+02, Y0: 74.561, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11020, Loss: 2.401e+02, Y0: 74.994, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 11030, Loss: 2.759e+02, Y0: 76.906, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11040, Loss: 3.951e+02, Y0: 74.321, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11050, Loss: 1.908e+02, Y0: 75.522, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11060, Loss: 1.986e+02, Y0: 76.392, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11070, Loss: 5.319e+02, Y0: 73.754, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11080, Loss: 2.709e+02, Y0: 75.371, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11090, Loss: 1.645e+02, Y0: 75.553, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11100, Loss: 2.257e+02, Y0: 75.354, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11110, Loss: 1.559e+02, Y0: 75.890, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11120, Loss: 1.516e+02, Y0: 75.718, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11130, Loss: 2.021e+02, Y0: 76.427, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11140, Loss: 3.139e+02, Y0: 77.258, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11150, Loss: 2.996e+02, Y0: 74.787, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 11160, Loss: 3.140e+02, Y0: 77.261, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 11170, Loss: 2.897e+02, Y0: 74.747, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 11180, Loss: 3.679e+02, Y0: 77.510, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 11190, Loss: 2.115e+02, Y0: 75.422, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11200, Loss: 3.078e+02, Y0: 77.276, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 11210, Loss: 4.434e+02, Y0: 74.181, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11220, Loss: 2.969e+02, Y0: 77.232, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11230, Loss: 1.860e+02, Y0: 75.448, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11240, Loss: 1.519e+02, Y0: 76.312, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11250, Loss: 1.366e+03, Y0: 79.359, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11260, Loss: 4.590e+02, Y0: 74.249, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11270, Loss: 3.772e+02, Y0: 74.343, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11280, Loss: 1.442e+02, Y0: 75.865, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11290, Loss: 1.734e+02, Y0: 76.512, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11300, Loss: 3.294e+02, Y0: 74.452, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11310, Loss: 2.124e+02, Y0: 76.847, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11320, Loss: 2.067e+02, Y0: 75.168, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11330, Loss: 1.745e+02, Y0: 75.954, Learning Rate: 1.000e-03, Time: 0.71s\n",
      "Epoch: 11340, Loss: 1.590e+02, Y0: 76.554, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 11350, Loss: 2.157e+02, Y0: 77.034, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 11360, Loss: 1.977e+02, Y0: 75.184, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 11370, Loss: 4.349e+02, Y0: 77.818, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11380, Loss: 1.448e+02, Y0: 75.688, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11390, Loss: 1.832e+02, Y0: 76.850, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11400, Loss: 3.361e+02, Y0: 77.634, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11410, Loss: 2.067e+02, Y0: 75.252, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11420, Loss: 1.416e+02, Y0: 76.599, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11430, Loss: 7.068e+02, Y0: 78.513, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11440, Loss: 2.183e+02, Y0: 76.976, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11450, Loss: 1.357e+02, Y0: 76.101, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11460, Loss: 1.548e+02, Y0: 76.809, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11470, Loss: 2.536e+02, Y0: 77.233, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11480, Loss: 2.097e+02, Y0: 75.856, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11490, Loss: 1.739e+02, Y0: 75.982, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11500, Loss: 1.459e+02, Y0: 76.341, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11510, Loss: 2.230e+03, Y0: 71.320, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 11520, Loss: 4.403e+02, Y0: 77.360, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 11530, Loss: 3.257e+02, Y0: 77.304, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 11540, Loss: 1.325e+02, Y0: 75.696, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 11550, Loss: 3.596e+02, Y0: 77.476, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11560, Loss: 1.868e+02, Y0: 75.802, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11570, Loss: 2.371e+02, Y0: 77.175, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11580, Loss: 1.624e+02, Y0: 75.352, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11590, Loss: 1.294e+02, Y0: 75.653, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11600, Loss: 1.312e+02, Y0: 76.639, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11610, Loss: 2.319e+02, Y0: 75.100, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11620, Loss: 2.174e+02, Y0: 75.336, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11630, Loss: 1.222e+02, Y0: 75.728, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11640, Loss: 1.401e+02, Y0: 76.830, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11650, Loss: 2.111e+02, Y0: 75.167, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11660, Loss: 1.309e+02, Y0: 75.899, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11670, Loss: 3.218e+02, Y0: 77.675, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 11680, Loss: 3.590e+02, Y0: 74.581, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11690, Loss: 3.968e+02, Y0: 77.962, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11700, Loss: 1.880e+02, Y0: 75.274, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 11710, Loss: 5.284e+02, Y0: 78.319, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 11720, Loss: 1.855e+02, Y0: 76.536, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 11730, Loss: 1.546e+02, Y0: 75.568, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 11740, Loss: 1.160e+02, Y0: 75.781, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11750, Loss: 1.097e+02, Y0: 76.094, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11760, Loss: 6.906e+02, Y0: 78.797, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11770, Loss: 1.377e+02, Y0: 76.329, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11780, Loss: 2.110e+02, Y0: 75.221, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 11790, Loss: 3.507e+02, Y0: 77.795, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 11800, Loss: 1.786e+02, Y0: 75.710, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11810, Loss: 5.359e+02, Y0: 74.155, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11820, Loss: 1.293e+02, Y0: 76.452, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11830, Loss: 2.258e+02, Y0: 75.010, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 11840, Loss: 2.487e+02, Y0: 77.438, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11850, Loss: 1.144e+02, Y0: 76.041, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11860, Loss: 4.665e+02, Y0: 78.143, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11870, Loss: 1.798e+02, Y0: 75.514, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11880, Loss: 1.254e+02, Y0: 76.877, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11890, Loss: 1.193e+02, Y0: 76.381, Learning Rate: 1.000e-03, Time: 0.79s\n",
      "Epoch: 11900, Loss: 5.069e+02, Y0: 74.074, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 11910, Loss: 1.136e+02, Y0: 76.006, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 11920, Loss: 1.004e+02, Y0: 76.047, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 11930, Loss: 9.424e+01, Y0: 75.986, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11940, Loss: 1.130e+02, Y0: 76.296, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 11950, Loss: 7.180e+02, Y0: 78.771, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11960, Loss: 1.435e+02, Y0: 76.626, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11970, Loss: 2.842e+02, Y0: 74.992, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 11980, Loss: 1.213e+02, Y0: 76.788, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 11990, Loss: 4.423e+02, Y0: 78.093, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 12000, Loss: 1.203e+02, Y0: 76.062, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12010, Loss: 4.183e+02, Y0: 77.995, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12020, Loss: 1.988e+02, Y0: 75.247, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12030, Loss: 2.213e+02, Y0: 77.502, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12040, Loss: 2.338e+02, Y0: 75.074, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12050, Loss: 4.158e+02, Y0: 77.792, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12060, Loss: 4.876e+02, Y0: 78.247, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12070, Loss: 1.118e+02, Y0: 76.340, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12080, Loss: 1.944e+02, Y0: 77.125, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 12090, Loss: 2.971e+02, Y0: 74.953, Learning Rate: 1.000e-03, Time: 0.89s\n",
      "Epoch: 12100, Loss: 2.070e+02, Y0: 77.426, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12110, Loss: 9.504e+01, Y0: 76.290, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12120, Loss: 4.390e+02, Y0: 78.221, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12130, Loss: 3.882e+02, Y0: 74.464, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 12140, Loss: 2.806e+02, Y0: 77.692, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12150, Loss: 1.013e+02, Y0: 76.208, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 12160, Loss: 2.025e+02, Y0: 75.232, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12170, Loss: 1.156e+02, Y0: 76.940, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12180, Loss: 2.122e+02, Y0: 75.118, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12190, Loss: 4.517e+02, Y0: 78.300, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12200, Loss: 1.208e+02, Y0: 75.713, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12210, Loss: 1.375e+02, Y0: 76.978, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12220, Loss: 9.166e+01, Y0: 76.375, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12230, Loss: 1.255e+02, Y0: 75.548, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12240, Loss: 2.181e+02, Y0: 75.079, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12250, Loss: 2.410e+02, Y0: 77.668, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12260, Loss: 2.585e+02, Y0: 75.308, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 12270, Loss: 1.517e+02, Y0: 76.954, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 12280, Loss: 1.534e+02, Y0: 75.465, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 12290, Loss: 2.119e+02, Y0: 77.185, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 12300, Loss: 1.357e+02, Y0: 76.907, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 12310, Loss: 1.599e+02, Y0: 75.554, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12320, Loss: 9.293e+01, Y0: 76.038, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12330, Loss: 9.361e+01, Y0: 75.963, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12340, Loss: 7.480e+01, Y0: 76.178, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12350, Loss: 4.079e+02, Y0: 78.247, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12360, Loss: 1.112e+02, Y0: 76.244, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12370, Loss: 4.723e+02, Y0: 74.202, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12380, Loss: 1.082e+02, Y0: 76.460, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12390, Loss: 2.304e+02, Y0: 75.021, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12400, Loss: 1.356e+02, Y0: 77.034, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12410, Loss: 7.955e+01, Y0: 76.474, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12420, Loss: 2.551e+02, Y0: 74.912, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12430, Loss: 1.373e+02, Y0: 77.124, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12440, Loss: 1.060e+02, Y0: 75.899, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12450, Loss: 5.251e+02, Y0: 74.135, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 12460, Loss: 2.093e+02, Y0: 77.546, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 12470, Loss: 4.386e+02, Y0: 74.285, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12480, Loss: 1.244e+02, Y0: 75.793, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12490, Loss: 3.838e+02, Y0: 77.932, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12500, Loss: 8.395e+01, Y0: 76.417, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12510, Loss: 2.763e+02, Y0: 77.667, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12520, Loss: 3.086e+02, Y0: 74.901, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12530, Loss: 1.906e+02, Y0: 77.436, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12540, Loss: 1.282e+02, Y0: 75.615, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12550, Loss: 2.972e+02, Y0: 77.833, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12560, Loss: 1.527e+02, Y0: 75.442, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12570, Loss: 8.083e+01, Y0: 76.335, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12580, Loss: 2.053e+02, Y0: 75.207, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12590, Loss: 1.306e+02, Y0: 75.677, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12600, Loss: 2.229e+02, Y0: 77.571, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12610, Loss: 3.976e+02, Y0: 74.378, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12620, Loss: 1.172e+02, Y0: 75.698, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12630, Loss: 1.710e+02, Y0: 77.276, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 12640, Loss: 1.499e+02, Y0: 77.008, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 12650, Loss: 9.925e+01, Y0: 75.902, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 12660, Loss: 4.434e+02, Y0: 74.310, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12670, Loss: 1.592e+02, Y0: 75.384, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12680, Loss: 3.724e+02, Y0: 77.953, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12690, Loss: 7.953e+01, Y0: 76.206, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12700, Loss: 1.435e+02, Y0: 75.388, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12710, Loss: 9.540e+01, Y0: 76.620, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12720, Loss: 7.608e+01, Y0: 76.386, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12730, Loss: 1.448e+02, Y0: 77.210, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12740, Loss: 8.290e+01, Y0: 76.023, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 12750, Loss: 1.040e+02, Y0: 76.120, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12760, Loss: 5.803e+02, Y0: 74.062, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12770, Loss: 1.336e+02, Y0: 75.647, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 12780, Loss: 1.550e+02, Y0: 77.236, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12790, Loss: 2.742e+02, Y0: 74.874, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12800, Loss: 1.581e+02, Y0: 77.211, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12810, Loss: 7.000e+01, Y0: 76.018, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12820, Loss: 1.216e+02, Y0: 75.624, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 12830, Loss: 1.006e+02, Y0: 76.907, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 12840, Loss: 1.470e+02, Y0: 77.377, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 12850, Loss: 1.506e+02, Y0: 75.869, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12860, Loss: 3.268e+02, Y0: 78.099, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12870, Loss: 1.562e+02, Y0: 75.539, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12880, Loss: 1.199e+02, Y0: 75.685, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12890, Loss: 5.570e+02, Y0: 78.560, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12900, Loss: 2.019e+02, Y0: 77.354, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12910, Loss: 1.254e+02, Y0: 75.619, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 12920, Loss: 1.261e+02, Y0: 75.486, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12930, Loss: 1.716e+02, Y0: 76.627, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12940, Loss: 3.089e+02, Y0: 77.769, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12950, Loss: 2.961e+02, Y0: 77.920, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 12960, Loss: 1.574e+02, Y0: 75.709, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12970, Loss: 9.787e+01, Y0: 76.184, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 12980, Loss: 1.339e+02, Y0: 75.991, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 12990, Loss: 8.895e+01, Y0: 75.884, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13000, Loss: 1.077e+02, Y0: 76.926, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 13010, Loss: 2.202e+02, Y0: 77.711, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 13020, Loss: 7.530e+01, Y0: 76.223, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 13030, Loss: 1.194e+02, Y0: 76.156, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13040, Loss: 9.128e+02, Y0: 73.406, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13050, Loss: 3.783e+02, Y0: 74.597, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13060, Loss: 1.230e+02, Y0: 76.581, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 13070, Loss: 7.715e+01, Y0: 75.976, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13080, Loss: 7.611e+01, Y0: 76.605, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 13090, Loss: 3.123e+02, Y0: 74.656, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13100, Loss: 2.245e+02, Y0: 77.614, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13110, Loss: 3.078e+02, Y0: 74.680, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13120, Loss: 1.039e+02, Y0: 75.798, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13130, Loss: 3.061e+02, Y0: 77.896, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13140, Loss: 1.966e+02, Y0: 75.133, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13150, Loss: 9.802e+01, Y0: 76.701, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13160, Loss: 2.349e+02, Y0: 77.655, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13170, Loss: 1.312e+02, Y0: 75.541, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13180, Loss: 1.324e+02, Y0: 77.109, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13190, Loss: 7.148e+01, Y0: 76.716, Learning Rate: 1.000e-03, Time: 0.77s\n",
      "Epoch: 13200, Loss: 4.220e+02, Y0: 74.501, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 13210, Loss: 1.500e+02, Y0: 75.501, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 13220, Loss: 1.629e+02, Y0: 77.206, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13230, Loss: 1.030e+02, Y0: 76.945, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 13240, Loss: 1.266e+02, Y0: 75.675, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 13250, Loss: 2.614e+02, Y0: 77.702, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13260, Loss: 6.836e+02, Y0: 73.721, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13270, Loss: 3.732e+02, Y0: 74.753, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13280, Loss: 1.188e+02, Y0: 76.869, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13290, Loss: 2.855e+02, Y0: 74.691, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13300, Loss: 6.837e+01, Y0: 76.127, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13310, Loss: 9.591e+01, Y0: 76.789, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13320, Loss: 1.086e+02, Y0: 75.797, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13330, Loss: 3.527e+02, Y0: 78.091, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13340, Loss: 2.236e+02, Y0: 77.600, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13350, Loss: 1.527e+02, Y0: 75.439, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13360, Loss: 1.978e+02, Y0: 77.514, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13370, Loss: 9.998e+01, Y0: 75.721, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 13380, Loss: 8.191e+01, Y0: 76.823, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 13390, Loss: 1.196e+02, Y0: 77.115, Learning Rate: 1.000e-03, Time: 0.89s\n",
      "Epoch: 13400, Loss: 7.888e+01, Y0: 76.801, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13410, Loss: 1.425e+02, Y0: 77.106, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13420, Loss: 7.042e+01, Y0: 76.674, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13430, Loss: 9.730e+01, Y0: 76.218, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13440, Loss: 4.857e+02, Y0: 74.328, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13450, Loss: 1.294e+02, Y0: 75.738, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13460, Loss: 2.930e+02, Y0: 77.564, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13470, Loss: 1.354e+02, Y0: 76.161, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13480, Loss: 2.126e+02, Y0: 75.134, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13490, Loss: 2.219e+02, Y0: 77.516, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13500, Loss: 8.055e+01, Y0: 75.852, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13510, Loss: 9.801e+01, Y0: 76.937, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13520, Loss: 8.787e+01, Y0: 75.752, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13530, Loss: 8.514e+01, Y0: 76.092, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13540, Loss: 2.750e+02, Y0: 77.798, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13550, Loss: 7.145e+01, Y0: 76.313, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13560, Loss: 1.383e+02, Y0: 77.288, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 13570, Loss: 1.147e+02, Y0: 77.198, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 13580, Loss: 2.206e+02, Y0: 77.391, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 13590, Loss: 2.155e+02, Y0: 75.125, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13600, Loss: 1.800e+02, Y0: 77.213, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13610, Loss: 3.690e+02, Y0: 77.852, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13620, Loss: 3.880e+02, Y0: 74.392, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13630, Loss: 1.327e+02, Y0: 75.701, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13640, Loss: 9.775e+01, Y0: 76.681, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13650, Loss: 3.121e+02, Y0: 74.892, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13660, Loss: 2.207e+02, Y0: 75.098, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13670, Loss: 1.457e+02, Y0: 77.230, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13680, Loss: 1.582e+02, Y0: 75.422, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13690, Loss: 5.104e+02, Y0: 74.177, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 13700, Loss: 3.969e+02, Y0: 74.568, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13710, Loss: 8.510e+01, Y0: 76.179, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13720, Loss: 1.416e+02, Y0: 77.256, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 13730, Loss: 1.039e+02, Y0: 75.650, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13740, Loss: 6.424e+01, Y0: 76.648, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13750, Loss: 9.121e+01, Y0: 75.856, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 13760, Loss: 2.139e+02, Y0: 77.548, Learning Rate: 1.000e-03, Time: 0.89s\n",
      "Epoch: 13770, Loss: 1.267e+02, Y0: 75.792, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13780, Loss: 1.218e+02, Y0: 77.075, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13790, Loss: 8.430e+01, Y0: 76.666, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13800, Loss: 7.910e+01, Y0: 76.255, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13810, Loss: 1.496e+02, Y0: 75.465, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13820, Loss: 3.605e+02, Y0: 78.052, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13830, Loss: 8.921e+01, Y0: 75.882, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13840, Loss: 1.643e+02, Y0: 75.593, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 13850, Loss: 2.278e+02, Y0: 77.568, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13860, Loss: 2.788e+02, Y0: 74.821, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13870, Loss: 6.462e+01, Y0: 76.389, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13880, Loss: 1.146e+02, Y0: 77.106, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 13890, Loss: 1.669e+02, Y0: 75.319, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13900, Loss: 1.239e+02, Y0: 77.204, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13910, Loss: 7.100e+01, Y0: 76.014, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13920, Loss: 8.470e+01, Y0: 76.213, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13930, Loss: 1.720e+02, Y0: 77.565, Learning Rate: 1.000e-03, Time: 0.71s\n",
      "Epoch: 13940, Loss: 3.939e+02, Y0: 74.589, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 13950, Loss: 8.130e+01, Y0: 76.644, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 13960, Loss: 9.909e+01, Y0: 75.855, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13970, Loss: 9.203e+01, Y0: 76.753, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 13980, Loss: 1.048e+02, Y0: 75.764, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 13990, Loss: 6.045e+01, Y0: 76.196, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14000, Loss: 5.644e+02, Y0: 74.228, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14010, Loss: 2.787e+02, Y0: 74.791, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14020, Loss: 2.883e+02, Y0: 77.650, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14030, Loss: 4.031e+02, Y0: 78.003, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14040, Loss: 2.635e+02, Y0: 77.695, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14050, Loss: 8.023e+01, Y0: 75.889, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14060, Loss: 6.554e+01, Y0: 76.327, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14070, Loss: 6.387e+01, Y0: 76.203, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14080, Loss: 5.758e+01, Y0: 76.573, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14090, Loss: 6.038e+01, Y0: 76.513, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14100, Loss: 8.836e+01, Y0: 76.028, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 14110, Loss: 8.373e+01, Y0: 75.853, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14120, Loss: 8.568e+01, Y0: 76.827, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 14130, Loss: 1.677e+02, Y0: 77.629, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 14140, Loss: 2.010e+02, Y0: 75.287, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 14150, Loss: 3.167e+02, Y0: 78.016, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14160, Loss: 3.985e+02, Y0: 74.439, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14170, Loss: 5.868e+01, Y0: 76.197, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14180, Loss: 1.015e+02, Y0: 77.165, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14190, Loss: 2.271e+02, Y0: 75.137, Learning Rate: 1.000e-03, Time: 0.65s\n",
      "Epoch: 14200, Loss: 1.775e+02, Y0: 75.166, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 14210, Loss: 3.133e+02, Y0: 77.698, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14220, Loss: 4.871e+02, Y0: 78.025, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 14230, Loss: 2.110e+02, Y0: 77.292, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14240, Loss: 7.283e+01, Y0: 75.986, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14250, Loss: 6.058e+01, Y0: 76.189, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14260, Loss: 7.001e+01, Y0: 76.703, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14270, Loss: 5.991e+01, Y0: 76.197, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14280, Loss: 6.744e+01, Y0: 76.223, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14290, Loss: 6.265e+01, Y0: 76.203, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14300, Loss: 4.946e+01, Y0: 76.427, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 14310, Loss: 1.380e+02, Y0: 75.608, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 14320, Loss: 1.700e+02, Y0: 77.689, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 14330, Loss: 2.596e+02, Y0: 75.052, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14340, Loss: 5.343e+01, Y0: 76.401, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14350, Loss: 1.185e+02, Y0: 77.248, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14360, Loss: 6.153e+01, Y0: 76.508, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14370, Loss: 5.459e+02, Y0: 74.091, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14380, Loss: 1.445e+02, Y0: 75.748, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14390, Loss: 8.229e+01, Y0: 76.841, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14400, Loss: 1.166e+02, Y0: 75.689, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14410, Loss: 2.844e+02, Y0: 77.811, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14420, Loss: 3.551e+02, Y0: 74.716, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14430, Loss: 3.064e+02, Y0: 77.284, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14440, Loss: 8.428e+02, Y0: 78.975, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 14450, Loss: 1.726e+02, Y0: 76.919, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14460, Loss: 1.768e+02, Y0: 76.855, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14470, Loss: 6.248e+01, Y0: 76.065, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14480, Loss: 7.724e+01, Y0: 75.767, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 14490, Loss: 5.835e+01, Y0: 76.572, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 14500, Loss: 4.510e+01, Y0: 76.352, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 14510, Loss: 5.267e+01, Y0: 76.306, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14520, Loss: 4.559e+01, Y0: 76.450, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14530, Loss: 5.988e+01, Y0: 76.153, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14540, Loss: 1.539e+02, Y0: 77.585, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14550, Loss: 5.633e+01, Y0: 76.225, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 14560, Loss: 2.879e+02, Y0: 76.224, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14570, Loss: 6.252e+01, Y0: 76.212, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14580, Loss: 1.732e+02, Y0: 77.451, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14590, Loss: 3.933e+02, Y0: 74.523, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14600, Loss: 1.053e+02, Y0: 75.892, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14610, Loss: 4.073e+02, Y0: 78.163, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14620, Loss: 2.040e+02, Y0: 77.486, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 14630, Loss: 1.428e+02, Y0: 75.289, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14640, Loss: 1.683e+02, Y0: 75.228, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14650, Loss: 5.448e+01, Y0: 76.178, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 14660, Loss: 5.590e+01, Y0: 76.166, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 14670, Loss: 5.529e+01, Y0: 76.324, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 14680, Loss: 1.224e+02, Y0: 77.313, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 14690, Loss: 1.791e+02, Y0: 75.263, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 14700, Loss: 1.143e+02, Y0: 77.332, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14710, Loss: 9.144e+01, Y0: 75.873, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14720, Loss: 1.848e+02, Y0: 77.666, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 14730, Loss: 5.946e+01, Y0: 76.038, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14740, Loss: 2.310e+02, Y0: 77.722, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14750, Loss: 1.357e+02, Y0: 75.414, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14760, Loss: 1.336e+02, Y0: 77.120, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14770, Loss: 1.296e+02, Y0: 77.331, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14780, Loss: 2.575e+02, Y0: 74.907, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14790, Loss: 7.094e+01, Y0: 76.246, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14800, Loss: 3.000e+02, Y0: 77.998, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14810, Loss: 9.486e+01, Y0: 76.302, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14820, Loss: 8.848e+01, Y0: 75.994, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14830, Loss: 7.722e+01, Y0: 76.987, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14840, Loss: 5.122e+01, Y0: 76.221, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14850, Loss: 4.745e+01, Y0: 76.712, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14860, Loss: 6.123e+01, Y0: 76.896, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 14870, Loss: 7.347e+01, Y0: 77.054, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 14880, Loss: 9.559e+01, Y0: 77.184, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 14890, Loss: 9.629e+01, Y0: 75.958, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 14900, Loss: 3.533e+02, Y0: 74.708, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14910, Loss: 1.213e+02, Y0: 77.082, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14920, Loss: 1.837e+02, Y0: 77.420, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14930, Loss: 6.000e+01, Y0: 76.659, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14940, Loss: 2.328e+02, Y0: 75.030, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14950, Loss: 5.408e+01, Y0: 76.382, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14960, Loss: 1.103e+02, Y0: 77.089, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 14970, Loss: 1.030e+02, Y0: 75.820, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 14980, Loss: 7.047e+01, Y0: 76.043, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 14990, Loss: 5.901e+01, Y0: 76.898, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15000, Loss: 6.350e+01, Y0: 76.886, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15010, Loss: 1.658e+02, Y0: 75.559, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15020, Loss: 6.471e+02, Y0: 78.529, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15030, Loss: 7.717e+01, Y0: 76.692, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15040, Loss: 2.351e+02, Y0: 75.231, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 15050, Loss: 9.748e+01, Y0: 76.654, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 15060, Loss: 1.945e+02, Y0: 77.395, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 15070, Loss: 1.830e+02, Y0: 75.386, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15080, Loss: 4.008e+02, Y0: 74.484, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15090, Loss: 8.282e+01, Y0: 76.124, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15100, Loss: 7.982e+01, Y0: 76.079, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15110, Loss: 1.003e+02, Y0: 76.866, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15120, Loss: 6.524e+01, Y0: 76.565, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15130, Loss: 8.829e+01, Y0: 75.819, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 15140, Loss: 6.174e+01, Y0: 76.362, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15150, Loss: 6.065e+01, Y0: 76.230, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15160, Loss: 4.492e+01, Y0: 76.523, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15170, Loss: 5.300e+01, Y0: 76.144, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15180, Loss: 4.293e+01, Y0: 76.563, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15190, Loss: 8.104e+01, Y0: 77.155, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15200, Loss: 5.515e+01, Y0: 76.276, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15210, Loss: 4.724e+01, Y0: 76.941, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15220, Loss: 1.082e+02, Y0: 77.414, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15230, Loss: 5.919e+01, Y0: 77.015, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 15240, Loss: 7.640e+01, Y0: 76.026, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 15250, Loss: 9.350e+01, Y0: 77.159, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 15260, Loss: 3.703e+02, Y0: 74.707, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15270, Loss: 6.558e+01, Y0: 76.295, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15280, Loss: 8.321e+01, Y0: 76.962, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15290, Loss: 9.962e+01, Y0: 75.663, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15300, Loss: 7.651e+01, Y0: 76.888, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15310, Loss: 7.338e+01, Y0: 76.279, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 15320, Loss: 5.099e+01, Y0: 76.793, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15330, Loss: 1.012e+02, Y0: 75.737, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15340, Loss: 4.361e+01, Y0: 76.684, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15350, Loss: 3.436e+02, Y0: 78.259, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15360, Loss: 2.976e+02, Y0: 74.821, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15370, Loss: 1.294e+02, Y0: 75.537, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15380, Loss: 3.660e+02, Y0: 78.068, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15390, Loss: 1.914e+02, Y0: 77.197, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15400, Loss: 7.690e+01, Y0: 76.079, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15410, Loss: 1.906e+02, Y0: 75.222, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 15420, Loss: 1.172e+02, Y0: 77.060, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 15430, Loss: 4.604e+01, Y0: 76.271, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 15440, Loss: 1.273e+02, Y0: 75.508, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15450, Loss: 2.005e+02, Y0: 77.643, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15460, Loss: 8.594e+01, Y0: 75.885, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15470, Loss: 1.075e+02, Y0: 75.682, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15480, Loss: 1.837e+02, Y0: 77.432, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15490, Loss: 1.057e+02, Y0: 75.607, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15500, Loss: 9.449e+01, Y0: 77.193, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15510, Loss: 1.973e+02, Y0: 75.235, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15520, Loss: 2.908e+02, Y0: 78.080, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15530, Loss: 8.987e+01, Y0: 75.954, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15540, Loss: 4.348e+01, Y0: 76.523, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15550, Loss: 1.496e+02, Y0: 75.445, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15560, Loss: 1.177e+02, Y0: 77.308, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15570, Loss: 9.147e+01, Y0: 75.869, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15580, Loss: 5.576e+01, Y0: 76.936, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15590, Loss: 5.791e+01, Y0: 76.926, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15600, Loss: 1.333e+02, Y0: 75.556, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 15610, Loss: 1.359e+02, Y0: 76.708, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 15620, Loss: 1.560e+02, Y0: 77.410, Learning Rate: 1.000e-03, Time: 0.79s\n",
      "Epoch: 15630, Loss: 2.949e+02, Y0: 74.861, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15640, Loss: 9.433e+01, Y0: 76.085, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15650, Loss: 4.894e+02, Y0: 75.057, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15660, Loss: 3.572e+05, Y0: 32.761, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15670, Loss: 4.231e+04, Y0: 73.685, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 15680, Loss: 2.614e+04, Y0: 69.359, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15690, Loss: 8.525e+03, Y0: 73.060, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15700, Loss: 6.559e+03, Y0: 73.945, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15710, Loss: 5.084e+03, Y0: 73.100, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15720, Loss: 4.608e+03, Y0: 72.800, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15730, Loss: 3.704e+03, Y0: 72.798, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15740, Loss: 3.344e+03, Y0: 72.361, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15750, Loss: 3.425e+03, Y0: 71.218, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15760, Loss: 2.542e+03, Y0: 70.045, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 15770, Loss: 2.299e+03, Y0: 69.911, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15780, Loss: 2.445e+03, Y0: 69.626, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15790, Loss: 1.825e+03, Y0: 69.205, Learning Rate: 1.000e-03, Time: 0.87s\n",
      "Epoch: 15800, Loss: 1.808e+03, Y0: 68.948, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 15810, Loss: 1.594e+03, Y0: 68.632, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15820, Loss: 1.732e+03, Y0: 68.137, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15830, Loss: 1.346e+03, Y0: 69.601, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 15840, Loss: 1.387e+03, Y0: 69.556, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15850, Loss: 1.477e+03, Y0: 70.408, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15860, Loss: 1.312e+03, Y0: 69.200, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15870, Loss: 1.209e+03, Y0: 70.617, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15880, Loss: 1.083e+03, Y0: 70.724, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15890, Loss: 1.157e+03, Y0: 71.137, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15900, Loss: 1.128e+03, Y0: 70.070, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15910, Loss: 1.026e+03, Y0: 71.361, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15920, Loss: 9.538e+02, Y0: 71.583, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15930, Loss: 9.358e+02, Y0: 71.280, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 15940, Loss: 1.013e+03, Y0: 72.061, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15950, Loss: 1.024e+03, Y0: 70.816, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15960, Loss: 1.281e+03, Y0: 73.639, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 15970, Loss: 9.087e+02, Y0: 70.707, Learning Rate: 1.000e-03, Time: 0.71s\n",
      "Epoch: 15980, Loss: 1.006e+03, Y0: 73.220, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 15990, Loss: 8.746e+02, Y0: 72.105, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 16000, Loss: 8.595e+02, Y0: 72.431, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16010, Loss: 7.874e+02, Y0: 71.919, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16020, Loss: 7.079e+02, Y0: 72.220, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16030, Loss: 8.672e+02, Y0: 73.408, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16040, Loss: 7.676e+02, Y0: 71.910, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16050, Loss: 6.943e+02, Y0: 72.966, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16060, Loss: 6.839e+02, Y0: 73.169, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16070, Loss: 8.604e+02, Y0: 73.086, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 16080, Loss: 6.651e+02, Y0: 72.671, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 16090, Loss: 7.095e+02, Y0: 72.677, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16100, Loss: 7.268e+02, Y0: 73.776, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16110, Loss: 6.036e+02, Y0: 73.488, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16120, Loss: 6.027e+02, Y0: 73.319, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16130, Loss: 5.891e+02, Y0: 73.145, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16140, Loss: 5.918e+02, Y0: 73.571, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16150, Loss: 5.817e+02, Y0: 73.351, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16160, Loss: 5.694e+02, Y0: 73.407, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 16170, Loss: 5.807e+02, Y0: 73.919, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 16180, Loss: 5.376e+02, Y0: 73.929, Learning Rate: 1.000e-03, Time: 0.68s\n",
      "Epoch: 16190, Loss: 5.216e+02, Y0: 74.157, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16200, Loss: 6.040e+02, Y0: 73.875, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16210, Loss: 5.112e+02, Y0: 73.672, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16220, Loss: 4.703e+02, Y0: 73.963, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16230, Loss: 5.231e+02, Y0: 73.591, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16240, Loss: 5.587e+02, Y0: 73.340, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16250, Loss: 4.937e+02, Y0: 73.880, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16260, Loss: 4.709e+02, Y0: 74.550, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16270, Loss: 4.637e+02, Y0: 74.050, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16280, Loss: 4.783e+02, Y0: 74.645, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16290, Loss: 6.157e+02, Y0: 75.306, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16300, Loss: 6.748e+02, Y0: 75.400, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 16310, Loss: 6.513e+02, Y0: 75.432, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16320, Loss: 4.224e+02, Y0: 74.499, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16330, Loss: 4.073e+02, Y0: 74.742, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16340, Loss: 4.558e+02, Y0: 75.084, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 16350, Loss: 4.956e+02, Y0: 73.358, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 16360, Loss: 3.898e+02, Y0: 74.654, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 16370, Loss: 3.871e+02, Y0: 74.441, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 16380, Loss: 3.762e+02, Y0: 74.517, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16390, Loss: 4.078e+02, Y0: 73.998, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16400, Loss: 5.015e+02, Y0: 73.611, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 16410, Loss: 4.495e+02, Y0: 75.302, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16420, Loss: 5.639e+02, Y0: 75.476, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 16430, Loss: 3.844e+02, Y0: 75.096, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16440, Loss: 3.438e+02, Y0: 74.434, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16450, Loss: 3.349e+02, Y0: 74.845, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16460, Loss: 3.323e+02, Y0: 75.087, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16470, Loss: 3.256e+02, Y0: 75.124, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16480, Loss: 4.040e+02, Y0: 74.211, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16490, Loss: 3.840e+02, Y0: 75.377, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16500, Loss: 4.483e+02, Y0: 75.507, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16510, Loss: 5.123e+02, Y0: 75.935, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16520, Loss: 3.788e+02, Y0: 75.440, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16530, Loss: 3.058e+02, Y0: 74.529, Learning Rate: 1.000e-03, Time: 0.79s\n",
      "Epoch: 16540, Loss: 3.576e+02, Y0: 74.889, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 16550, Loss: 3.034e+02, Y0: 75.200, Learning Rate: 1.000e-03, Time: 0.73s\n",
      "Epoch: 16560, Loss: 3.459e+02, Y0: 75.412, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16570, Loss: 2.838e+02, Y0: 75.127, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 16580, Loss: 3.632e+02, Y0: 74.393, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16590, Loss: 3.866e+02, Y0: 75.865, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16600, Loss: 3.773e+02, Y0: 75.660, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16610, Loss: 2.597e+02, Y0: 75.279, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16620, Loss: 6.153e+02, Y0: 76.844, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16630, Loss: 3.048e+02, Y0: 74.605, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16640, Loss: 2.564e+02, Y0: 75.322, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 16650, Loss: 2.896e+02, Y0: 75.613, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16660, Loss: 2.784e+02, Y0: 75.082, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16670, Loss: 2.720e+02, Y0: 74.799, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16680, Loss: 2.804e+02, Y0: 74.585, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16690, Loss: 2.548e+02, Y0: 74.731, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 16700, Loss: 2.362e+02, Y0: 75.200, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16710, Loss: 2.781e+02, Y0: 75.790, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16720, Loss: 2.786e+02, Y0: 74.590, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 16730, Loss: 3.825e+02, Y0: 76.468, Learning Rate: 1.000e-03, Time: 0.88s\n",
      "Epoch: 16740, Loss: 3.989e+02, Y0: 74.219, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 16750, Loss: 2.658e+02, Y0: 75.636, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 16760, Loss: 3.147e+02, Y0: 74.899, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16770, Loss: 2.949e+02, Y0: 74.646, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16780, Loss: 2.257e+02, Y0: 75.698, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16790, Loss: 3.880e+02, Y0: 74.062, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16800, Loss: 2.953e+02, Y0: 75.849, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16810, Loss: 2.348e+02, Y0: 75.085, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16820, Loss: 2.723e+02, Y0: 74.936, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16830, Loss: 2.770e+02, Y0: 76.015, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16840, Loss: 2.419e+02, Y0: 74.953, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16850, Loss: 2.487e+02, Y0: 74.853, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16860, Loss: 4.458e+02, Y0: 76.705, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16870, Loss: 2.335e+02, Y0: 75.741, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 16880, Loss: 2.081e+02, Y0: 75.842, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16890, Loss: 2.099e+02, Y0: 75.488, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16900, Loss: 2.186e+02, Y0: 75.355, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 16910, Loss: 5.039e+02, Y0: 74.069, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 16920, Loss: 2.885e+02, Y0: 75.977, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 16930, Loss: 2.599e+02, Y0: 74.832, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16940, Loss: 3.373e+02, Y0: 75.969, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16950, Loss: 2.154e+02, Y0: 75.324, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 16960, Loss: 3.658e+02, Y0: 73.911, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16970, Loss: 3.106e+02, Y0: 76.483, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 16980, Loss: 2.226e+02, Y0: 75.149, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 16990, Loss: 2.855e+02, Y0: 76.425, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17000, Loss: 1.759e+02, Y0: 75.567, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17010, Loss: 2.102e+02, Y0: 75.241, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17020, Loss: 3.061e+02, Y0: 76.620, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 17030, Loss: 2.691e+02, Y0: 74.878, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17040, Loss: 3.384e+02, Y0: 76.672, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17050, Loss: 1.934e+02, Y0: 75.273, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17060, Loss: 2.049e+02, Y0: 75.227, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17070, Loss: 3.971e+02, Y0: 76.822, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 17080, Loss: 2.156e+02, Y0: 75.832, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17090, Loss: 3.422e+02, Y0: 74.261, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 17100, Loss: 1.764e+02, Y0: 75.274, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 17110, Loss: 1.654e+02, Y0: 75.767, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 17120, Loss: 3.632e+02, Y0: 74.342, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17130, Loss: 2.709e+02, Y0: 74.679, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17140, Loss: 2.252e+02, Y0: 76.362, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17150, Loss: 1.550e+02, Y0: 75.403, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17160, Loss: 2.025e+02, Y0: 75.304, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17170, Loss: 3.657e+02, Y0: 76.964, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17180, Loss: 2.166e+02, Y0: 74.984, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17190, Loss: 2.802e+02, Y0: 74.887, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17200, Loss: 3.848e+02, Y0: 76.996, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17210, Loss: 2.070e+02, Y0: 74.948, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17220, Loss: 1.513e+02, Y0: 75.606, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17230, Loss: 7.480e+02, Y0: 75.052, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17240, Loss: 3.379e+02, Y0: 76.840, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17250, Loss: 2.490e+02, Y0: 74.850, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17260, Loss: 1.502e+02, Y0: 75.759, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17270, Loss: 3.189e+02, Y0: 76.672, Learning Rate: 1.000e-03, Time: 0.66s\n",
      "Epoch: 17280, Loss: 3.102e+02, Y0: 74.658, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 17290, Loss: 1.351e+02, Y0: 75.583, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 17300, Loss: 1.466e+02, Y0: 75.981, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17310, Loss: 1.434e+02, Y0: 76.014, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17320, Loss: 1.489e+02, Y0: 75.761, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17330, Loss: 1.544e+02, Y0: 75.487, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17340, Loss: 3.107e+02, Y0: 76.979, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17350, Loss: 2.154e+02, Y0: 74.947, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17360, Loss: 3.930e+02, Y0: 77.302, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17370, Loss: 1.734e+02, Y0: 75.113, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17380, Loss: 3.060e+02, Y0: 74.731, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17390, Loss: 1.939e+02, Y0: 75.883, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17400, Loss: 1.306e+02, Y0: 75.513, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17410, Loss: 2.163e+02, Y0: 74.962, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17420, Loss: 1.458e+02, Y0: 76.191, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17430, Loss: 3.969e+02, Y0: 74.439, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17440, Loss: 1.334e+02, Y0: 75.970, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17450, Loss: 1.427e+02, Y0: 76.281, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17460, Loss: 1.117e+02, Y0: 76.160, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 17470, Loss: 2.704e+02, Y0: 74.829, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 17480, Loss: 2.369e+02, Y0: 76.765, Learning Rate: 1.000e-03, Time: 0.76s\n",
      "Epoch: 17490, Loss: 1.705e+02, Y0: 75.283, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17500, Loss: 1.208e+02, Y0: 76.019, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17510, Loss: 1.201e+02, Y0: 75.763, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17520, Loss: 2.601e+02, Y0: 74.915, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17530, Loss: 1.639e+02, Y0: 76.502, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17540, Loss: 2.079e+02, Y0: 76.819, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17550, Loss: 2.065e+02, Y0: 74.933, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17560, Loss: 2.022e+02, Y0: 76.705, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17570, Loss: 1.551e+02, Y0: 75.193, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17580, Loss: 2.027e+02, Y0: 76.777, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17590, Loss: 1.137e+02, Y0: 75.830, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17600, Loss: 3.360e+02, Y0: 77.213, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17610, Loss: 2.232e+02, Y0: 75.020, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17620, Loss: 2.817e+02, Y0: 77.196, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17630, Loss: 1.933e+02, Y0: 75.022, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17640, Loss: 1.661e+02, Y0: 76.777, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17650, Loss: 2.045e+02, Y0: 75.391, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 17660, Loss: 1.495e+02, Y0: 76.070, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 17670, Loss: 1.292e+02, Y0: 75.587, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 17680, Loss: 1.200e+02, Y0: 76.258, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17690, Loss: 1.879e+02, Y0: 74.670, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 17700, Loss: 2.946e+02, Y0: 76.920, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17710, Loss: 1.062e+02, Y0: 75.548, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 17720, Loss: 1.270e+02, Y0: 75.690, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17730, Loss: 9.728e+01, Y0: 75.963, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17740, Loss: 2.757e+02, Y0: 76.944, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17750, Loss: 3.616e+02, Y0: 74.647, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17760, Loss: 1.210e+02, Y0: 76.071, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17770, Loss: 1.620e+02, Y0: 76.886, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17780, Loss: 1.665e+02, Y0: 75.313, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17790, Loss: 1.185e+02, Y0: 76.016, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17800, Loss: 2.004e+02, Y0: 75.241, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17810, Loss: 2.587e+02, Y0: 76.526, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17820, Loss: 1.762e+02, Y0: 74.831, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17830, Loss: 2.189e+02, Y0: 74.934, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 17840, Loss: 1.094e+02, Y0: 75.931, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 17850, Loss: 1.165e+02, Y0: 76.439, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 17860, Loss: 9.448e+01, Y0: 75.883, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17870, Loss: 1.273e+02, Y0: 75.559, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17880, Loss: 1.186e+02, Y0: 76.493, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17890, Loss: 1.368e+02, Y0: 75.720, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17900, Loss: 1.101e+02, Y0: 75.698, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17910, Loss: 2.219e+02, Y0: 75.213, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17920, Loss: 5.082e+02, Y0: 77.352, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 17930, Loss: 3.067e+02, Y0: 77.258, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17940, Loss: 1.599e+02, Y0: 75.766, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 17950, Loss: 1.148e+02, Y0: 76.472, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17960, Loss: 1.183e+02, Y0: 75.772, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 17970, Loss: 2.977e+02, Y0: 77.109, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 17980, Loss: 1.324e+02, Y0: 75.974, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 17990, Loss: 3.326e+02, Y0: 76.143, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18000, Loss: 1.325e+02, Y0: 75.128, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18010, Loss: 1.278e+02, Y0: 75.695, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 18020, Loss: 1.305e+02, Y0: 76.279, Learning Rate: 1.000e-03, Time: 0.84s\n",
      "Epoch: 18030, Loss: 1.770e+02, Y0: 75.139, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 18040, Loss: 1.006e+02, Y0: 76.469, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 18050, Loss: 8.472e+01, Y0: 76.421, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18060, Loss: 1.324e+02, Y0: 76.707, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18070, Loss: 7.536e+01, Y0: 76.178, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18080, Loss: 9.634e+01, Y0: 75.764, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18090, Loss: 5.605e+02, Y0: 74.002, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18100, Loss: 2.311e+02, Y0: 74.703, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18110, Loss: 2.509e+02, Y0: 76.744, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18120, Loss: 3.867e+02, Y0: 77.701, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18130, Loss: 1.001e+02, Y0: 75.787, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18140, Loss: 8.847e+01, Y0: 75.952, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18150, Loss: 9.724e+01, Y0: 76.400, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18160, Loss: 1.800e+02, Y0: 76.874, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18170, Loss: 1.666e+02, Y0: 75.498, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18180, Loss: 1.924e+02, Y0: 76.838, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18190, Loss: 1.419e+02, Y0: 75.481, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18200, Loss: 7.999e+01, Y0: 75.904, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 18210, Loss: 9.060e+01, Y0: 76.575, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 18220, Loss: 1.433e+02, Y0: 76.782, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 18230, Loss: 8.528e+01, Y0: 76.399, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18240, Loss: 3.169e+02, Y0: 76.953, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18250, Loss: 1.019e+02, Y0: 75.554, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18260, Loss: 8.939e+01, Y0: 76.471, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18270, Loss: 1.036e+02, Y0: 76.558, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18280, Loss: 2.065e+02, Y0: 76.740, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18290, Loss: 2.347e+02, Y0: 74.750, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18300, Loss: 9.641e+01, Y0: 76.484, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18310, Loss: 5.898e+02, Y0: 76.460, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18320, Loss: 2.653e+02, Y0: 77.239, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18330, Loss: 2.192e+02, Y0: 77.039, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18340, Loss: 1.009e+02, Y0: 75.659, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18350, Loss: 1.063e+02, Y0: 76.250, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18360, Loss: 9.871e+01, Y0: 75.445, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 18370, Loss: 7.743e+01, Y0: 76.091, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18380, Loss: 9.400e+01, Y0: 75.736, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18390, Loss: 6.684e+01, Y0: 75.714, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 18400, Loss: 8.512e+01, Y0: 76.494, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 18410, Loss: 6.821e+01, Y0: 76.119, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 18420, Loss: 4.566e+02, Y0: 74.290, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18430, Loss: 1.339e+02, Y0: 75.338, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18440, Loss: 2.010e+02, Y0: 76.682, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18450, Loss: 7.954e+01, Y0: 76.291, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 18460, Loss: 1.240e+02, Y0: 76.062, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18470, Loss: 1.571e+02, Y0: 75.248, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18480, Loss: 8.067e+01, Y0: 76.360, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18490, Loss: 2.448e+02, Y0: 77.071, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 18500, Loss: 3.833e+02, Y0: 74.637, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18510, Loss: 1.107e+02, Y0: 75.524, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18520, Loss: 1.482e+02, Y0: 76.882, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18530, Loss: 2.768e+02, Y0: 75.279, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18540, Loss: 1.366e+02, Y0: 76.876, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18550, Loss: 1.012e+02, Y0: 75.813, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18560, Loss: 1.722e+02, Y0: 76.996, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18570, Loss: 1.040e+02, Y0: 75.784, Learning Rate: 1.000e-03, Time: 0.69s\n",
      "Epoch: 18580, Loss: 1.096e+02, Y0: 76.213, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 18590, Loss: 3.867e+02, Y0: 77.540, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 18600, Loss: 1.496e+02, Y0: 75.198, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18610, Loss: 7.220e+01, Y0: 76.310, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18620, Loss: 8.644e+01, Y0: 76.238, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18630, Loss: 8.287e+01, Y0: 75.946, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18640, Loss: 6.328e+01, Y0: 76.319, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 18650, Loss: 8.451e+01, Y0: 76.383, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18660, Loss: 1.792e+02, Y0: 75.074, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18670, Loss: 7.960e+01, Y0: 76.612, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18680, Loss: 1.671e+02, Y0: 75.160, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18690, Loss: 1.115e+02, Y0: 76.823, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18700, Loss: 3.999e+02, Y0: 74.502, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18710, Loss: 3.363e+02, Y0: 77.573, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18720, Loss: 1.473e+02, Y0: 77.215, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18730, Loss: 2.241e+02, Y0: 75.157, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18740, Loss: 2.099e+02, Y0: 76.843, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18750, Loss: 1.672e+02, Y0: 77.067, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18760, Loss: 1.426e+02, Y0: 75.359, Learning Rate: 1.000e-03, Time: 0.75s\n",
      "Epoch: 18770, Loss: 7.357e+01, Y0: 76.460, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 18780, Loss: 7.980e+01, Y0: 75.778, Learning Rate: 1.000e-03, Time: 0.74s\n",
      "Epoch: 18790, Loss: 1.069e+02, Y0: 76.451, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18800, Loss: 1.125e+02, Y0: 75.850, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18810, Loss: 8.847e+01, Y0: 76.415, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18820, Loss: 2.608e+02, Y0: 77.406, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18830, Loss: 3.186e+02, Y0: 74.892, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18840, Loss: 7.384e+01, Y0: 76.355, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18850, Loss: 2.458e+02, Y0: 74.756, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18860, Loss: 9.828e+01, Y0: 76.605, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18870, Loss: 1.031e+02, Y0: 75.414, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18880, Loss: 6.822e+01, Y0: 76.391, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 18890, Loss: 1.837e+02, Y0: 75.095, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18900, Loss: 6.728e+01, Y0: 76.223, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 18910, Loss: 2.181e+02, Y0: 77.134, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18920, Loss: 1.597e+02, Y0: 75.481, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18930, Loss: 1.618e+02, Y0: 77.023, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 18940, Loss: 1.540e+02, Y0: 75.435, Learning Rate: 1.000e-03, Time: 0.64s\n",
      "Epoch: 18950, Loss: 8.337e+01, Y0: 76.819, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 18960, Loss: 7.604e+01, Y0: 76.594, Learning Rate: 1.000e-03, Time: 0.91s\n",
      "Epoch: 18970, Loss: 5.719e+01, Y0: 76.292, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 18980, Loss: 2.380e+02, Y0: 77.420, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 18990, Loss: 2.872e+02, Y0: 74.717, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19000, Loss: 3.546e+02, Y0: 77.704, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 19010, Loss: 7.903e+01, Y0: 76.931, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19020, Loss: 7.451e+01, Y0: 75.659, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 19030, Loss: 1.151e+02, Y0: 75.390, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19040, Loss: 1.595e+02, Y0: 76.850, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 19050, Loss: 1.716e+02, Y0: 75.038, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 19060, Loss: 9.919e+01, Y0: 76.714, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19070, Loss: 6.357e+01, Y0: 76.015, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19080, Loss: 1.323e+02, Y0: 76.627, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19090, Loss: 6.703e+01, Y0: 76.497, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19100, Loss: 8.548e+01, Y0: 75.736, Learning Rate: 1.000e-03, Time: 0.63s\n",
      "Epoch: 19110, Loss: 7.192e+01, Y0: 76.577, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19120, Loss: 7.101e+01, Y0: 75.991, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19130, Loss: 7.184e+01, Y0: 76.122, Learning Rate: 1.000e-03, Time: 0.80s\n",
      "Epoch: 19140, Loss: 2.924e+02, Y0: 74.655, Learning Rate: 1.000e-03, Time: 0.83s\n",
      "Epoch: 19150, Loss: 3.213e+02, Y0: 77.721, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 19160, Loss: 9.195e+01, Y0: 75.773, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19170, Loss: 6.244e+01, Y0: 75.777, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19180, Loss: 1.098e+02, Y0: 75.666, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 19190, Loss: 1.121e+02, Y0: 75.767, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19200, Loss: 2.802e+02, Y0: 77.413, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19210, Loss: 1.728e+02, Y0: 75.343, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19220, Loss: 1.049e+02, Y0: 76.916, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19230, Loss: 9.243e+01, Y0: 75.938, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 19240, Loss: 1.154e+02, Y0: 75.394, Learning Rate: 1.000e-03, Time: 0.56s\n",
      "Epoch: 19250, Loss: 2.250e+02, Y0: 77.120, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19260, Loss: 1.166e+02, Y0: 75.527, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19270, Loss: 5.393e+01, Y0: 76.237, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19280, Loss: 7.657e+01, Y0: 76.161, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19290, Loss: 8.484e+01, Y0: 76.002, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19300, Loss: 1.276e+02, Y0: 77.366, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19310, Loss: 1.581e+02, Y0: 75.464, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19320, Loss: 1.702e+02, Y0: 77.216, Learning Rate: 1.000e-03, Time: 0.85s\n",
      "Epoch: 19330, Loss: 1.312e+02, Y0: 75.370, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 19340, Loss: 4.954e+01, Y0: 76.401, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19350, Loss: 1.852e+02, Y0: 75.058, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19360, Loss: 1.801e+02, Y0: 77.214, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19370, Loss: 2.571e+02, Y0: 75.107, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19380, Loss: 2.170e+02, Y0: 77.354, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19390, Loss: 7.190e+01, Y0: 76.263, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19400, Loss: 1.101e+02, Y0: 75.428, Learning Rate: 1.000e-03, Time: 0.61s\n",
      "Epoch: 19410, Loss: 5.626e+01, Y0: 76.290, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19420, Loss: 1.054e+02, Y0: 75.618, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19430, Loss: 9.972e+01, Y0: 75.454, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19440, Loss: 2.936e+02, Y0: 77.128, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19450, Loss: 7.761e+01, Y0: 75.989, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19460, Loss: 5.635e+01, Y0: 76.184, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19470, Loss: 7.784e+01, Y0: 76.719, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19480, Loss: 6.479e+01, Y0: 76.431, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19490, Loss: 1.486e+02, Y0: 75.010, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19500, Loss: 1.810e+02, Y0: 76.941, Learning Rate: 1.000e-03, Time: 0.70s\n",
      "Epoch: 19510, Loss: 1.228e+02, Y0: 75.496, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 19520, Loss: 5.085e+01, Y0: 76.661, Learning Rate: 1.000e-03, Time: 0.81s\n",
      "Epoch: 19530, Loss: 6.315e+01, Y0: 76.673, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19540, Loss: 5.959e+01, Y0: 76.277, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 19550, Loss: 1.326e+02, Y0: 75.224, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19560, Loss: 6.189e+01, Y0: 76.825, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19570, Loss: 4.847e+01, Y0: 76.291, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19580, Loss: 1.430e+02, Y0: 75.169, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19590, Loss: 2.980e+02, Y0: 77.515, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19600, Loss: 1.310e+02, Y0: 75.870, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19610, Loss: 8.003e+01, Y0: 76.609, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19620, Loss: 8.426e+01, Y0: 76.737, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19630, Loss: 4.704e+01, Y0: 76.375, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19640, Loss: 8.949e+01, Y0: 76.923, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19650, Loss: 3.600e+02, Y0: 74.437, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19660, Loss: 1.535e+02, Y0: 77.009, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19670, Loss: 5.761e+01, Y0: 76.567, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19680, Loss: 6.231e+01, Y0: 76.494, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19690, Loss: 1.862e+02, Y0: 74.916, Learning Rate: 1.000e-03, Time: 0.78s\n",
      "Epoch: 19700, Loss: 2.525e+02, Y0: 77.609, Learning Rate: 1.000e-03, Time: 0.82s\n",
      "Epoch: 19710, Loss: 2.542e+02, Y0: 74.955, Learning Rate: 1.000e-03, Time: 0.72s\n",
      "Epoch: 19720, Loss: 7.121e+01, Y0: 76.275, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19730, Loss: 2.511e+02, Y0: 77.494, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19740, Loss: 2.727e+02, Y0: 74.993, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19750, Loss: 1.285e+02, Y0: 77.304, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19760, Loss: 5.362e+01, Y0: 76.215, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19770, Loss: 9.251e+01, Y0: 76.610, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19780, Loss: 7.148e+01, Y0: 75.711, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19790, Loss: 6.357e+01, Y0: 76.508, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19800, Loss: 8.598e+01, Y0: 76.760, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19810, Loss: 9.437e+01, Y0: 77.172, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19820, Loss: 1.835e+02, Y0: 75.398, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19830, Loss: 2.223e+02, Y0: 77.466, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19840, Loss: 7.959e+01, Y0: 76.002, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19850, Loss: 2.681e+02, Y0: 77.415, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19860, Loss: 2.992e+02, Y0: 74.793, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 19870, Loss: 5.073e+01, Y0: 76.404, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19880, Loss: 7.328e+01, Y0: 76.842, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 19890, Loss: 2.694e+02, Y0: 74.980, Learning Rate: 1.000e-03, Time: 0.86s\n",
      "Epoch: 19900, Loss: 1.513e+02, Y0: 76.931, Learning Rate: 1.000e-03, Time: 0.60s\n",
      "Epoch: 19910, Loss: 5.818e+01, Y0: 76.087, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19920, Loss: 6.289e+01, Y0: 76.397, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19930, Loss: 5.528e+01, Y0: 76.116, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19940, Loss: 2.149e+02, Y0: 77.395, Learning Rate: 1.000e-03, Time: 0.58s\n",
      "Epoch: 19950, Loss: 2.167e+02, Y0: 75.411, Learning Rate: 1.000e-03, Time: 0.59s\n",
      "Epoch: 19960, Loss: 2.242e+02, Y0: 77.628, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19970, Loss: 5.263e+01, Y0: 76.052, Learning Rate: 1.000e-03, Time: 0.62s\n",
      "Epoch: 19980, Loss: 4.611e+01, Y0: 75.978, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 19990, Loss: 4.713e+01, Y0: 76.151, Learning Rate: 1.000e-03, Time: 0.57s\n",
      "Epoch: 0, Loss: 4.597e+01, Y0: 76.410, Learning Rate: 1.000e-04, Time: 0.06s\n",
      "Epoch: 10, Loss: 4.453e+01, Y0: 76.359, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20, Loss: 4.203e+01, Y0: 76.451, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 30, Loss: 6.035e+01, Y0: 76.422, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 40, Loss: 4.024e+01, Y0: 76.454, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 50, Loss: 4.234e+01, Y0: 76.446, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 60, Loss: 5.884e+01, Y0: 76.399, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 70, Loss: 4.467e+01, Y0: 76.452, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 80, Loss: 4.306e+01, Y0: 76.411, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 90, Loss: 4.359e+01, Y0: 76.407, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 100, Loss: 4.835e+01, Y0: 76.371, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 110, Loss: 3.577e+01, Y0: 76.386, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 120, Loss: 4.199e+01, Y0: 76.407, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 130, Loss: 4.886e+01, Y0: 76.356, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 140, Loss: 3.684e+01, Y0: 76.396, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 150, Loss: 4.025e+01, Y0: 76.427, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 160, Loss: 5.532e+01, Y0: 76.353, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 170, Loss: 4.170e+01, Y0: 76.387, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 180, Loss: 4.131e+01, Y0: 76.429, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 190, Loss: 3.993e+01, Y0: 76.343, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 200, Loss: 4.308e+01, Y0: 76.396, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 210, Loss: 4.034e+01, Y0: 76.396, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 220, Loss: 4.184e+01, Y0: 76.423, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 230, Loss: 3.983e+01, Y0: 76.411, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 240, Loss: 5.666e+01, Y0: 76.418, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 250, Loss: 3.871e+01, Y0: 76.414, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 260, Loss: 4.544e+01, Y0: 76.425, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 270, Loss: 4.283e+01, Y0: 76.410, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 280, Loss: 5.046e+01, Y0: 76.377, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 290, Loss: 4.601e+01, Y0: 76.386, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 300, Loss: 4.581e+01, Y0: 76.380, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 310, Loss: 9.151e+01, Y0: 76.384, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 320, Loss: 4.070e+01, Y0: 76.423, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 330, Loss: 4.663e+01, Y0: 76.411, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 340, Loss: 4.024e+01, Y0: 76.409, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 350, Loss: 5.797e+01, Y0: 76.395, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 360, Loss: 3.932e+01, Y0: 76.443, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 370, Loss: 3.790e+01, Y0: 76.449, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 380, Loss: 4.449e+01, Y0: 76.368, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 390, Loss: 5.966e+01, Y0: 76.427, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 400, Loss: 4.260e+01, Y0: 76.440, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 410, Loss: 4.233e+01, Y0: 76.427, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 420, Loss: 4.017e+01, Y0: 76.365, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 430, Loss: 4.574e+01, Y0: 76.386, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 440, Loss: 4.060e+01, Y0: 76.404, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 450, Loss: 3.860e+01, Y0: 76.467, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 460, Loss: 4.153e+01, Y0: 76.451, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 470, Loss: 3.737e+01, Y0: 76.422, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 480, Loss: 3.909e+01, Y0: 76.389, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 490, Loss: 4.091e+01, Y0: 76.384, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 500, Loss: 4.203e+01, Y0: 76.374, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 510, Loss: 4.243e+01, Y0: 76.395, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 520, Loss: 4.381e+01, Y0: 76.419, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 530, Loss: 3.808e+01, Y0: 76.434, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 540, Loss: 4.196e+01, Y0: 76.475, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 550, Loss: 4.077e+01, Y0: 76.508, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 560, Loss: 3.817e+01, Y0: 76.441, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 570, Loss: 3.894e+01, Y0: 76.395, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 580, Loss: 3.743e+01, Y0: 76.452, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 590, Loss: 4.356e+01, Y0: 76.478, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 600, Loss: 4.597e+01, Y0: 76.478, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 610, Loss: 3.903e+01, Y0: 76.455, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 620, Loss: 5.269e+01, Y0: 76.424, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 630, Loss: 4.296e+01, Y0: 76.498, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 640, Loss: 4.377e+01, Y0: 76.469, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 650, Loss: 4.973e+01, Y0: 76.448, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 660, Loss: 5.007e+01, Y0: 76.452, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 670, Loss: 4.365e+01, Y0: 76.421, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 680, Loss: 3.745e+01, Y0: 76.501, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 690, Loss: 4.227e+01, Y0: 76.380, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 700, Loss: 3.986e+01, Y0: 76.460, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 710, Loss: 3.897e+01, Y0: 76.420, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 720, Loss: 3.807e+01, Y0: 76.459, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 730, Loss: 4.072e+01, Y0: 76.452, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 740, Loss: 3.449e+01, Y0: 76.430, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 750, Loss: 4.350e+01, Y0: 76.423, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 760, Loss: 3.819e+01, Y0: 76.455, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 770, Loss: 3.870e+01, Y0: 76.570, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 780, Loss: 4.533e+01, Y0: 76.414, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 790, Loss: 4.447e+01, Y0: 76.437, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 800, Loss: 3.777e+01, Y0: 76.438, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 810, Loss: 3.781e+01, Y0: 76.479, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 820, Loss: 4.276e+01, Y0: 76.460, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 830, Loss: 3.930e+01, Y0: 76.472, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 840, Loss: 3.703e+01, Y0: 76.455, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 850, Loss: 4.144e+01, Y0: 76.457, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 860, Loss: 4.272e+01, Y0: 76.430, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 870, Loss: 5.090e+01, Y0: 76.444, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 880, Loss: 4.149e+01, Y0: 76.479, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 890, Loss: 3.536e+01, Y0: 76.406, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 900, Loss: 3.823e+01, Y0: 76.480, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 910, Loss: 3.508e+01, Y0: 76.447, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 920, Loss: 4.131e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 930, Loss: 3.631e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 940, Loss: 3.842e+01, Y0: 76.434, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 950, Loss: 3.989e+01, Y0: 76.488, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 960, Loss: 3.634e+01, Y0: 76.483, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 970, Loss: 3.676e+01, Y0: 76.481, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 980, Loss: 3.572e+01, Y0: 76.438, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 990, Loss: 3.782e+01, Y0: 76.518, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1000, Loss: 3.705e+01, Y0: 76.481, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 1010, Loss: 3.538e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 1020, Loss: 4.362e+01, Y0: 76.436, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 1030, Loss: 3.484e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1040, Loss: 3.726e+01, Y0: 76.509, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1050, Loss: 5.276e+01, Y0: 76.291, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1060, Loss: 4.040e+01, Y0: 76.488, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1070, Loss: 5.069e+01, Y0: 76.517, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1080, Loss: 4.337e+01, Y0: 76.601, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1090, Loss: 4.162e+01, Y0: 76.466, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1100, Loss: 4.654e+01, Y0: 76.515, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1110, Loss: 4.336e+01, Y0: 76.496, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1120, Loss: 4.247e+01, Y0: 76.438, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 1130, Loss: 5.394e+01, Y0: 76.545, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1140, Loss: 3.422e+01, Y0: 76.455, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1150, Loss: 4.701e+01, Y0: 76.484, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1160, Loss: 3.397e+01, Y0: 76.563, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1170, Loss: 3.684e+01, Y0: 76.448, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 1180, Loss: 3.805e+01, Y0: 76.485, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 1190, Loss: 3.814e+01, Y0: 76.461, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 1200, Loss: 3.487e+01, Y0: 76.497, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 1210, Loss: 3.337e+01, Y0: 76.493, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1220, Loss: 3.523e+01, Y0: 76.448, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1230, Loss: 3.613e+01, Y0: 76.494, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 1240, Loss: 3.955e+01, Y0: 76.514, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1250, Loss: 3.589e+01, Y0: 76.490, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1260, Loss: 4.117e+01, Y0: 76.421, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1270, Loss: 4.131e+01, Y0: 76.532, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1280, Loss: 3.764e+01, Y0: 76.460, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1290, Loss: 3.703e+01, Y0: 76.519, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1300, Loss: 3.681e+01, Y0: 76.551, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1310, Loss: 3.913e+01, Y0: 76.569, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1320, Loss: 4.519e+01, Y0: 76.543, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1330, Loss: 3.897e+01, Y0: 76.489, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1340, Loss: 3.474e+01, Y0: 76.485, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1350, Loss: 3.539e+01, Y0: 76.486, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1360, Loss: 3.868e+01, Y0: 76.535, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1370, Loss: 3.811e+01, Y0: 76.480, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 1380, Loss: 4.807e+01, Y0: 76.524, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 1390, Loss: 4.421e+01, Y0: 76.471, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 1400, Loss: 3.651e+01, Y0: 76.479, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1410, Loss: 3.984e+01, Y0: 76.518, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1420, Loss: 3.752e+01, Y0: 76.508, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1430, Loss: 3.793e+01, Y0: 76.506, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 1440, Loss: 3.297e+01, Y0: 76.497, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1450, Loss: 4.352e+01, Y0: 76.479, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1460, Loss: 3.521e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1470, Loss: 3.575e+01, Y0: 76.506, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1480, Loss: 3.737e+01, Y0: 76.510, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1490, Loss: 3.515e+01, Y0: 76.514, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1500, Loss: 4.006e+01, Y0: 76.486, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1510, Loss: 3.927e+01, Y0: 76.438, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1520, Loss: 4.812e+01, Y0: 76.627, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 1530, Loss: 5.109e+01, Y0: 76.475, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1540, Loss: 3.319e+01, Y0: 76.446, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1550, Loss: 3.752e+01, Y0: 76.516, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1560, Loss: 3.458e+01, Y0: 76.458, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 1570, Loss: 3.648e+01, Y0: 76.536, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 1580, Loss: 3.464e+01, Y0: 76.437, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 1590, Loss: 6.818e+01, Y0: 76.464, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1600, Loss: 3.832e+01, Y0: 76.509, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1610, Loss: 4.244e+01, Y0: 76.559, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 1620, Loss: 3.408e+01, Y0: 76.545, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1630, Loss: 3.968e+01, Y0: 76.448, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1640, Loss: 3.140e+01, Y0: 76.534, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1650, Loss: 3.633e+01, Y0: 76.534, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1660, Loss: 3.109e+01, Y0: 76.566, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1670, Loss: 3.733e+01, Y0: 76.508, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1680, Loss: 8.831e+01, Y0: 76.522, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1690, Loss: 3.488e+01, Y0: 76.459, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1700, Loss: 3.893e+01, Y0: 76.592, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1710, Loss: 4.674e+01, Y0: 76.457, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1720, Loss: 3.619e+01, Y0: 76.568, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1730, Loss: 4.041e+01, Y0: 76.430, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1740, Loss: 4.202e+01, Y0: 76.541, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 1750, Loss: 4.163e+01, Y0: 76.517, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 1760, Loss: 4.230e+01, Y0: 76.449, Learning Rate: 1.000e-04, Time: 0.89s\n",
      "Epoch: 1770, Loss: 4.027e+01, Y0: 76.529, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1780, Loss: 5.700e+01, Y0: 76.513, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1790, Loss: 4.170e+01, Y0: 76.530, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1800, Loss: 4.141e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1810, Loss: 3.620e+01, Y0: 76.532, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1820, Loss: 3.635e+01, Y0: 76.531, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1830, Loss: 4.056e+01, Y0: 76.556, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1840, Loss: 3.495e+01, Y0: 76.495, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1850, Loss: 3.554e+01, Y0: 76.567, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1860, Loss: 3.605e+01, Y0: 76.474, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 1870, Loss: 4.109e+01, Y0: 76.552, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1880, Loss: 3.413e+01, Y0: 76.605, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1890, Loss: 3.905e+01, Y0: 76.545, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1900, Loss: 3.559e+01, Y0: 76.548, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1910, Loss: 3.857e+01, Y0: 76.508, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 1920, Loss: 3.862e+01, Y0: 76.584, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 1930, Loss: 3.470e+01, Y0: 76.516, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 1940, Loss: 3.800e+01, Y0: 76.536, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 1950, Loss: 3.431e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 1960, Loss: 3.479e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 1970, Loss: 3.503e+01, Y0: 76.466, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 1980, Loss: 3.199e+01, Y0: 76.513, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 1990, Loss: 3.853e+01, Y0: 76.573, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2000, Loss: 3.298e+01, Y0: 76.483, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2010, Loss: 3.708e+01, Y0: 76.572, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2020, Loss: 3.685e+01, Y0: 76.540, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2030, Loss: 3.564e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2040, Loss: 5.387e+01, Y0: 76.536, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2050, Loss: 3.695e+01, Y0: 76.602, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2060, Loss: 3.541e+01, Y0: 76.551, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2070, Loss: 3.294e+01, Y0: 76.576, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2080, Loss: 1.151e+02, Y0: 76.486, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2090, Loss: 4.118e+01, Y0: 76.595, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2100, Loss: 3.857e+01, Y0: 76.516, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2110, Loss: 3.403e+01, Y0: 76.552, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2120, Loss: 3.735e+01, Y0: 76.570, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 2130, Loss: 3.658e+01, Y0: 76.516, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 2140, Loss: 3.129e+01, Y0: 76.563, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2150, Loss: 2.375e+02, Y0: 76.604, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2160, Loss: 3.766e+01, Y0: 76.385, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2170, Loss: 4.171e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2180, Loss: 3.528e+01, Y0: 76.529, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2190, Loss: 3.257e+01, Y0: 76.521, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2200, Loss: 7.605e+01, Y0: 76.552, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2210, Loss: 4.213e+01, Y0: 76.500, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2220, Loss: 4.133e+01, Y0: 76.714, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2230, Loss: 3.704e+01, Y0: 76.497, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2240, Loss: 3.818e+01, Y0: 76.643, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2250, Loss: 3.248e+01, Y0: 76.591, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 2260, Loss: 3.779e+01, Y0: 76.536, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2270, Loss: 3.143e+01, Y0: 76.587, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2280, Loss: 3.668e+01, Y0: 76.547, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2290, Loss: 3.103e+01, Y0: 76.546, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2300, Loss: 3.324e+01, Y0: 76.610, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 2310, Loss: 3.521e+01, Y0: 76.484, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 2320, Loss: 3.901e+01, Y0: 76.611, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 2330, Loss: 3.523e+01, Y0: 76.592, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2340, Loss: 3.924e+01, Y0: 76.538, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2350, Loss: 3.523e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2360, Loss: 3.879e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2370, Loss: 3.071e+01, Y0: 76.505, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2380, Loss: 3.692e+01, Y0: 76.605, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2390, Loss: 4.620e+01, Y0: 76.558, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2400, Loss: 3.405e+01, Y0: 76.550, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2410, Loss: 5.165e+01, Y0: 76.632, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2420, Loss: 3.502e+01, Y0: 76.521, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2430, Loss: 3.817e+01, Y0: 76.619, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2440, Loss: 6.739e+01, Y0: 76.507, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2450, Loss: 3.293e+01, Y0: 76.506, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2460, Loss: 3.542e+01, Y0: 76.575, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 2470, Loss: 3.340e+01, Y0: 76.581, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2480, Loss: 3.603e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2490, Loss: 4.005e+01, Y0: 76.671, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 2500, Loss: 3.963e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 2510, Loss: 7.342e+01, Y0: 76.487, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 2520, Loss: 3.485e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 2530, Loss: 3.714e+01, Y0: 76.543, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2540, Loss: 3.804e+01, Y0: 76.526, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2550, Loss: 2.963e+01, Y0: 76.581, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2560, Loss: 3.152e+01, Y0: 76.493, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2570, Loss: 3.457e+01, Y0: 76.600, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2580, Loss: 3.564e+01, Y0: 76.499, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2590, Loss: 3.311e+01, Y0: 76.531, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2600, Loss: 3.113e+01, Y0: 76.634, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2610, Loss: 3.975e+01, Y0: 76.506, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2620, Loss: 3.372e+01, Y0: 76.537, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2630, Loss: 4.734e+01, Y0: 76.622, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 2640, Loss: 3.187e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2650, Loss: 3.528e+01, Y0: 76.473, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2660, Loss: 3.044e+01, Y0: 76.594, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2670, Loss: 4.094e+01, Y0: 76.576, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2680, Loss: 3.280e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 2690, Loss: 3.811e+01, Y0: 76.527, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 2700, Loss: 3.754e+01, Y0: 76.682, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2710, Loss: 5.109e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2720, Loss: 4.416e+01, Y0: 76.632, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2730, Loss: 3.923e+01, Y0: 76.654, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2740, Loss: 3.631e+01, Y0: 76.564, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2750, Loss: 3.528e+01, Y0: 76.536, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 2760, Loss: 3.090e+01, Y0: 76.613, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2770, Loss: 3.664e+01, Y0: 76.631, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 2780, Loss: 3.103e+01, Y0: 76.520, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2790, Loss: 3.395e+01, Y0: 76.524, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2800, Loss: 3.559e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2810, Loss: 3.650e+01, Y0: 76.687, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 2820, Loss: 4.948e+01, Y0: 76.608, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2830, Loss: 3.459e+01, Y0: 76.598, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 2840, Loss: 3.461e+01, Y0: 76.575, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 2850, Loss: 3.709e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2860, Loss: 3.708e+01, Y0: 76.672, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 2870, Loss: 3.414e+01, Y0: 76.549, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 2880, Loss: 3.166e+01, Y0: 76.519, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 2890, Loss: 3.253e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2900, Loss: 3.564e+01, Y0: 76.551, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2910, Loss: 3.384e+01, Y0: 76.590, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 2920, Loss: 3.897e+01, Y0: 76.518, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 2930, Loss: 3.353e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2940, Loss: 3.375e+01, Y0: 76.518, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2950, Loss: 2.983e+01, Y0: 76.661, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2960, Loss: 3.603e+01, Y0: 76.544, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2970, Loss: 3.685e+01, Y0: 76.608, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 2980, Loss: 3.082e+01, Y0: 76.493, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 2990, Loss: 3.597e+01, Y0: 76.567, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3000, Loss: 3.165e+01, Y0: 76.622, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3010, Loss: 3.162e+01, Y0: 76.650, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3020, Loss: 3.375e+01, Y0: 76.600, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3030, Loss: 3.671e+01, Y0: 76.623, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3040, Loss: 3.188e+01, Y0: 76.446, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3050, Loss: 3.556e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 3060, Loss: 3.573e+01, Y0: 76.590, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 3070, Loss: 3.125e+01, Y0: 76.537, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3080, Loss: 3.231e+01, Y0: 76.565, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3090, Loss: 3.197e+01, Y0: 76.607, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3100, Loss: 4.391e+01, Y0: 76.623, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3110, Loss: 3.654e+01, Y0: 76.507, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3120, Loss: 3.123e+01, Y0: 76.596, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3130, Loss: 7.262e+01, Y0: 76.498, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3140, Loss: 3.464e+01, Y0: 76.838, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3150, Loss: 3.212e+01, Y0: 76.426, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3160, Loss: 3.620e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3170, Loss: 3.448e+01, Y0: 76.513, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3180, Loss: 3.293e+01, Y0: 76.665, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3190, Loss: 3.875e+01, Y0: 76.508, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3200, Loss: 3.542e+01, Y0: 76.610, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3210, Loss: 3.164e+01, Y0: 76.653, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3220, Loss: 3.507e+01, Y0: 76.660, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3230, Loss: 3.536e+01, Y0: 76.498, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 3240, Loss: 3.769e+01, Y0: 76.617, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 3250, Loss: 3.509e+01, Y0: 76.553, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 3260, Loss: 3.290e+01, Y0: 76.539, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3270, Loss: 3.898e+01, Y0: 76.622, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 3280, Loss: 3.125e+01, Y0: 76.659, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3290, Loss: 3.352e+01, Y0: 76.632, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3300, Loss: 3.228e+01, Y0: 76.613, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3310, Loss: 3.928e+01, Y0: 76.530, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3320, Loss: 3.463e+01, Y0: 76.587, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3330, Loss: 3.427e+01, Y0: 76.645, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3340, Loss: 3.659e+01, Y0: 76.540, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 3350, Loss: 3.359e+01, Y0: 76.525, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 3360, Loss: 2.962e+01, Y0: 76.655, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 3370, Loss: 2.976e+01, Y0: 76.517, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 3380, Loss: 3.305e+01, Y0: 76.595, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3390, Loss: 3.243e+01, Y0: 76.651, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3400, Loss: 3.381e+01, Y0: 76.518, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3410, Loss: 3.192e+01, Y0: 76.641, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 3420, Loss: 2.959e+01, Y0: 76.654, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 3430, Loss: 3.348e+01, Y0: 76.593, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 3440, Loss: 3.110e+01, Y0: 76.603, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3450, Loss: 3.007e+01, Y0: 76.586, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3460, Loss: 2.951e+01, Y0: 76.551, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3470, Loss: 3.298e+01, Y0: 76.650, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3480, Loss: 3.330e+01, Y0: 76.593, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3490, Loss: 3.269e+01, Y0: 76.563, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3500, Loss: 3.974e+01, Y0: 76.615, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3510, Loss: 3.557e+01, Y0: 76.550, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3520, Loss: 3.922e+01, Y0: 76.693, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3530, Loss: 3.081e+01, Y0: 76.620, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 3540, Loss: 3.288e+01, Y0: 76.529, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3550, Loss: 3.179e+01, Y0: 76.526, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3560, Loss: 3.045e+01, Y0: 76.643, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 3570, Loss: 4.697e+01, Y0: 76.548, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3580, Loss: 3.559e+01, Y0: 76.594, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3590, Loss: 3.037e+01, Y0: 76.670, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3600, Loss: 3.431e+01, Y0: 76.533, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 3610, Loss: 3.221e+01, Y0: 76.598, Learning Rate: 1.000e-04, Time: 0.88s\n",
      "Epoch: 3620, Loss: 1.438e+02, Y0: 76.358, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 3630, Loss: 3.652e+01, Y0: 76.426, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 3640, Loss: 3.110e+01, Y0: 76.658, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3650, Loss: 3.326e+01, Y0: 76.569, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3660, Loss: 3.184e+01, Y0: 76.611, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3670, Loss: 3.619e+01, Y0: 76.421, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3680, Loss: 2.880e+01, Y0: 76.584, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3690, Loss: 3.241e+01, Y0: 76.591, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 3700, Loss: 2.658e+01, Y0: 76.550, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3710, Loss: 3.004e+01, Y0: 76.520, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3720, Loss: 3.218e+01, Y0: 76.590, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3730, Loss: 3.225e+01, Y0: 76.670, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3740, Loss: 3.886e+01, Y0: 76.785, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3750, Loss: 3.039e+01, Y0: 76.593, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3760, Loss: 3.182e+01, Y0: 76.643, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3770, Loss: 3.487e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3780, Loss: 2.822e+01, Y0: 76.677, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 3790, Loss: 2.983e+01, Y0: 76.576, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 3800, Loss: 3.821e+01, Y0: 76.729, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 3810, Loss: 3.794e+01, Y0: 76.435, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3820, Loss: 3.071e+01, Y0: 76.702, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3830, Loss: 4.110e+01, Y0: 76.586, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3840, Loss: 3.488e+01, Y0: 76.675, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3850, Loss: 2.925e+01, Y0: 76.793, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 3860, Loss: 3.186e+01, Y0: 76.696, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3870, Loss: 2.966e+01, Y0: 76.762, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3880, Loss: 2.905e+01, Y0: 76.620, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3890, Loss: 2.967e+01, Y0: 76.558, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3900, Loss: 3.152e+01, Y0: 76.701, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3910, Loss: 3.253e+01, Y0: 76.843, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3920, Loss: 3.136e+01, Y0: 76.534, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 3930, Loss: 3.169e+01, Y0: 76.651, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3940, Loss: 3.344e+01, Y0: 76.735, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 3950, Loss: 2.966e+01, Y0: 76.528, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3960, Loss: 3.800e+01, Y0: 76.607, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 3970, Loss: 2.854e+01, Y0: 76.504, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 3980, Loss: 4.398e+01, Y0: 76.715, Learning Rate: 1.000e-04, Time: 0.91s\n",
      "Epoch: 3990, Loss: 3.461e+01, Y0: 76.764, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4000, Loss: 3.282e+01, Y0: 76.484, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4010, Loss: 3.065e+01, Y0: 76.659, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4020, Loss: 2.860e+01, Y0: 76.704, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4030, Loss: 3.360e+01, Y0: 76.641, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4040, Loss: 2.781e+01, Y0: 76.730, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4050, Loss: 3.259e+01, Y0: 76.756, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 4060, Loss: 3.651e+01, Y0: 76.514, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4070, Loss: 3.638e+01, Y0: 76.734, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4080, Loss: 3.119e+01, Y0: 76.694, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4090, Loss: 2.896e+01, Y0: 76.716, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4100, Loss: 3.199e+01, Y0: 76.671, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4110, Loss: 3.001e+01, Y0: 76.540, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4120, Loss: 3.242e+01, Y0: 76.677, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4130, Loss: 3.034e+01, Y0: 76.699, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4140, Loss: 2.557e+01, Y0: 76.757, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 4150, Loss: 2.747e+01, Y0: 76.672, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 4160, Loss: 3.400e+01, Y0: 76.668, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 4170, Loss: 2.879e+01, Y0: 76.522, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 4180, Loss: 3.242e+01, Y0: 76.651, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4190, Loss: 3.001e+01, Y0: 76.587, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4200, Loss: 3.030e+01, Y0: 76.763, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4210, Loss: 2.640e+01, Y0: 76.696, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4220, Loss: 3.503e+01, Y0: 76.641, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4230, Loss: 2.895e+01, Y0: 76.722, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4240, Loss: 3.478e+01, Y0: 76.615, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4250, Loss: 2.491e+01, Y0: 76.589, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4260, Loss: 3.171e+01, Y0: 76.724, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4270, Loss: 2.790e+01, Y0: 76.523, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4280, Loss: 2.997e+01, Y0: 76.644, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4290, Loss: 2.648e+01, Y0: 76.581, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4300, Loss: 2.728e+01, Y0: 76.633, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4310, Loss: 6.113e+01, Y0: 76.433, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4320, Loss: 5.420e+01, Y0: 77.075, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4330, Loss: 3.771e+01, Y0: 76.643, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 4340, Loss: 3.221e+01, Y0: 76.850, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 4350, Loss: 2.838e+01, Y0: 76.751, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 4360, Loss: 3.338e+01, Y0: 76.715, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4370, Loss: 3.004e+01, Y0: 76.626, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4380, Loss: 2.500e+01, Y0: 76.618, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4390, Loss: 3.131e+01, Y0: 76.764, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4400, Loss: 3.000e+01, Y0: 76.643, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4410, Loss: 3.079e+01, Y0: 76.710, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4420, Loss: 3.594e+01, Y0: 76.700, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4430, Loss: 2.948e+01, Y0: 76.456, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4440, Loss: 2.811e+01, Y0: 76.624, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4450, Loss: 3.074e+01, Y0: 76.737, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4460, Loss: 2.930e+01, Y0: 76.615, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4470, Loss: 2.922e+01, Y0: 76.797, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4480, Loss: 2.956e+01, Y0: 76.675, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4490, Loss: 2.944e+01, Y0: 76.678, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4500, Loss: 2.818e+01, Y0: 76.771, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4510, Loss: 2.538e+01, Y0: 76.527, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 4520, Loss: 3.312e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 4530, Loss: 3.018e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 4540, Loss: 2.986e+01, Y0: 76.647, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4550, Loss: 2.787e+01, Y0: 76.641, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4560, Loss: 2.965e+01, Y0: 76.615, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4570, Loss: 3.192e+01, Y0: 76.541, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4580, Loss: 3.256e+01, Y0: 76.568, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4590, Loss: 2.746e+01, Y0: 76.678, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4600, Loss: 2.657e+01, Y0: 76.703, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 4610, Loss: 3.007e+01, Y0: 76.724, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4620, Loss: 2.859e+01, Y0: 76.547, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4630, Loss: 2.864e+01, Y0: 76.569, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4640, Loss: 2.594e+01, Y0: 76.592, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4650, Loss: 2.693e+01, Y0: 76.710, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4660, Loss: 3.058e+01, Y0: 76.599, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4670, Loss: 3.524e+01, Y0: 76.578, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4680, Loss: 2.992e+01, Y0: 76.513, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4690, Loss: 2.787e+01, Y0: 76.519, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4700, Loss: 2.965e+01, Y0: 76.474, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 4710, Loss: 2.940e+01, Y0: 76.551, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 4720, Loss: 3.051e+01, Y0: 76.650, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 4730, Loss: 3.173e+01, Y0: 76.527, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4740, Loss: 3.280e+01, Y0: 76.559, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4750, Loss: 2.812e+01, Y0: 76.633, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4760, Loss: 2.558e+01, Y0: 76.626, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4770, Loss: 2.783e+01, Y0: 76.639, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4780, Loss: 5.213e+02, Y0: 76.213, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4790, Loss: 5.768e+01, Y0: 76.297, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4800, Loss: 3.649e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4810, Loss: 3.008e+01, Y0: 76.728, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 4820, Loss: 2.973e+01, Y0: 76.581, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4830, Loss: 2.711e+01, Y0: 76.579, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4840, Loss: 2.975e+01, Y0: 76.683, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4850, Loss: 4.514e+01, Y0: 76.606, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4860, Loss: 6.125e+02, Y0: 76.605, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4870, Loss: 3.178e+01, Y0: 76.610, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 4880, Loss: 3.079e+01, Y0: 76.789, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4890, Loss: 3.334e+01, Y0: 76.635, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 4900, Loss: 3.170e+01, Y0: 76.758, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 4910, Loss: 2.750e+01, Y0: 76.506, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 4920, Loss: 3.061e+01, Y0: 76.544, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4930, Loss: 2.701e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4940, Loss: 2.910e+01, Y0: 76.646, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 4950, Loss: 3.006e+01, Y0: 76.735, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4960, Loss: 3.187e+01, Y0: 76.799, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4970, Loss: 2.697e+01, Y0: 76.686, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 4980, Loss: 2.951e+01, Y0: 76.630, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 4990, Loss: 2.245e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5000, Loss: 2.674e+01, Y0: 76.524, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5010, Loss: 2.876e+01, Y0: 76.550, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5020, Loss: 2.547e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5030, Loss: 3.704e+01, Y0: 76.506, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5040, Loss: 2.970e+01, Y0: 76.537, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5050, Loss: 2.651e+01, Y0: 76.556, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5060, Loss: 2.818e+01, Y0: 76.622, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5070, Loss: 2.872e+01, Y0: 76.628, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 5080, Loss: 2.943e+01, Y0: 76.648, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 5090, Loss: 2.795e+01, Y0: 76.692, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 5100, Loss: 2.698e+01, Y0: 76.676, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5110, Loss: 2.421e+01, Y0: 76.755, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5120, Loss: 3.138e+01, Y0: 76.781, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 5130, Loss: 2.822e+01, Y0: 76.697, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5140, Loss: 3.012e+01, Y0: 76.826, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5150, Loss: 2.753e+01, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5160, Loss: 2.973e+01, Y0: 76.744, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5170, Loss: 2.789e+01, Y0: 76.631, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5180, Loss: 3.055e+01, Y0: 76.764, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5190, Loss: 2.771e+01, Y0: 76.828, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5200, Loss: 4.533e+01, Y0: 76.745, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5210, Loss: 2.678e+01, Y0: 76.580, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5220, Loss: 3.475e+01, Y0: 76.776, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5230, Loss: 4.178e+01, Y0: 76.822, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5240, Loss: 2.602e+01, Y0: 76.801, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5250, Loss: 2.939e+01, Y0: 76.598, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5260, Loss: 2.720e+01, Y0: 76.721, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 5270, Loss: 2.637e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 5280, Loss: 2.883e+01, Y0: 76.697, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 5290, Loss: 2.651e+01, Y0: 76.561, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5300, Loss: 2.532e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5310, Loss: 2.864e+01, Y0: 76.716, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5320, Loss: 2.768e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5330, Loss: 2.256e+01, Y0: 76.681, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5340, Loss: 3.010e+01, Y0: 76.800, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5350, Loss: 2.422e+01, Y0: 76.689, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5360, Loss: 5.295e+01, Y0: 76.482, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5370, Loss: 2.864e+01, Y0: 76.743, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5380, Loss: 2.732e+01, Y0: 76.754, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5390, Loss: 2.664e+01, Y0: 76.624, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5400, Loss: 3.238e+01, Y0: 76.517, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5410, Loss: 3.140e+01, Y0: 76.733, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5420, Loss: 3.080e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5430, Loss: 2.982e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5440, Loss: 3.302e+01, Y0: 76.590, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5450, Loss: 2.556e+01, Y0: 76.601, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 5460, Loss: 3.042e+01, Y0: 76.774, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 5470, Loss: 2.704e+01, Y0: 76.771, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 5480, Loss: 6.999e+01, Y0: 76.610, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5490, Loss: 3.044e+01, Y0: 76.470, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5500, Loss: 2.789e+01, Y0: 76.754, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5510, Loss: 3.612e+01, Y0: 76.872, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5520, Loss: 3.071e+01, Y0: 76.731, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 5530, Loss: 3.964e+01, Y0: 76.828, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5540, Loss: 2.484e+01, Y0: 76.628, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5550, Loss: 2.915e+01, Y0: 76.598, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 5560, Loss: 2.879e+01, Y0: 76.594, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5570, Loss: 2.615e+01, Y0: 76.723, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5580, Loss: 2.741e+01, Y0: 76.655, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5590, Loss: 2.581e+01, Y0: 76.531, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5600, Loss: 4.418e+01, Y0: 76.654, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5610, Loss: 2.735e+01, Y0: 76.502, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5620, Loss: 2.643e+01, Y0: 76.613, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5630, Loss: 3.083e+01, Y0: 76.750, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 5640, Loss: 2.879e+01, Y0: 76.804, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 5650, Loss: 3.587e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 5660, Loss: 3.715e+01, Y0: 77.055, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5670, Loss: 2.541e+01, Y0: 76.876, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5680, Loss: 2.476e+01, Y0: 76.715, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5690, Loss: 2.303e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5700, Loss: 2.722e+01, Y0: 76.730, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5710, Loss: 2.672e+01, Y0: 76.597, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5720, Loss: 2.775e+01, Y0: 76.639, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5730, Loss: 2.341e+01, Y0: 76.574, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5740, Loss: 3.162e+01, Y0: 76.783, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5750, Loss: 3.168e+01, Y0: 76.943, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5760, Loss: 3.309e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5770, Loss: 3.682e+01, Y0: 76.948, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5780, Loss: 2.703e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5790, Loss: 2.616e+01, Y0: 76.843, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5800, Loss: 3.528e+01, Y0: 76.998, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5810, Loss: 2.762e+01, Y0: 76.762, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5820, Loss: 2.742e+01, Y0: 76.528, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 5830, Loss: 1.098e+02, Y0: 76.463, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 5840, Loss: 2.744e+01, Y0: 76.504, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 5850, Loss: 2.357e+01, Y0: 76.596, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 5860, Loss: 2.412e+01, Y0: 76.655, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5870, Loss: 2.684e+01, Y0: 76.632, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5880, Loss: 2.100e+01, Y0: 76.674, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5890, Loss: 2.773e+01, Y0: 76.573, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5900, Loss: 2.452e+01, Y0: 76.654, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5910, Loss: 2.539e+01, Y0: 76.639, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5920, Loss: 2.341e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5930, Loss: 2.234e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5940, Loss: 2.674e+01, Y0: 76.822, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 5950, Loss: 2.600e+01, Y0: 76.628, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5960, Loss: 2.655e+01, Y0: 76.659, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 5970, Loss: 2.569e+01, Y0: 76.732, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 5980, Loss: 2.840e+01, Y0: 76.587, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 5990, Loss: 2.720e+01, Y0: 76.636, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6000, Loss: 2.430e+01, Y0: 76.624, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 6010, Loss: 2.254e+01, Y0: 76.626, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 6020, Loss: 2.440e+01, Y0: 76.609, Learning Rate: 1.000e-04, Time: 0.89s\n",
      "Epoch: 6030, Loss: 2.625e+01, Y0: 76.582, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6040, Loss: 2.594e+01, Y0: 76.599, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6050, Loss: 3.458e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 6060, Loss: 2.476e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6070, Loss: 2.505e+01, Y0: 76.793, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6080, Loss: 2.867e+01, Y0: 76.707, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6090, Loss: 2.483e+01, Y0: 76.473, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6100, Loss: 3.514e+01, Y0: 76.561, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 6110, Loss: 2.868e+01, Y0: 76.464, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6120, Loss: 2.546e+01, Y0: 76.544, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6130, Loss: 3.383e+01, Y0: 76.481, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6140, Loss: 2.414e+01, Y0: 76.562, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6150, Loss: 2.663e+01, Y0: 76.618, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6160, Loss: 2.676e+01, Y0: 76.638, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6170, Loss: 2.319e+01, Y0: 76.760, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6180, Loss: 2.468e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6190, Loss: 2.488e+01, Y0: 76.724, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 6200, Loss: 2.274e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 6210, Loss: 2.131e+01, Y0: 76.702, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 6220, Loss: 2.295e+01, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6230, Loss: 2.514e+01, Y0: 76.620, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6240, Loss: 3.447e+01, Y0: 76.747, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6250, Loss: 2.416e+01, Y0: 76.833, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6260, Loss: 2.391e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 6270, Loss: 2.536e+01, Y0: 76.817, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6280, Loss: 3.579e+01, Y0: 76.790, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6290, Loss: 3.042e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6300, Loss: 2.269e+01, Y0: 76.737, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6310, Loss: 2.662e+01, Y0: 76.625, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6320, Loss: 2.793e+01, Y0: 76.564, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6330, Loss: 5.386e+01, Y0: 76.593, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 6340, Loss: 6.043e+01, Y0: 76.630, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6350, Loss: 2.453e+01, Y0: 76.658, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6360, Loss: 2.582e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6370, Loss: 2.685e+01, Y0: 76.604, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6380, Loss: 3.305e+01, Y0: 76.745, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 6390, Loss: 3.020e+01, Y0: 76.851, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 6400, Loss: 2.741e+01, Y0: 76.798, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 6410, Loss: 2.686e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6420, Loss: 2.419e+01, Y0: 76.778, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6430, Loss: 2.505e+01, Y0: 76.730, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6440, Loss: 2.564e+01, Y0: 76.749, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6450, Loss: 8.740e+01, Y0: 76.182, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6460, Loss: 3.840e+01, Y0: 76.712, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6470, Loss: 7.019e+01, Y0: 76.384, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 6480, Loss: 2.621e+01, Y0: 76.732, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6490, Loss: 2.379e+01, Y0: 76.725, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6500, Loss: 2.474e+01, Y0: 76.820, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6510, Loss: 2.574e+01, Y0: 76.823, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6520, Loss: 2.506e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6530, Loss: 2.346e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6540, Loss: 2.283e+01, Y0: 76.681, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6550, Loss: 2.341e+01, Y0: 76.755, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6560, Loss: 3.329e+01, Y0: 76.824, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 6570, Loss: 2.853e+01, Y0: 76.705, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 6580, Loss: 2.287e+01, Y0: 76.656, Learning Rate: 1.000e-04, Time: 0.88s\n",
      "Epoch: 6590, Loss: 2.670e+01, Y0: 76.653, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6600, Loss: 2.260e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6610, Loss: 2.384e+01, Y0: 76.720, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6620, Loss: 2.418e+01, Y0: 76.707, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 6630, Loss: 2.590e+01, Y0: 76.636, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6640, Loss: 2.390e+01, Y0: 76.746, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6650, Loss: 2.399e+01, Y0: 76.757, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6660, Loss: 2.203e+01, Y0: 76.714, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6670, Loss: 2.546e+01, Y0: 76.728, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6680, Loss: 2.727e+01, Y0: 76.811, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6690, Loss: 2.272e+01, Y0: 76.718, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6700, Loss: 2.116e+01, Y0: 76.762, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6710, Loss: 2.549e+01, Y0: 76.711, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6720, Loss: 2.441e+01, Y0: 76.759, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6730, Loss: 2.243e+01, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6740, Loss: 2.379e+01, Y0: 76.842, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6750, Loss: 2.288e+01, Y0: 76.713, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 6760, Loss: 2.368e+01, Y0: 76.770, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 6770, Loss: 2.481e+01, Y0: 76.818, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 6780, Loss: 2.531e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6790, Loss: 2.215e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6800, Loss: 2.425e+01, Y0: 76.858, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6810, Loss: 2.652e+01, Y0: 76.785, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6820, Loss: 2.173e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6830, Loss: 2.595e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6840, Loss: 2.465e+01, Y0: 76.729, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6850, Loss: 2.313e+01, Y0: 76.694, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6860, Loss: 2.520e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 6870, Loss: 2.500e+01, Y0: 76.728, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6880, Loss: 2.381e+01, Y0: 76.865, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6890, Loss: 2.651e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6900, Loss: 2.697e+01, Y0: 76.518, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 6910, Loss: 2.531e+01, Y0: 76.692, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6920, Loss: 2.245e+01, Y0: 76.690, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6930, Loss: 2.579e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 6940, Loss: 2.294e+01, Y0: 76.797, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 6950, Loss: 2.486e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 6960, Loss: 2.379e+01, Y0: 76.784, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 6970, Loss: 2.068e+01, Y0: 76.669, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 6980, Loss: 2.659e+01, Y0: 76.948, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 6990, Loss: 2.405e+01, Y0: 76.808, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7000, Loss: 2.439e+01, Y0: 76.706, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7010, Loss: 2.779e+01, Y0: 76.756, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7020, Loss: 2.553e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7030, Loss: 3.269e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7040, Loss: 2.303e+01, Y0: 76.727, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7050, Loss: 2.321e+01, Y0: 76.580, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7060, Loss: 2.478e+01, Y0: 76.588, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7070, Loss: 2.690e+01, Y0: 76.832, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7080, Loss: 2.301e+01, Y0: 76.796, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7090, Loss: 2.178e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7100, Loss: 2.705e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7110, Loss: 2.241e+01, Y0: 76.853, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7120, Loss: 3.062e+01, Y0: 76.580, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 7130, Loss: 2.548e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 7140, Loss: 2.626e+01, Y0: 76.705, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 7150, Loss: 2.594e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7160, Loss: 2.791e+01, Y0: 76.565, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7170, Loss: 2.310e+01, Y0: 76.561, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7180, Loss: 2.545e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7190, Loss: 3.478e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7200, Loss: 2.628e+01, Y0: 76.820, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7210, Loss: 2.364e+01, Y0: 76.689, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7220, Loss: 2.333e+01, Y0: 76.667, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7230, Loss: 2.166e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7240, Loss: 2.538e+01, Y0: 76.524, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 7250, Loss: 2.021e+01, Y0: 76.766, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7260, Loss: 2.327e+01, Y0: 76.582, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7270, Loss: 3.189e+01, Y0: 76.286, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7280, Loss: 2.820e+01, Y0: 76.417, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7290, Loss: 4.132e+01, Y0: 76.290, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 7300, Loss: 3.093e+01, Y0: 76.588, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7310, Loss: 2.576e+01, Y0: 76.763, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 7320, Loss: 2.061e+01, Y0: 76.817, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 7330, Loss: 6.716e+01, Y0: 76.686, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 7340, Loss: 2.205e+01, Y0: 76.826, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7350, Loss: 2.458e+01, Y0: 76.790, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7360, Loss: 2.719e+01, Y0: 76.796, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7370, Loss: 2.479e+01, Y0: 76.690, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7380, Loss: 2.180e+01, Y0: 76.670, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7390, Loss: 2.013e+01, Y0: 76.722, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7400, Loss: 2.130e+01, Y0: 76.587, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7410, Loss: 2.230e+01, Y0: 76.680, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7420, Loss: 2.215e+01, Y0: 76.691, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7430, Loss: 2.040e+01, Y0: 76.786, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7440, Loss: 2.467e+01, Y0: 76.713, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7450, Loss: 2.784e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 7460, Loss: 2.422e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7470, Loss: 2.443e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7480, Loss: 2.150e+01, Y0: 76.821, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7490, Loss: 2.045e+01, Y0: 76.857, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 7500, Loss: 2.431e+01, Y0: 76.721, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 7510, Loss: 2.878e+01, Y0: 76.541, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 7520, Loss: 2.311e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7530, Loss: 2.188e+01, Y0: 76.826, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7540, Loss: 1.904e+01, Y0: 76.832, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7550, Loss: 2.704e+01, Y0: 76.721, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7560, Loss: 2.558e+01, Y0: 76.852, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7570, Loss: 1.962e+01, Y0: 76.757, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7580, Loss: 1.851e+01, Y0: 76.646, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 7590, Loss: 2.797e+01, Y0: 76.751, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7600, Loss: 2.397e+01, Y0: 76.809, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7610, Loss: 2.151e+01, Y0: 76.769, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7620, Loss: 2.361e+01, Y0: 76.752, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7630, Loss: 2.051e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7640, Loss: 2.117e+01, Y0: 76.809, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7650, Loss: 2.691e+01, Y0: 76.795, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 7660, Loss: 2.488e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7670, Loss: 2.234e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7680, Loss: 2.060e+01, Y0: 76.753, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 7690, Loss: 2.146e+01, Y0: 76.749, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 7700, Loss: 2.227e+01, Y0: 76.745, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 7710, Loss: 2.341e+01, Y0: 76.763, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7720, Loss: 2.262e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7730, Loss: 2.106e+01, Y0: 76.729, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7740, Loss: 2.345e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7750, Loss: 2.083e+01, Y0: 76.675, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7760, Loss: 5.029e+01, Y0: 76.421, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7770, Loss: 2.318e+01, Y0: 76.728, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7780, Loss: 2.293e+01, Y0: 76.688, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7790, Loss: 2.082e+01, Y0: 76.612, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7800, Loss: 3.276e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7810, Loss: 2.238e+01, Y0: 76.711, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7820, Loss: 2.303e+01, Y0: 76.823, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7830, Loss: 2.319e+01, Y0: 76.573, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7840, Loss: 2.162e+01, Y0: 76.665, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7850, Loss: 2.248e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7860, Loss: 2.333e+01, Y0: 76.695, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7870, Loss: 2.122e+01, Y0: 76.868, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 7880, Loss: 2.355e+01, Y0: 76.639, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 7890, Loss: 2.153e+01, Y0: 76.768, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7900, Loss: 2.464e+01, Y0: 76.832, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7910, Loss: 2.601e+01, Y0: 76.610, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7920, Loss: 2.620e+01, Y0: 76.580, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 7930, Loss: 2.928e+01, Y0: 76.507, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7940, Loss: 2.166e+01, Y0: 76.533, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 7950, Loss: 2.556e+01, Y0: 76.683, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7960, Loss: 2.385e+01, Y0: 76.689, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 7970, Loss: 2.720e+01, Y0: 76.630, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 7980, Loss: 1.986e+01, Y0: 76.651, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 7990, Loss: 2.112e+01, Y0: 76.750, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8000, Loss: 2.014e+01, Y0: 76.725, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8010, Loss: 2.282e+01, Y0: 76.867, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8020, Loss: 2.173e+01, Y0: 76.749, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8030, Loss: 2.141e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8040, Loss: 2.249e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8050, Loss: 2.329e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 8060, Loss: 2.111e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 8070, Loss: 4.320e+01, Y0: 76.489, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 8080, Loss: 2.096e+01, Y0: 76.876, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8090, Loss: 1.900e+01, Y0: 76.712, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8100, Loss: 2.749e+01, Y0: 76.676, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8110, Loss: 2.487e+01, Y0: 76.838, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8120, Loss: 2.956e+01, Y0: 76.461, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8130, Loss: 1.956e+01, Y0: 76.693, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8140, Loss: 2.332e+01, Y0: 76.757, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8150, Loss: 2.486e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8160, Loss: 2.117e+01, Y0: 76.705, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8170, Loss: 2.096e+01, Y0: 76.703, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8180, Loss: 1.992e+01, Y0: 76.645, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8190, Loss: 2.002e+01, Y0: 76.724, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8200, Loss: 2.085e+01, Y0: 76.794, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 8210, Loss: 2.933e+01, Y0: 76.507, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8220, Loss: 2.569e+01, Y0: 76.682, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8230, Loss: 2.565e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8240, Loss: 2.204e+01, Y0: 76.870, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 8250, Loss: 2.071e+01, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 8260, Loss: 1.986e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 8270, Loss: 2.112e+01, Y0: 76.777, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8280, Loss: 2.376e+01, Y0: 76.699, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8290, Loss: 2.129e+01, Y0: 76.858, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8300, Loss: 1.968e+01, Y0: 76.573, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8310, Loss: 1.983e+01, Y0: 76.646, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8320, Loss: 3.172e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8330, Loss: 3.151e+01, Y0: 76.601, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8340, Loss: 2.252e+01, Y0: 76.816, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 8350, Loss: 2.141e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8360, Loss: 2.532e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8370, Loss: 1.978e+01, Y0: 76.696, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8380, Loss: 2.098e+01, Y0: 76.640, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8390, Loss: 2.259e+01, Y0: 76.732, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8400, Loss: 2.533e+01, Y0: 76.936, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 8410, Loss: 1.857e+01, Y0: 76.765, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8420, Loss: 2.206e+01, Y0: 76.645, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 8430, Loss: 2.134e+01, Y0: 76.622, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 8440, Loss: 1.901e+01, Y0: 76.722, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 8450, Loss: 2.214e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 8460, Loss: 1.992e+01, Y0: 76.752, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8470, Loss: 3.517e+01, Y0: 76.581, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 8480, Loss: 2.616e+01, Y0: 76.539, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8490, Loss: 2.206e+01, Y0: 76.671, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8500, Loss: 2.194e+01, Y0: 76.765, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8510, Loss: 2.039e+01, Y0: 76.841, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8520, Loss: 2.108e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8530, Loss: 2.208e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8540, Loss: 2.050e+01, Y0: 76.754, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8550, Loss: 1.837e+01, Y0: 76.820, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8560, Loss: 1.900e+01, Y0: 76.614, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8570, Loss: 2.029e+01, Y0: 76.702, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 8580, Loss: 1.995e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8590, Loss: 1.798e+01, Y0: 76.784, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8600, Loss: 2.433e+01, Y0: 76.746, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8610, Loss: 1.967e+01, Y0: 76.746, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 8620, Loss: 2.333e+01, Y0: 76.979, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 8630, Loss: 2.282e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 8640, Loss: 2.209e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8650, Loss: 2.217e+01, Y0: 76.655, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8660, Loss: 2.352e+01, Y0: 76.868, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8670, Loss: 2.106e+01, Y0: 76.660, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 8680, Loss: 2.652e+01, Y0: 76.447, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8690, Loss: 2.257e+01, Y0: 76.790, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8700, Loss: 4.219e+01, Y0: 76.765, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8710, Loss: 2.381e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8720, Loss: 2.104e+01, Y0: 76.716, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8730, Loss: 2.496e+01, Y0: 76.625, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8740, Loss: 2.564e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8750, Loss: 1.867e+01, Y0: 76.698, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8760, Loss: 2.138e+01, Y0: 76.557, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8770, Loss: 2.111e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8780, Loss: 2.052e+01, Y0: 76.668, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8790, Loss: 2.780e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8800, Loss: 2.136e+01, Y0: 76.544, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 8810, Loss: 4.872e+01, Y0: 76.671, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 8820, Loss: 2.255e+01, Y0: 76.736, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8830, Loss: 2.126e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8840, Loss: 3.812e+01, Y0: 76.352, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8850, Loss: 2.649e+01, Y0: 76.694, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 8860, Loss: 2.274e+01, Y0: 76.870, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 8870, Loss: 2.129e+01, Y0: 76.723, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 8880, Loss: 1.859e+01, Y0: 76.769, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8890, Loss: 2.024e+01, Y0: 76.852, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8900, Loss: 2.654e+01, Y0: 76.734, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8910, Loss: 1.977e+01, Y0: 76.843, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8920, Loss: 2.585e+01, Y0: 76.592, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8930, Loss: 2.162e+01, Y0: 76.651, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8940, Loss: 2.038e+01, Y0: 76.877, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 8950, Loss: 1.965e+01, Y0: 76.736, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 8960, Loss: 1.914e+01, Y0: 76.741, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 8970, Loss: 2.140e+01, Y0: 76.807, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 8980, Loss: 1.913e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 8990, Loss: 2.467e+01, Y0: 76.658, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 9000, Loss: 2.103e+01, Y0: 76.630, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 9010, Loss: 2.346e+01, Y0: 76.756, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9020, Loss: 2.483e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9030, Loss: 1.883e+01, Y0: 76.967, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 9040, Loss: 2.264e+01, Y0: 76.748, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9050, Loss: 2.027e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9060, Loss: 2.086e+01, Y0: 76.997, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9070, Loss: 2.870e+01, Y0: 76.753, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9080, Loss: 2.156e+01, Y0: 76.810, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 9090, Loss: 1.975e+01, Y0: 76.843, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9100, Loss: 1.862e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 9110, Loss: 1.920e+01, Y0: 76.750, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9120, Loss: 1.849e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 9130, Loss: 2.191e+01, Y0: 76.844, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9140, Loss: 2.242e+01, Y0: 76.740, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9150, Loss: 2.023e+01, Y0: 76.844, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9160, Loss: 2.684e+01, Y0: 76.616, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9170, Loss: 2.064e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 9180, Loss: 1.759e+01, Y0: 76.839, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 9190, Loss: 1.951e+01, Y0: 76.733, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9200, Loss: 2.067e+01, Y0: 76.604, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9210, Loss: 2.390e+01, Y0: 76.955, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9220, Loss: 1.956e+01, Y0: 76.644, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9230, Loss: 1.983e+01, Y0: 76.696, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9240, Loss: 2.046e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9250, Loss: 2.299e+01, Y0: 76.826, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9260, Loss: 2.310e+01, Y0: 76.928, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9270, Loss: 2.157e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9280, Loss: 2.036e+01, Y0: 76.745, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9290, Loss: 2.116e+01, Y0: 76.819, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9300, Loss: 2.248e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9310, Loss: 2.065e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9320, Loss: 2.140e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9330, Loss: 1.948e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9340, Loss: 2.207e+01, Y0: 76.792, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 9350, Loss: 1.812e+01, Y0: 76.817, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 9360, Loss: 2.423e+01, Y0: 76.656, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 9370, Loss: 1.975e+01, Y0: 76.905, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 9380, Loss: 1.979e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9390, Loss: 2.016e+01, Y0: 76.747, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9400, Loss: 2.872e+01, Y0: 77.159, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9410, Loss: 2.328e+01, Y0: 77.037, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9420, Loss: 1.943e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 9430, Loss: 2.060e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9440, Loss: 1.938e+01, Y0: 76.847, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9450, Loss: 1.970e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9460, Loss: 2.002e+01, Y0: 76.752, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9470, Loss: 2.094e+01, Y0: 76.721, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9480, Loss: 1.972e+01, Y0: 76.782, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9490, Loss: 1.992e+01, Y0: 76.808, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9500, Loss: 1.974e+01, Y0: 76.582, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 9510, Loss: 1.967e+01, Y0: 76.849, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9520, Loss: 2.004e+01, Y0: 76.673, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9530, Loss: 2.092e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9540, Loss: 2.376e+01, Y0: 76.906, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 9550, Loss: 1.832e+01, Y0: 76.702, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 9560, Loss: 1.845e+01, Y0: 76.868, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 9570, Loss: 2.111e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9580, Loss: 2.747e+01, Y0: 77.105, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9590, Loss: 2.329e+01, Y0: 76.816, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9600, Loss: 2.095e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9610, Loss: 2.007e+01, Y0: 76.859, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9620, Loss: 2.536e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9630, Loss: 2.636e+01, Y0: 76.448, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9640, Loss: 1.937e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9650, Loss: 2.753e+01, Y0: 77.050, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9660, Loss: 2.280e+01, Y0: 76.752, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9670, Loss: 1.806e+01, Y0: 76.576, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9680, Loss: 1.882e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9690, Loss: 1.976e+01, Y0: 76.894, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9700, Loss: 2.734e+01, Y0: 76.801, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9710, Loss: 1.966e+01, Y0: 76.765, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9720, Loss: 2.222e+01, Y0: 76.806, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 9730, Loss: 2.288e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 9740, Loss: 3.145e+01, Y0: 76.984, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 9750, Loss: 2.665e+01, Y0: 77.087, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9760, Loss: 2.680e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9770, Loss: 1.771e+01, Y0: 76.955, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9780, Loss: 1.842e+01, Y0: 76.739, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 9790, Loss: 2.214e+01, Y0: 76.694, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9800, Loss: 1.708e+01, Y0: 76.784, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9810, Loss: 3.807e+01, Y0: 76.554, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 9820, Loss: 3.534e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9830, Loss: 1.885e+01, Y0: 76.982, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9840, Loss: 2.105e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9850, Loss: 1.754e+01, Y0: 76.711, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9860, Loss: 2.096e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9870, Loss: 2.403e+01, Y0: 76.840, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9880, Loss: 1.900e+01, Y0: 76.742, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9890, Loss: 1.656e+01, Y0: 76.726, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9900, Loss: 1.819e+01, Y0: 76.678, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 9910, Loss: 1.863e+01, Y0: 76.698, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 9920, Loss: 1.955e+01, Y0: 76.849, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 9930, Loss: 1.997e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 9940, Loss: 2.039e+01, Y0: 76.804, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 9950, Loss: 1.846e+01, Y0: 76.776, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9960, Loss: 1.671e+01, Y0: 76.802, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 9970, Loss: 2.012e+01, Y0: 76.854, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 9980, Loss: 1.836e+01, Y0: 76.843, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 9990, Loss: 2.759e+01, Y0: 77.008, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10000, Loss: 2.089e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10010, Loss: 1.773e+01, Y0: 76.773, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10020, Loss: 5.752e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 10030, Loss: 3.577e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10040, Loss: 2.719e+01, Y0: 76.745, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10050, Loss: 1.875e+01, Y0: 76.647, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10060, Loss: 1.739e+01, Y0: 76.783, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10070, Loss: 1.785e+01, Y0: 76.787, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10080, Loss: 1.747e+01, Y0: 76.692, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10090, Loss: 1.881e+01, Y0: 76.755, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10100, Loss: 2.036e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 10110, Loss: 1.819e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 10120, Loss: 2.970e+01, Y0: 76.517, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 10130, Loss: 2.132e+01, Y0: 76.548, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10140, Loss: 1.940e+01, Y0: 76.631, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10150, Loss: 2.087e+01, Y0: 76.812, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10160, Loss: 1.953e+01, Y0: 76.508, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 10170, Loss: 1.724e+01, Y0: 76.828, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10180, Loss: 2.338e+01, Y0: 76.789, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10190, Loss: 1.991e+01, Y0: 76.720, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10200, Loss: 2.123e+01, Y0: 76.737, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10210, Loss: 1.718e+01, Y0: 76.742, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 10220, Loss: 2.404e+01, Y0: 76.777, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10230, Loss: 1.874e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10240, Loss: 1.802e+01, Y0: 76.837, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10250, Loss: 3.285e+01, Y0: 76.564, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10260, Loss: 2.175e+01, Y0: 76.916, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 10270, Loss: 2.342e+01, Y0: 77.150, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10280, Loss: 1.928e+01, Y0: 77.111, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 10290, Loss: 1.908e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 10300, Loss: 1.691e+01, Y0: 76.787, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 10310, Loss: 1.746e+01, Y0: 76.758, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 10320, Loss: 1.834e+01, Y0: 76.723, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10330, Loss: 1.650e+01, Y0: 76.720, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10340, Loss: 2.062e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 10350, Loss: 2.156e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10360, Loss: 1.801e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 10370, Loss: 1.829e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10380, Loss: 1.758e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 10390, Loss: 1.942e+01, Y0: 76.718, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 10400, Loss: 2.060e+01, Y0: 76.961, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 10410, Loss: 2.168e+01, Y0: 77.031, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10420, Loss: 1.800e+01, Y0: 76.733, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10430, Loss: 2.199e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10440, Loss: 2.281e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10450, Loss: 1.996e+01, Y0: 76.835, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10460, Loss: 2.720e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10470, Loss: 2.887e+01, Y0: 77.024, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 10480, Loss: 1.963e+01, Y0: 76.810, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 10490, Loss: 1.904e+01, Y0: 76.631, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 10500, Loss: 1.941e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 10510, Loss: 1.726e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10520, Loss: 1.941e+01, Y0: 76.674, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10530, Loss: 1.958e+01, Y0: 76.709, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10540, Loss: 1.973e+01, Y0: 76.669, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10550, Loss: 1.699e+01, Y0: 76.785, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10560, Loss: 1.729e+01, Y0: 76.864, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10570, Loss: 1.735e+01, Y0: 76.844, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10580, Loss: 2.113e+01, Y0: 76.885, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 10590, Loss: 1.913e+01, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10600, Loss: 1.852e+01, Y0: 76.783, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10610, Loss: 1.679e+01, Y0: 76.853, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10620, Loss: 1.876e+01, Y0: 76.841, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10630, Loss: 1.903e+01, Y0: 76.817, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10640, Loss: 1.925e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10650, Loss: 1.698e+01, Y0: 76.895, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10660, Loss: 1.857e+01, Y0: 76.729, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 10670, Loss: 1.878e+01, Y0: 76.793, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 10680, Loss: 1.811e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 10690, Loss: 1.991e+01, Y0: 76.838, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10700, Loss: 1.780e+01, Y0: 76.781, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10710, Loss: 2.099e+01, Y0: 76.816, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 10720, Loss: 2.077e+01, Y0: 76.872, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10730, Loss: 1.871e+01, Y0: 76.838, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10740, Loss: 1.765e+01, Y0: 76.859, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10750, Loss: 1.776e+01, Y0: 76.918, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10760, Loss: 1.840e+01, Y0: 76.842, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10770, Loss: 1.774e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 10780, Loss: 1.904e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10790, Loss: 2.293e+01, Y0: 76.715, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10800, Loss: 1.770e+01, Y0: 76.753, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10810, Loss: 1.966e+01, Y0: 76.756, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10820, Loss: 1.669e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10830, Loss: 1.777e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 10840, Loss: 1.801e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 10850, Loss: 1.959e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 10860, Loss: 2.138e+01, Y0: 76.990, Learning Rate: 1.000e-04, Time: 0.88s\n",
      "Epoch: 10870, Loss: 1.598e+01, Y0: 76.806, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10880, Loss: 1.833e+01, Y0: 76.803, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10890, Loss: 1.529e+01, Y0: 76.759, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10900, Loss: 1.859e+01, Y0: 76.685, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 10910, Loss: 2.244e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 10920, Loss: 2.018e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10930, Loss: 2.468e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 10940, Loss: 3.827e+01, Y0: 76.612, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10950, Loss: 3.042e+01, Y0: 76.570, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10960, Loss: 2.418e+01, Y0: 76.804, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10970, Loss: 2.767e+01, Y0: 76.765, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 10980, Loss: 2.319e+01, Y0: 76.640, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 10990, Loss: 1.929e+01, Y0: 76.742, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11000, Loss: 1.878e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11010, Loss: 1.674e+01, Y0: 76.866, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11020, Loss: 3.675e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11030, Loss: 1.949e+01, Y0: 76.770, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 11040, Loss: 1.605e+01, Y0: 76.690, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 11050, Loss: 1.726e+01, Y0: 76.732, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 11060, Loss: 1.971e+01, Y0: 76.984, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11070, Loss: 2.079e+01, Y0: 76.879, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 11080, Loss: 1.983e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11090, Loss: 2.007e+01, Y0: 76.724, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11100, Loss: 1.746e+01, Y0: 76.743, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11110, Loss: 1.876e+01, Y0: 76.716, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11120, Loss: 1.671e+01, Y0: 76.683, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11130, Loss: 1.873e+01, Y0: 76.825, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11140, Loss: 1.795e+01, Y0: 76.849, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11150, Loss: 4.111e+01, Y0: 76.751, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11160, Loss: 1.787e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11170, Loss: 1.929e+01, Y0: 76.914, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11180, Loss: 1.668e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11190, Loss: 1.816e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11200, Loss: 1.659e+01, Y0: 76.759, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11210, Loss: 1.642e+01, Y0: 76.859, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 11220, Loss: 1.583e+01, Y0: 77.058, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 11230, Loss: 1.867e+01, Y0: 76.864, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 11240, Loss: 1.632e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 11250, Loss: 1.752e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11260, Loss: 1.671e+01, Y0: 76.810, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11270, Loss: 1.698e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11280, Loss: 3.899e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11290, Loss: 1.638e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11300, Loss: 1.764e+01, Y0: 76.858, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11310, Loss: 5.619e+01, Y0: 76.401, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11320, Loss: 1.733e+01, Y0: 76.662, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11330, Loss: 1.834e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11340, Loss: 1.765e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11350, Loss: 1.652e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11360, Loss: 1.717e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11370, Loss: 1.601e+01, Y0: 76.838, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11380, Loss: 1.761e+01, Y0: 76.819, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11390, Loss: 2.193e+01, Y0: 76.698, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 11400, Loss: 1.704e+01, Y0: 76.769, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 11410, Loss: 2.107e+01, Y0: 76.994, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 11420, Loss: 1.503e+01, Y0: 76.852, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 11430, Loss: 1.845e+01, Y0: 77.000, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11440, Loss: 1.815e+01, Y0: 76.689, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11450, Loss: 1.905e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11460, Loss: 1.784e+01, Y0: 76.823, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11470, Loss: 1.550e+01, Y0: 76.784, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11480, Loss: 1.682e+01, Y0: 76.993, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11490, Loss: 1.765e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11500, Loss: 2.038e+01, Y0: 76.754, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11510, Loss: 2.050e+01, Y0: 77.168, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11520, Loss: 2.548e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11530, Loss: 3.034e+01, Y0: 77.132, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11540, Loss: 1.809e+01, Y0: 76.621, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11550, Loss: 2.012e+01, Y0: 76.751, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11560, Loss: 1.662e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11570, Loss: 1.828e+01, Y0: 76.847, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 11580, Loss: 1.892e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11590, Loss: 1.840e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 11600, Loss: 1.803e+01, Y0: 76.702, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 11610, Loss: 1.850e+01, Y0: 76.778, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 11620, Loss: 1.789e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11630, Loss: 1.893e+01, Y0: 76.803, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11640, Loss: 1.680e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 11650, Loss: 1.716e+01, Y0: 76.639, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11660, Loss: 2.795e+01, Y0: 76.729, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 11670, Loss: 1.578e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11680, Loss: 1.605e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11690, Loss: 1.672e+01, Y0: 76.874, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 11700, Loss: 1.680e+01, Y0: 76.884, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11710, Loss: 4.992e+01, Y0: 77.088, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11720, Loss: 2.387e+01, Y0: 76.642, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11730, Loss: 2.191e+01, Y0: 76.700, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11740, Loss: 4.723e+01, Y0: 77.415, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11750, Loss: 3.678e+01, Y0: 77.357, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11760, Loss: 2.451e+01, Y0: 77.092, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11770, Loss: 8.786e+01, Y0: 76.795, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 11780, Loss: 2.337e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 11790, Loss: 1.975e+01, Y0: 77.004, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 11800, Loss: 2.141e+01, Y0: 76.854, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11810, Loss: 1.943e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 11820, Loss: 1.911e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11830, Loss: 1.951e+01, Y0: 76.832, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11840, Loss: 3.746e+01, Y0: 76.708, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11850, Loss: 1.999e+01, Y0: 76.745, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11860, Loss: 1.883e+01, Y0: 76.950, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11870, Loss: 1.883e+01, Y0: 76.902, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11880, Loss: 1.647e+01, Y0: 76.791, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11890, Loss: 1.683e+01, Y0: 76.812, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11900, Loss: 1.732e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11910, Loss: 1.547e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11920, Loss: 1.903e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 11930, Loss: 1.663e+01, Y0: 76.817, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 11940, Loss: 1.709e+01, Y0: 76.870, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11950, Loss: 1.611e+01, Y0: 76.818, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 11960, Loss: 1.587e+01, Y0: 76.765, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 11970, Loss: 1.622e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 11980, Loss: 1.902e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 11990, Loss: 1.829e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12000, Loss: 1.642e+01, Y0: 76.823, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12010, Loss: 1.823e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12020, Loss: 1.753e+01, Y0: 76.797, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12030, Loss: 2.234e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12040, Loss: 1.936e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12050, Loss: 1.780e+01, Y0: 76.845, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12060, Loss: 2.065e+01, Y0: 76.661, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12070, Loss: 2.128e+01, Y0: 76.780, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12080, Loss: 1.714e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12090, Loss: 1.994e+01, Y0: 76.756, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12100, Loss: 1.916e+01, Y0: 76.895, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12110, Loss: 1.584e+01, Y0: 76.866, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12120, Loss: 1.808e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12130, Loss: 2.429e+01, Y0: 76.719, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12140, Loss: 1.623e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 12150, Loss: 1.861e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 12160, Loss: 1.577e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 12170, Loss: 1.620e+01, Y0: 76.808, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12180, Loss: 1.573e+01, Y0: 76.798, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 12190, Loss: 1.871e+01, Y0: 77.065, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12200, Loss: 1.716e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12210, Loss: 1.861e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12220, Loss: 2.209e+01, Y0: 76.742, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12230, Loss: 1.818e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 12240, Loss: 1.551e+01, Y0: 76.814, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12250, Loss: 1.695e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 12260, Loss: 1.740e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 12270, Loss: 1.693e+01, Y0: 76.784, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12280, Loss: 2.796e+01, Y0: 77.172, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12290, Loss: 2.033e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12300, Loss: 1.828e+01, Y0: 76.824, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12310, Loss: 3.526e+01, Y0: 76.666, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12320, Loss: 1.895e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12330, Loss: 2.189e+01, Y0: 76.876, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 12340, Loss: 2.037e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 12350, Loss: 1.802e+01, Y0: 76.989, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 12360, Loss: 1.866e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12370, Loss: 1.759e+01, Y0: 76.807, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12380, Loss: 1.915e+01, Y0: 76.752, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12390, Loss: 1.899e+01, Y0: 76.792, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12400, Loss: 1.747e+01, Y0: 76.816, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12410, Loss: 3.432e+01, Y0: 77.212, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12420, Loss: 2.450e+01, Y0: 77.086, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12430, Loss: 2.038e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12440, Loss: 2.144e+01, Y0: 76.800, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12450, Loss: 2.079e+01, Y0: 77.054, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12460, Loss: 3.229e+02, Y0: 76.224, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12470, Loss: 3.910e+01, Y0: 76.156, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12480, Loss: 2.709e+01, Y0: 76.337, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12490, Loss: 2.408e+01, Y0: 76.706, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12500, Loss: 1.966e+01, Y0: 76.673, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12510, Loss: 1.967e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12520, Loss: 1.625e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 12530, Loss: 1.745e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 12540, Loss: 1.586e+01, Y0: 76.781, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 12550, Loss: 1.897e+01, Y0: 76.771, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12560, Loss: 1.745e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12570, Loss: 1.760e+01, Y0: 76.928, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12580, Loss: 1.562e+01, Y0: 76.806, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12590, Loss: 1.899e+01, Y0: 76.806, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12600, Loss: 1.817e+01, Y0: 76.812, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12610, Loss: 1.801e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 12620, Loss: 1.954e+01, Y0: 76.806, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12630, Loss: 1.762e+01, Y0: 76.833, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12640, Loss: 1.829e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12650, Loss: 1.593e+01, Y0: 76.852, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12660, Loss: 2.019e+01, Y0: 76.846, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12670, Loss: 1.717e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 12680, Loss: 1.984e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12690, Loss: 1.986e+01, Y0: 76.989, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12700, Loss: 1.891e+01, Y0: 76.835, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 12710, Loss: 1.508e+01, Y0: 76.853, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 12720, Loss: 1.870e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 12730, Loss: 1.473e+01, Y0: 76.881, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12740, Loss: 1.494e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12750, Loss: 1.629e+01, Y0: 76.828, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12760, Loss: 1.686e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12770, Loss: 1.517e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12780, Loss: 1.633e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12790, Loss: 1.578e+01, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12800, Loss: 1.821e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12810, Loss: 1.798e+01, Y0: 76.919, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12820, Loss: 2.158e+01, Y0: 76.842, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12830, Loss: 1.685e+01, Y0: 76.847, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12840, Loss: 2.343e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 12850, Loss: 1.630e+01, Y0: 76.706, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12860, Loss: 1.483e+01, Y0: 76.786, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12870, Loss: 2.003e+02, Y0: 76.743, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12880, Loss: 2.528e+01, Y0: 77.130, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12890, Loss: 1.980e+01, Y0: 77.109, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 12900, Loss: 1.705e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 12910, Loss: 2.105e+01, Y0: 76.710, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 12920, Loss: 1.979e+01, Y0: 76.738, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 12930, Loss: 2.176e+01, Y0: 76.744, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 12940, Loss: 1.840e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12950, Loss: 1.879e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12960, Loss: 1.933e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12970, Loss: 1.907e+01, Y0: 76.777, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 12980, Loss: 1.811e+01, Y0: 76.586, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 12990, Loss: 3.246e+01, Y0: 76.466, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13000, Loss: 1.838e+01, Y0: 76.685, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13010, Loss: 1.810e+01, Y0: 76.798, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13020, Loss: 1.495e+01, Y0: 76.802, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13030, Loss: 1.638e+01, Y0: 76.824, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13040, Loss: 1.748e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13050, Loss: 1.436e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13060, Loss: 1.687e+01, Y0: 76.825, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13070, Loss: 1.708e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13080, Loss: 1.644e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 13090, Loss: 1.823e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 13100, Loss: 1.714e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 13110, Loss: 1.601e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13120, Loss: 1.936e+01, Y0: 77.003, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13130, Loss: 2.012e+01, Y0: 77.059, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13140, Loss: 1.488e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 13150, Loss: 1.765e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13160, Loss: 1.967e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13170, Loss: 1.665e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13180, Loss: 1.686e+01, Y0: 76.791, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13190, Loss: 1.973e+01, Y0: 76.840, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13200, Loss: 1.472e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13210, Loss: 1.511e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13220, Loss: 1.735e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 13230, Loss: 1.835e+01, Y0: 76.780, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13240, Loss: 1.538e+01, Y0: 76.833, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13250, Loss: 1.836e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13260, Loss: 1.789e+01, Y0: 77.038, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 13270, Loss: 2.149e+01, Y0: 77.081, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 13280, Loss: 1.993e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 13290, Loss: 1.335e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13300, Loss: 1.740e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13310, Loss: 1.733e+01, Y0: 76.810, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13320, Loss: 1.690e+01, Y0: 76.849, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 13330, Loss: 1.553e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13340, Loss: 1.682e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13350, Loss: 1.742e+01, Y0: 76.936, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13360, Loss: 1.532e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13370, Loss: 1.870e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13380, Loss: 1.645e+01, Y0: 76.886, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13390, Loss: 1.554e+01, Y0: 76.798, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13400, Loss: 1.480e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13410, Loss: 1.647e+01, Y0: 76.777, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13420, Loss: 2.051e+01, Y0: 76.572, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13430, Loss: 3.067e+01, Y0: 77.081, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13440, Loss: 3.459e+01, Y0: 77.038, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13450, Loss: 2.791e+01, Y0: 77.036, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 13460, Loss: 2.158e+01, Y0: 77.054, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 13470, Loss: 1.506e+01, Y0: 76.704, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 13480, Loss: 1.535e+01, Y0: 76.786, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13490, Loss: 1.644e+01, Y0: 76.763, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13500, Loss: 1.379e+01, Y0: 76.906, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13510, Loss: 1.751e+01, Y0: 76.913, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13520, Loss: 1.566e+01, Y0: 76.866, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13530, Loss: 1.550e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 13540, Loss: 1.515e+01, Y0: 76.845, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13550, Loss: 1.665e+01, Y0: 76.843, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13560, Loss: 1.698e+01, Y0: 76.879, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13570, Loss: 1.639e+01, Y0: 76.847, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13580, Loss: 1.562e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13590, Loss: 1.608e+01, Y0: 76.979, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13600, Loss: 1.545e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13610, Loss: 1.610e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13620, Loss: 1.542e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13630, Loss: 1.679e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 13640, Loss: 1.605e+01, Y0: 76.854, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 13650, Loss: 1.714e+01, Y0: 76.802, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 13660, Loss: 1.867e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 13670, Loss: 1.783e+01, Y0: 76.938, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13680, Loss: 2.034e+01, Y0: 76.846, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13690, Loss: 2.216e+01, Y0: 76.823, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13700, Loss: 1.650e+01, Y0: 76.719, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13710, Loss: 1.681e+01, Y0: 76.742, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13720, Loss: 5.418e+01, Y0: 76.637, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13730, Loss: 1.772e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13740, Loss: 1.721e+01, Y0: 76.990, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13750, Loss: 1.606e+01, Y0: 76.989, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13760, Loss: 1.402e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 13770, Loss: 1.814e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13780, Loss: 1.417e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13790, Loss: 1.788e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13800, Loss: 1.750e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13810, Loss: 1.913e+01, Y0: 76.635, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13820, Loss: 1.572e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 13830, Loss: 1.737e+01, Y0: 76.865, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 13840, Loss: 1.558e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 13850, Loss: 1.571e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13860, Loss: 1.914e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 13870, Loss: 1.481e+01, Y0: 76.880, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13880, Loss: 1.603e+01, Y0: 76.858, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13890, Loss: 1.578e+01, Y0: 76.921, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13900, Loss: 1.637e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13910, Loss: 1.514e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13920, Loss: 1.548e+01, Y0: 76.720, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13930, Loss: 1.657e+01, Y0: 76.845, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13940, Loss: 1.744e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13950, Loss: 1.657e+01, Y0: 76.859, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 13960, Loss: 1.184e+02, Y0: 76.733, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13970, Loss: 2.798e+01, Y0: 76.818, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 13980, Loss: 3.334e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 13990, Loss: 2.682e+01, Y0: 76.385, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14000, Loss: 2.135e+01, Y0: 76.646, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 14010, Loss: 1.603e+01, Y0: 76.774, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 14020, Loss: 1.873e+01, Y0: 76.721, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 14030, Loss: 1.626e+01, Y0: 76.734, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14040, Loss: 1.501e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14050, Loss: 1.802e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14060, Loss: 1.493e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14070, Loss: 1.586e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14080, Loss: 1.627e+01, Y0: 76.802, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 14090, Loss: 1.739e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14100, Loss: 1.505e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14110, Loss: 1.546e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14120, Loss: 1.407e+01, Y0: 76.872, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14130, Loss: 1.511e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14140, Loss: 1.726e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14150, Loss: 1.622e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14160, Loss: 1.661e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14170, Loss: 1.643e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14180, Loss: 1.627e+01, Y0: 76.870, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14190, Loss: 1.381e+01, Y0: 76.850, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 14200, Loss: 1.503e+01, Y0: 76.960, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 14210, Loss: 1.402e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 14220, Loss: 1.574e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14230, Loss: 1.528e+01, Y0: 76.893, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14240, Loss: 1.565e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14250, Loss: 1.544e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14260, Loss: 1.603e+01, Y0: 76.895, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14270, Loss: 1.519e+01, Y0: 76.822, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14280, Loss: 1.667e+01, Y0: 76.877, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14290, Loss: 1.699e+01, Y0: 76.919, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14300, Loss: 1.523e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14310, Loss: 1.622e+01, Y0: 76.842, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14320, Loss: 1.583e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14330, Loss: 2.529e+01, Y0: 76.928, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14340, Loss: 1.692e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14350, Loss: 1.732e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14360, Loss: 1.476e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14370, Loss: 1.432e+01, Y0: 76.879, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14380, Loss: 1.346e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 14390, Loss: 1.560e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 14400, Loss: 1.472e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 14410, Loss: 1.600e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14420, Loss: 1.931e+01, Y0: 76.881, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14430, Loss: 1.532e+01, Y0: 76.696, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14440, Loss: 1.568e+01, Y0: 76.814, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14450, Loss: 1.959e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14460, Loss: 1.465e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14470, Loss: 1.616e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14480, Loss: 1.413e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14490, Loss: 1.524e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14500, Loss: 1.449e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14510, Loss: 1.444e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14520, Loss: 1.478e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14530, Loss: 1.586e+01, Y0: 76.894, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14540, Loss: 1.530e+01, Y0: 76.881, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14550, Loss: 1.633e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14560, Loss: 1.613e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 14570, Loss: 1.659e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 14580, Loss: 1.736e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 14590, Loss: 1.514e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14600, Loss: 1.565e+01, Y0: 77.007, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14610, Loss: 1.761e+01, Y0: 77.112, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14620, Loss: 1.656e+01, Y0: 76.891, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14630, Loss: 1.535e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14640, Loss: 1.371e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14650, Loss: 2.100e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14660, Loss: 1.445e+01, Y0: 76.856, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14670, Loss: 1.746e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14680, Loss: 1.699e+01, Y0: 76.825, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14690, Loss: 1.391e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14700, Loss: 1.421e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14710, Loss: 1.486e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14720, Loss: 1.818e+01, Y0: 76.844, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14730, Loss: 1.489e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14740, Loss: 1.536e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14750, Loss: 1.368e+01, Y0: 76.950, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 14760, Loss: 1.442e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 14770, Loss: 1.324e+01, Y0: 76.989, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 14780, Loss: 2.126e+01, Y0: 76.709, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 14790, Loss: 2.252e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14800, Loss: 1.448e+01, Y0: 76.733, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14810, Loss: 1.655e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14820, Loss: 2.089e+01, Y0: 76.759, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14830, Loss: 1.563e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14840, Loss: 2.171e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 14850, Loss: 1.786e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14860, Loss: 1.494e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14870, Loss: 1.471e+01, Y0: 76.978, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 14880, Loss: 1.581e+01, Y0: 76.998, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14890, Loss: 1.608e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14900, Loss: 1.572e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 14910, Loss: 1.528e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 14920, Loss: 1.757e+01, Y0: 76.683, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14930, Loss: 1.480e+01, Y0: 76.918, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 14940, Loss: 1.573e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 14950, Loss: 1.599e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 14960, Loss: 2.072e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 14970, Loss: 1.628e+01, Y0: 76.841, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 14980, Loss: 1.467e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 14990, Loss: 1.645e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15000, Loss: 1.411e+01, Y0: 76.803, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15010, Loss: 1.686e+01, Y0: 76.808, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15020, Loss: 1.478e+01, Y0: 76.806, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15030, Loss: 1.798e+01, Y0: 76.797, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15040, Loss: 1.821e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15050, Loss: 1.810e+01, Y0: 76.757, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15060, Loss: 1.615e+01, Y0: 76.877, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15070, Loss: 1.569e+01, Y0: 76.773, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15080, Loss: 1.412e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 15090, Loss: 1.585e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15100, Loss: 1.575e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15110, Loss: 1.502e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 15120, Loss: 1.672e+01, Y0: 76.930, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 15130, Loss: 1.624e+01, Y0: 77.109, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 15140, Loss: 1.901e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15150, Loss: 1.941e+01, Y0: 77.096, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15160, Loss: 1.816e+01, Y0: 77.040, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15170, Loss: 1.885e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15180, Loss: 1.533e+01, Y0: 76.742, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15190, Loss: 1.707e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15200, Loss: 1.398e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15210, Loss: 1.401e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15220, Loss: 1.379e+01, Y0: 76.914, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15230, Loss: 1.740e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15240, Loss: 2.487e+01, Y0: 76.670, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15250, Loss: 1.740e+01, Y0: 76.672, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15260, Loss: 1.763e+01, Y0: 76.847, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15270, Loss: 1.533e+01, Y0: 76.792, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15280, Loss: 1.582e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15290, Loss: 1.514e+01, Y0: 77.024, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 15300, Loss: 1.461e+01, Y0: 76.761, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 15310, Loss: 1.518e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 15320, Loss: 1.797e+01, Y0: 76.710, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15330, Loss: 1.693e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15340, Loss: 1.473e+01, Y0: 76.928, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15350, Loss: 1.630e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15360, Loss: 1.764e+01, Y0: 76.846, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15370, Loss: 1.412e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15380, Loss: 1.459e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15390, Loss: 1.566e+01, Y0: 76.994, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15400, Loss: 1.558e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15410, Loss: 2.901e+01, Y0: 77.216, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15420, Loss: 2.856e+03, Y0: 76.644, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15430, Loss: 2.326e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 15440, Loss: 3.936e+01, Y0: 76.923, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15450, Loss: 1.964e+01, Y0: 77.013, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15460, Loss: 1.700e+01, Y0: 76.938, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15470, Loss: 1.792e+01, Y0: 76.994, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15480, Loss: 1.765e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 15490, Loss: 1.641e+01, Y0: 76.921, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 15500, Loss: 1.803e+01, Y0: 76.803, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 15510, Loss: 1.405e+01, Y0: 76.710, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15520, Loss: 1.741e+01, Y0: 76.796, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15530, Loss: 1.611e+01, Y0: 76.842, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15540, Loss: 1.624e+01, Y0: 76.853, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15550, Loss: 1.553e+01, Y0: 76.822, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15560, Loss: 1.413e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15570, Loss: 1.490e+01, Y0: 76.960, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15580, Loss: 1.500e+01, Y0: 77.034, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15590, Loss: 1.623e+01, Y0: 76.923, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15600, Loss: 1.534e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15610, Loss: 1.519e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15620, Loss: 1.633e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15630, Loss: 1.196e+02, Y0: 76.767, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 15640, Loss: 2.103e+01, Y0: 77.286, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15650, Loss: 1.761e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 15660, Loss: 1.553e+01, Y0: 76.827, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 15670, Loss: 1.730e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 15680, Loss: 1.552e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 15690, Loss: 1.851e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15700, Loss: 1.673e+01, Y0: 76.758, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15710, Loss: 1.380e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15720, Loss: 1.497e+01, Y0: 76.839, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15730, Loss: 1.530e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15740, Loss: 1.361e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15750, Loss: 1.594e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15760, Loss: 1.574e+01, Y0: 76.895, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15770, Loss: 1.372e+01, Y0: 76.819, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15780, Loss: 1.513e+01, Y0: 76.884, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15790, Loss: 1.912e+01, Y0: 76.727, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15800, Loss: 1.630e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15810, Loss: 1.537e+01, Y0: 76.965, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15820, Loss: 1.578e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15830, Loss: 1.864e+01, Y0: 77.116, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15840, Loss: 1.694e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 15850, Loss: 2.475e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 15860, Loss: 1.413e+01, Y0: 76.921, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 15870, Loss: 1.438e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15880, Loss: 1.851e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15890, Loss: 1.562e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15900, Loss: 1.598e+01, Y0: 76.811, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15910, Loss: 2.409e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15920, Loss: 1.621e+01, Y0: 76.990, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15930, Loss: 1.602e+01, Y0: 76.855, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 15940, Loss: 1.995e+01, Y0: 76.707, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15950, Loss: 1.736e+01, Y0: 76.826, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 15960, Loss: 1.427e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 15970, Loss: 1.592e+01, Y0: 76.943, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 15980, Loss: 1.395e+01, Y0: 76.872, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 15990, Loss: 1.417e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16000, Loss: 1.541e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16010, Loss: 1.347e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16020, Loss: 1.444e+01, Y0: 76.880, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16030, Loss: 1.930e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 16040, Loss: 1.808e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 16050, Loss: 1.656e+01, Y0: 76.865, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 16060, Loss: 1.827e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16070, Loss: 1.448e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16080, Loss: 1.560e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16090, Loss: 1.477e+01, Y0: 77.034, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16100, Loss: 1.715e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16110, Loss: 9.603e+01, Y0: 76.808, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16120, Loss: 1.547e+01, Y0: 76.778, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16130, Loss: 2.120e+01, Y0: 76.585, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16140, Loss: 1.622e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16150, Loss: 1.379e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16160, Loss: 1.423e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16170, Loss: 1.520e+01, Y0: 76.886, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16180, Loss: 1.329e+01, Y0: 76.930, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16190, Loss: 1.611e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16200, Loss: 1.773e+01, Y0: 77.007, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16210, Loss: 1.481e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 16220, Loss: 1.741e+01, Y0: 76.753, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 16230, Loss: 1.343e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 16240, Loss: 2.604e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16250, Loss: 1.952e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16260, Loss: 1.451e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16270, Loss: 1.506e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 16280, Loss: 1.516e+01, Y0: 77.073, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16290, Loss: 1.371e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16300, Loss: 1.708e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16310, Loss: 1.346e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16320, Loss: 1.429e+01, Y0: 76.851, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16330, Loss: 1.611e+01, Y0: 76.994, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16340, Loss: 1.510e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16350, Loss: 1.644e+01, Y0: 76.826, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16360, Loss: 1.626e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16370, Loss: 1.403e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16380, Loss: 1.451e+01, Y0: 76.955, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16390, Loss: 1.418e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16400, Loss: 1.420e+01, Y0: 76.921, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 16410, Loss: 1.506e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 16420, Loss: 1.596e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 16430, Loss: 1.524e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16440, Loss: 1.382e+01, Y0: 76.976, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16450, Loss: 1.392e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16460, Loss: 1.545e+01, Y0: 77.022, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 16470, Loss: 1.550e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16480, Loss: 1.514e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 16490, Loss: 1.901e+01, Y0: 76.879, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16500, Loss: 2.226e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16510, Loss: 1.802e+01, Y0: 76.682, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16520, Loss: 1.844e+01, Y0: 76.818, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16530, Loss: 1.502e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16540, Loss: 3.219e+01, Y0: 77.152, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16550, Loss: 1.454e+01, Y0: 76.816, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16560, Loss: 1.951e+01, Y0: 76.706, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16570, Loss: 1.562e+01, Y0: 76.768, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16580, Loss: 1.481e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16590, Loss: 1.298e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 16600, Loss: 1.296e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 16610, Loss: 1.455e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 16620, Loss: 1.282e+02, Y0: 77.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16630, Loss: 3.643e+01, Y0: 76.876, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 16640, Loss: 3.073e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16650, Loss: 1.847e+01, Y0: 76.867, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16660, Loss: 1.634e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16670, Loss: 1.625e+01, Y0: 77.054, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16680, Loss: 1.561e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16690, Loss: 1.512e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16700, Loss: 1.482e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16710, Loss: 1.427e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16720, Loss: 1.322e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16730, Loss: 1.375e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16740, Loss: 1.310e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16750, Loss: 1.643e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16760, Loss: 1.715e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16770, Loss: 1.407e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16780, Loss: 1.572e+01, Y0: 77.044, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 16790, Loss: 1.439e+01, Y0: 76.923, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 16800, Loss: 1.820e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 16810, Loss: 1.486e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16820, Loss: 1.442e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16830, Loss: 1.536e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16840, Loss: 1.356e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16850, Loss: 1.468e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16860, Loss: 1.459e+01, Y0: 76.917, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 16870, Loss: 1.518e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16880, Loss: 1.566e+01, Y0: 76.990, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16890, Loss: 1.397e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 16900, Loss: 1.419e+01, Y0: 76.893, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16910, Loss: 1.362e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 16920, Loss: 1.529e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16930, Loss: 1.439e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16940, Loss: 1.434e+01, Y0: 76.805, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 16950, Loss: 1.323e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 16960, Loss: 1.587e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 16970, Loss: 1.556e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 16980, Loss: 1.552e+01, Y0: 76.829, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 16990, Loss: 1.491e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17000, Loss: 1.460e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17010, Loss: 1.432e+01, Y0: 76.856, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17020, Loss: 1.591e+01, Y0: 76.800, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17030, Loss: 1.501e+01, Y0: 76.870, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17040, Loss: 1.347e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17050, Loss: 1.521e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17060, Loss: 1.390e+01, Y0: 76.877, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 17070, Loss: 1.722e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17080, Loss: 1.350e+01, Y0: 76.889, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17090, Loss: 1.997e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17100, Loss: 1.416e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17110, Loss: 1.364e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17120, Loss: 1.453e+01, Y0: 76.928, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17130, Loss: 1.807e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17140, Loss: 1.333e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17150, Loss: 1.411e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 17160, Loss: 1.506e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 17170, Loss: 1.493e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 17180, Loss: 1.539e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17190, Loss: 1.519e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17200, Loss: 1.845e+01, Y0: 76.783, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17210, Loss: 1.479e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17220, Loss: 1.326e+01, Y0: 76.914, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17230, Loss: 1.393e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17240, Loss: 1.424e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17250, Loss: 1.383e+01, Y0: 76.982, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17260, Loss: 1.598e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17270, Loss: 1.824e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17280, Loss: 1.648e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17290, Loss: 1.382e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17300, Loss: 1.434e+01, Y0: 77.106, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17310, Loss: 1.578e+01, Y0: 76.887, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17320, Loss: 2.738e+01, Y0: 77.310, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17330, Loss: 2.245e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 17340, Loss: 1.377e+01, Y0: 77.044, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 17350, Loss: 1.608e+01, Y0: 77.087, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 17360, Loss: 1.479e+01, Y0: 77.050, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17370, Loss: 1.730e+01, Y0: 76.743, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17380, Loss: 1.500e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 17390, Loss: 1.425e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17400, Loss: 1.296e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 17410, Loss: 1.995e+02, Y0: 76.735, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17420, Loss: 1.635e+01, Y0: 76.839, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17430, Loss: 1.695e+01, Y0: 76.886, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17440, Loss: 1.390e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17450, Loss: 1.443e+01, Y0: 76.891, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17460, Loss: 1.347e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17470, Loss: 1.486e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17480, Loss: 1.490e+01, Y0: 76.918, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 17490, Loss: 1.292e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17500, Loss: 1.274e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17510, Loss: 1.478e+01, Y0: 76.909, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 17520, Loss: 1.410e+01, Y0: 76.827, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 17530, Loss: 1.481e+01, Y0: 76.820, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 17540, Loss: 1.487e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17550, Loss: 1.453e+01, Y0: 77.041, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17560, Loss: 1.374e+01, Y0: 77.048, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17570, Loss: 1.639e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17580, Loss: 1.435e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17590, Loss: 1.440e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17600, Loss: 1.367e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17610, Loss: 1.471e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17620, Loss: 1.382e+01, Y0: 76.918, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17630, Loss: 1.263e+01, Y0: 76.813, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17640, Loss: 1.419e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17650, Loss: 1.374e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17660, Loss: 1.384e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17670, Loss: 1.986e+01, Y0: 77.227, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17680, Loss: 1.746e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17690, Loss: 1.345e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17700, Loss: 1.483e+01, Y0: 76.811, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 17710, Loss: 1.399e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 17720, Loss: 1.599e+01, Y0: 77.013, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 17730, Loss: 1.265e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17740, Loss: 1.826e+01, Y0: 76.943, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17750, Loss: 1.488e+01, Y0: 77.098, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17760, Loss: 1.655e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17770, Loss: 1.436e+01, Y0: 77.070, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17780, Loss: 1.490e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17790, Loss: 1.483e+01, Y0: 76.993, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17800, Loss: 1.732e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17810, Loss: 1.267e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17820, Loss: 1.413e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17830, Loss: 1.490e+01, Y0: 76.990, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17840, Loss: 1.884e+01, Y0: 76.803, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17850, Loss: 1.454e+01, Y0: 76.902, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17860, Loss: 1.642e+01, Y0: 77.254, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17870, Loss: 1.538e+01, Y0: 77.113, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 17880, Loss: 2.087e+01, Y0: 77.175, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17890, Loss: 1.877e+01, Y0: 76.673, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 17900, Loss: 1.453e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 17910, Loss: 1.480e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 17920, Loss: 1.985e+01, Y0: 76.825, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17930, Loss: 1.893e+01, Y0: 77.006, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17940, Loss: 1.553e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 17950, Loss: 1.404e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17960, Loss: 1.501e+01, Y0: 76.887, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 17970, Loss: 2.986e+01, Y0: 76.851, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 17980, Loss: 1.645e+01, Y0: 77.045, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 17990, Loss: 1.503e+01, Y0: 76.822, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18000, Loss: 1.475e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 18010, Loss: 1.514e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18020, Loss: 1.698e+01, Y0: 76.979, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18030, Loss: 1.327e+01, Y0: 76.874, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18040, Loss: 1.462e+01, Y0: 77.108, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18050, Loss: 1.290e+01, Y0: 76.875, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 18060, Loss: 1.382e+01, Y0: 77.029, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18070, Loss: 1.225e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 18080, Loss: 1.312e+01, Y0: 76.969, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 18090, Loss: 1.375e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 18100, Loss: 1.861e+01, Y0: 77.048, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18110, Loss: 1.407e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18120, Loss: 1.645e+01, Y0: 77.082, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18130, Loss: 2.422e+01, Y0: 77.135, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18140, Loss: 1.609e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18150, Loss: 1.691e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18160, Loss: 1.265e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18170, Loss: 4.090e+01, Y0: 76.622, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18180, Loss: 1.400e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18190, Loss: 1.553e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 18200, Loss: 2.848e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18210, Loss: 1.656e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18220, Loss: 1.547e+01, Y0: 76.762, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18230, Loss: 1.366e+01, Y0: 76.858, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18240, Loss: 1.254e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18250, Loss: 1.484e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18260, Loss: 1.629e+01, Y0: 77.131, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 18270, Loss: 1.281e+01, Y0: 77.035, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 18280, Loss: 1.591e+01, Y0: 76.815, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 18290, Loss: 1.441e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18300, Loss: 1.416e+01, Y0: 76.850, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18310, Loss: 1.592e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18320, Loss: 3.678e+01, Y0: 76.995, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18330, Loss: 2.447e+01, Y0: 76.781, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 18340, Loss: 1.704e+01, Y0: 76.817, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18350, Loss: 1.576e+01, Y0: 76.863, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18360, Loss: 1.386e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18370, Loss: 1.406e+01, Y0: 76.950, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18380, Loss: 1.811e+01, Y0: 77.059, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18390, Loss: 1.537e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.55s\n",
      "Epoch: 18400, Loss: 1.558e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18410, Loss: 1.400e+01, Y0: 76.782, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 18420, Loss: 1.354e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18430, Loss: 1.561e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18440, Loss: 1.403e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18450, Loss: 1.355e+01, Y0: 77.168, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 18460, Loss: 1.382e+01, Y0: 77.078, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 18470, Loss: 1.381e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 18480, Loss: 1.463e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18490, Loss: 1.284e+01, Y0: 77.098, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18500, Loss: 1.895e+01, Y0: 76.707, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18510, Loss: 1.430e+01, Y0: 76.734, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18520, Loss: 1.428e+01, Y0: 77.008, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18530, Loss: 1.335e+01, Y0: 76.887, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18540, Loss: 1.279e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18550, Loss: 1.876e+01, Y0: 76.996, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18560, Loss: 1.514e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18570, Loss: 1.663e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18580, Loss: 1.503e+01, Y0: 77.021, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18590, Loss: 1.259e+01, Y0: 77.077, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18600, Loss: 1.752e+01, Y0: 77.104, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18610, Loss: 1.305e+01, Y0: 77.001, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 18620, Loss: 1.581e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18630, Loss: 1.661e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 18640, Loss: 1.811e+01, Y0: 76.717, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 18650, Loss: 2.911e+01, Y0: 77.025, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 18660, Loss: 2.446e+01, Y0: 76.707, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 18670, Loss: 1.768e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18680, Loss: 1.570e+01, Y0: 76.936, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18690, Loss: 1.399e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18700, Loss: 1.518e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 18710, Loss: 1.324e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 18720, Loss: 1.981e+01, Y0: 77.059, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18730, Loss: 1.867e+01, Y0: 76.811, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18740, Loss: 1.422e+01, Y0: 76.906, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18750, Loss: 1.589e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18760, Loss: 1.300e+01, Y0: 76.902, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 18770, Loss: 1.526e+01, Y0: 76.948, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 18780, Loss: 1.487e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18790, Loss: 1.532e+01, Y0: 76.976, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18800, Loss: 1.394e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 18810, Loss: 1.438e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 18820, Loss: 1.346e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 18830, Loss: 1.303e+01, Y0: 77.031, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 18840, Loss: 1.381e+01, Y0: 77.040, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 18850, Loss: 1.410e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18860, Loss: 1.422e+01, Y0: 76.870, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18870, Loss: 1.642e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18880, Loss: 1.401e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18890, Loss: 1.566e+01, Y0: 76.736, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18900, Loss: 1.408e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18910, Loss: 1.413e+01, Y0: 76.809, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18920, Loss: 1.474e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18930, Loss: 1.449e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18940, Loss: 1.408e+01, Y0: 77.097, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18950, Loss: 1.873e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18960, Loss: 1.928e+01, Y0: 77.138, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 18970, Loss: 1.655e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 18980, Loss: 1.668e+01, Y0: 77.126, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 18990, Loss: 2.330e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19000, Loss: 1.450e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19010, Loss: 1.297e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 19020, Loss: 1.290e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 19030, Loss: 2.431e+01, Y0: 76.758, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 19040, Loss: 1.406e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19050, Loss: 1.757e+01, Y0: 77.191, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19060, Loss: 1.454e+01, Y0: 76.884, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19070, Loss: 1.243e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19080, Loss: 1.364e+01, Y0: 77.029, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19090, Loss: 1.436e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19100, Loss: 1.420e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19110, Loss: 1.270e+01, Y0: 77.066, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19120, Loss: 1.427e+01, Y0: 76.862, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19130, Loss: 1.332e+01, Y0: 76.782, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19140, Loss: 1.872e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19150, Loss: 1.390e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19160, Loss: 1.697e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19170, Loss: 1.445e+01, Y0: 76.849, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19180, Loss: 1.278e+01, Y0: 76.852, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19190, Loss: 1.523e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19200, Loss: 2.058e+01, Y0: 76.799, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 19210, Loss: 1.469e+01, Y0: 76.844, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 19220, Loss: 1.425e+01, Y0: 77.073, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 19230, Loss: 1.683e+01, Y0: 77.102, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19240, Loss: 4.439e+01, Y0: 76.690, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19250, Loss: 1.371e+01, Y0: 76.760, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19260, Loss: 1.552e+01, Y0: 76.913, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19270, Loss: 1.392e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19280, Loss: 1.329e+01, Y0: 77.053, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 19290, Loss: 1.699e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19300, Loss: 1.793e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19310, Loss: 1.555e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19320, Loss: 1.477e+01, Y0: 76.918, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19330, Loss: 1.433e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19340, Loss: 1.328e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19350, Loss: 1.396e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19360, Loss: 1.316e+01, Y0: 76.894, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19370, Loss: 1.840e+01, Y0: 77.058, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19380, Loss: 1.397e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19390, Loss: 1.298e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 19400, Loss: 1.353e+01, Y0: 77.058, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 19410, Loss: 1.731e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 19420, Loss: 1.472e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19430, Loss: 1.307e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19440, Loss: 1.244e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19450, Loss: 1.461e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19460, Loss: 1.337e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19470, Loss: 1.713e+01, Y0: 77.039, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19480, Loss: 1.933e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19490, Loss: 1.359e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19500, Loss: 1.565e+01, Y0: 76.731, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19510, Loss: 1.654e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19520, Loss: 1.809e+01, Y0: 76.723, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19530, Loss: 1.297e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19540, Loss: 1.321e+01, Y0: 76.864, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19550, Loss: 1.241e+01, Y0: 76.780, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19560, Loss: 1.492e+01, Y0: 77.142, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19570, Loss: 2.437e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19580, Loss: 1.404e+01, Y0: 77.132, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 19590, Loss: 1.518e+01, Y0: 77.099, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 19600, Loss: 1.414e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 19610, Loss: 1.541e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19620, Loss: 1.313e+01, Y0: 77.067, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19630, Loss: 2.128e+01, Y0: 77.436, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19640, Loss: 1.590e+01, Y0: 76.885, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19650, Loss: 1.394e+01, Y0: 77.062, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19660, Loss: 1.414e+01, Y0: 77.023, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19670, Loss: 1.500e+01, Y0: 77.001, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19680, Loss: 1.393e+01, Y0: 76.857, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19690, Loss: 1.416e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19700, Loss: 1.799e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19710, Loss: 1.656e+01, Y0: 76.788, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19720, Loss: 1.535e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19730, Loss: 1.430e+01, Y0: 76.961, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19740, Loss: 2.135e+01, Y0: 77.096, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19750, Loss: 1.289e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19760, Loss: 1.309e+01, Y0: 76.982, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19770, Loss: 1.434e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 19780, Loss: 1.557e+01, Y0: 77.041, Learning Rate: 1.000e-04, Time: 0.96s\n",
      "Epoch: 19790, Loss: 1.277e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 19800, Loss: 1.502e+01, Y0: 76.999, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19810, Loss: 1.372e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 19820, Loss: 1.349e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19830, Loss: 1.475e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19840, Loss: 1.428e+01, Y0: 77.000, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19850, Loss: 1.495e+01, Y0: 77.056, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19860, Loss: 1.596e+01, Y0: 76.916, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19870, Loss: 1.543e+01, Y0: 77.000, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 19880, Loss: 1.161e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19890, Loss: 1.382e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19900, Loss: 1.387e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 19910, Loss: 1.601e+01, Y0: 77.104, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19920, Loss: 1.286e+01, Y0: 76.861, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 19930, Loss: 1.469e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 19940, Loss: 1.123e+02, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 19950, Loss: 2.432e+01, Y0: 76.667, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 19960, Loss: 2.437e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 19970, Loss: 1.748e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 19980, Loss: 1.434e+01, Y0: 77.066, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 19990, Loss: 1.632e+01, Y0: 76.989, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20000, Loss: 1.793e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20010, Loss: 1.806e+01, Y0: 77.069, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20020, Loss: 1.362e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 20030, Loss: 1.482e+01, Y0: 76.909, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20040, Loss: 1.333e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20050, Loss: 1.404e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20060, Loss: 1.300e+01, Y0: 77.130, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20070, Loss: 1.409e+01, Y0: 77.037, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20080, Loss: 1.304e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 20090, Loss: 1.355e+01, Y0: 76.923, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20100, Loss: 1.516e+01, Y0: 76.999, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20110, Loss: 1.270e+01, Y0: 76.886, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20120, Loss: 1.239e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20130, Loss: 1.218e+01, Y0: 77.025, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20140, Loss: 1.202e+01, Y0: 77.035, Learning Rate: 1.000e-04, Time: 0.89s\n",
      "Epoch: 20150, Loss: 1.319e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.88s\n",
      "Epoch: 20160, Loss: 1.370e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20170, Loss: 1.291e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20180, Loss: 1.658e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20190, Loss: 1.315e+01, Y0: 77.055, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20200, Loss: 1.330e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20210, Loss: 1.157e+01, Y0: 77.108, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20220, Loss: 1.317e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20230, Loss: 1.503e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 20240, Loss: 1.311e+01, Y0: 77.087, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20250, Loss: 1.226e+01, Y0: 77.041, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20260, Loss: 1.442e+01, Y0: 77.082, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20270, Loss: 1.572e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20280, Loss: 1.563e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20290, Loss: 1.479e+01, Y0: 77.046, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20300, Loss: 1.415e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20310, Loss: 1.283e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20320, Loss: 1.452e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 20330, Loss: 1.489e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 20340, Loss: 1.346e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 20350, Loss: 1.510e+01, Y0: 76.832, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20360, Loss: 1.371e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20370, Loss: 1.701e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20380, Loss: 1.377e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20390, Loss: 1.396e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20400, Loss: 1.473e+01, Y0: 77.081, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20410, Loss: 1.278e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20420, Loss: 1.387e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20430, Loss: 1.590e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20440, Loss: 1.305e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20450, Loss: 1.374e+01, Y0: 77.111, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20460, Loss: 1.366e+01, Y0: 76.840, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20470, Loss: 1.410e+01, Y0: 76.994, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20480, Loss: 1.492e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20490, Loss: 1.304e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 20500, Loss: 1.330e+01, Y0: 76.878, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20510, Loss: 1.778e+01, Y0: 77.019, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 20520, Loss: 3.419e+01, Y0: 76.779, Learning Rate: 1.000e-04, Time: 0.89s\n",
      "Epoch: 20530, Loss: 2.729e+01, Y0: 77.062, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 20540, Loss: 3.166e+01, Y0: 77.344, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20550, Loss: 1.505e+01, Y0: 77.272, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 20560, Loss: 1.605e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20570, Loss: 1.443e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20580, Loss: 1.352e+01, Y0: 76.943, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20590, Loss: 1.434e+01, Y0: 76.960, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20600, Loss: 1.214e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20610, Loss: 1.508e+01, Y0: 77.006, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20620, Loss: 1.322e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20630, Loss: 1.434e+01, Y0: 76.984, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20640, Loss: 1.409e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20650, Loss: 1.323e+01, Y0: 76.937, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 20660, Loss: 1.291e+01, Y0: 77.029, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20670, Loss: 1.496e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 20680, Loss: 1.364e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20690, Loss: 1.260e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 20700, Loss: 1.161e+01, Y0: 76.943, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 20710, Loss: 1.396e+01, Y0: 76.996, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 20720, Loss: 1.402e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20730, Loss: 2.690e+01, Y0: 76.552, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20740, Loss: 3.119e+01, Y0: 76.693, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20750, Loss: 2.433e+01, Y0: 77.041, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20760, Loss: 1.551e+01, Y0: 77.124, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20770, Loss: 1.447e+01, Y0: 77.140, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20780, Loss: 1.344e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20790, Loss: 1.174e+01, Y0: 76.901, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20800, Loss: 1.366e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20810, Loss: 1.426e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20820, Loss: 1.457e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20830, Loss: 1.312e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20840, Loss: 1.572e+01, Y0: 76.998, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20850, Loss: 1.344e+01, Y0: 77.056, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20860, Loss: 1.446e+01, Y0: 77.177, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20870, Loss: 1.500e+01, Y0: 77.042, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 20880, Loss: 1.355e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 20890, Loss: 1.372e+01, Y0: 76.857, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 20900, Loss: 1.392e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 20910, Loss: 1.200e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20920, Loss: 1.316e+01, Y0: 77.031, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 20930, Loss: 1.245e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20940, Loss: 1.380e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20950, Loss: 1.294e+01, Y0: 77.031, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 20960, Loss: 1.326e+01, Y0: 76.938, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 20970, Loss: 1.362e+01, Y0: 77.062, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 20980, Loss: 1.324e+01, Y0: 77.113, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 20990, Loss: 1.497e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21000, Loss: 1.580e+01, Y0: 77.055, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21010, Loss: 1.564e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21020, Loss: 1.490e+01, Y0: 77.067, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21030, Loss: 1.689e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21040, Loss: 1.209e+01, Y0: 77.024, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21050, Loss: 1.471e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21060, Loss: 1.292e+01, Y0: 77.035, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 21070, Loss: 8.853e+01, Y0: 76.284, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 21080, Loss: 5.555e+01, Y0: 76.442, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 21090, Loss: 4.696e+01, Y0: 77.310, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21100, Loss: 2.485e+01, Y0: 76.759, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21110, Loss: 2.004e+01, Y0: 77.115, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21120, Loss: 1.408e+01, Y0: 76.989, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21130, Loss: 1.261e+01, Y0: 77.059, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21140, Loss: 1.148e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21150, Loss: 1.197e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21160, Loss: 1.336e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21170, Loss: 1.275e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21180, Loss: 1.163e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 21190, Loss: 1.382e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 21200, Loss: 1.353e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21210, Loss: 1.283e+01, Y0: 76.872, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21220, Loss: 1.329e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21230, Loss: 1.284e+01, Y0: 76.938, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 21240, Loss: 1.537e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21250, Loss: 1.179e+01, Y0: 76.845, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 21260, Loss: 1.234e+01, Y0: 76.841, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 21270, Loss: 1.296e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 21280, Loss: 1.223e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21290, Loss: 1.302e+01, Y0: 77.074, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21300, Loss: 1.369e+01, Y0: 77.045, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21310, Loss: 1.403e+01, Y0: 77.003, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21320, Loss: 1.188e+01, Y0: 77.044, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21330, Loss: 1.325e+01, Y0: 76.884, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21340, Loss: 1.257e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21350, Loss: 1.425e+01, Y0: 77.070, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21360, Loss: 1.416e+01, Y0: 77.103, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21370, Loss: 1.370e+01, Y0: 77.039, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21380, Loss: 1.359e+01, Y0: 76.974, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21390, Loss: 1.366e+01, Y0: 77.096, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21400, Loss: 1.417e+01, Y0: 77.124, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21410, Loss: 1.368e+01, Y0: 77.130, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21420, Loss: 1.416e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21430, Loss: 1.473e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 21440, Loss: 1.177e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 21450, Loss: 1.249e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 21460, Loss: 1.244e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 21470, Loss: 1.383e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21480, Loss: 1.275e+01, Y0: 76.979, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21490, Loss: 1.222e+01, Y0: 76.916, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 21500, Loss: 1.314e+01, Y0: 76.901, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21510, Loss: 1.335e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21520, Loss: 1.532e+01, Y0: 77.140, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21530, Loss: 1.369e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21540, Loss: 1.421e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21550, Loss: 1.366e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21560, Loss: 1.352e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21570, Loss: 1.492e+01, Y0: 77.056, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21580, Loss: 1.508e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21590, Loss: 1.343e+01, Y0: 76.876, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 21600, Loss: 1.371e+01, Y0: 76.922, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21610, Loss: 1.417e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21620, Loss: 1.183e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 21630, Loss: 1.208e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 21640, Loss: 1.393e+01, Y0: 76.905, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 21650, Loss: 1.293e+01, Y0: 77.075, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 21660, Loss: 1.531e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21670, Loss: 1.643e+01, Y0: 77.119, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21680, Loss: 1.549e+01, Y0: 76.775, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21690, Loss: 1.431e+01, Y0: 76.887, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21700, Loss: 1.377e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21710, Loss: 1.264e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21720, Loss: 1.583e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21730, Loss: 1.364e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 21740, Loss: 1.301e+01, Y0: 77.184, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21750, Loss: 1.461e+01, Y0: 77.105, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21760, Loss: 1.346e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21770, Loss: 1.343e+01, Y0: 76.995, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21780, Loss: 1.231e+01, Y0: 77.056, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21790, Loss: 1.485e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21800, Loss: 1.566e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21810, Loss: 1.612e+01, Y0: 76.752, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 21820, Loss: 1.635e+01, Y0: 77.139, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 21830, Loss: 1.813e+01, Y0: 76.884, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 21840, Loss: 1.852e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21850, Loss: 2.042e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21860, Loss: 2.264e+01, Y0: 77.204, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21870, Loss: 1.449e+01, Y0: 76.743, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21880, Loss: 1.193e+01, Y0: 76.755, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21890, Loss: 1.438e+01, Y0: 76.936, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21900, Loss: 1.208e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21910, Loss: 1.249e+01, Y0: 77.095, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21920, Loss: 1.258e+01, Y0: 77.076, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21930, Loss: 1.371e+01, Y0: 76.930, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 21940, Loss: 1.616e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21950, Loss: 1.315e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 21960, Loss: 1.405e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 21970, Loss: 1.605e+01, Y0: 77.139, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 21980, Loss: 1.277e+01, Y0: 76.993, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 21990, Loss: 1.279e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22000, Loss: 1.306e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 22010, Loss: 1.205e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 22020, Loss: 1.170e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 22030, Loss: 1.557e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22040, Loss: 1.321e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22050, Loss: 1.279e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22060, Loss: 1.205e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22070, Loss: 1.252e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22080, Loss: 1.238e+01, Y0: 77.092, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22090, Loss: 3.469e+01, Y0: 77.206, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22100, Loss: 2.141e+01, Y0: 76.593, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22110, Loss: 1.292e+01, Y0: 76.782, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22120, Loss: 1.559e+01, Y0: 77.027, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22130, Loss: 1.314e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 22140, Loss: 1.620e+01, Y0: 77.070, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22150, Loss: 1.436e+01, Y0: 76.961, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22160, Loss: 1.367e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22170, Loss: 2.197e+01, Y0: 77.201, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22180, Loss: 1.937e+01, Y0: 76.867, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 22190, Loss: 1.411e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 22200, Loss: 1.361e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 22210, Loss: 1.194e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22220, Loss: 1.270e+01, Y0: 77.081, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22230, Loss: 1.436e+01, Y0: 76.836, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22240, Loss: 1.571e+01, Y0: 77.044, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22250, Loss: 1.218e+01, Y0: 77.081, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22260, Loss: 1.393e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 22270, Loss: 1.317e+01, Y0: 77.017, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22280, Loss: 2.706e+01, Y0: 76.768, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22290, Loss: 1.731e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22300, Loss: 1.200e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22310, Loss: 1.201e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22320, Loss: 1.525e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22330, Loss: 1.342e+01, Y0: 76.798, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22340, Loss: 1.903e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22350, Loss: 1.461e+01, Y0: 77.159, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22360, Loss: 1.512e+01, Y0: 77.062, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22370, Loss: 1.462e+01, Y0: 76.936, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 22380, Loss: 1.500e+01, Y0: 77.114, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 22390, Loss: 1.210e+01, Y0: 77.149, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 22400, Loss: 1.260e+01, Y0: 77.048, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22410, Loss: 1.339e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22420, Loss: 1.265e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22430, Loss: 1.234e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22440, Loss: 1.311e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22450, Loss: 1.381e+01, Y0: 76.754, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22460, Loss: 1.490e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22470, Loss: 1.381e+01, Y0: 77.079, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22480, Loss: 1.375e+01, Y0: 76.998, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22490, Loss: 1.856e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22500, Loss: 1.864e+01, Y0: 76.854, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22510, Loss: 1.445e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22520, Loss: 1.571e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22530, Loss: 1.902e+01, Y0: 76.850, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22540, Loss: 1.325e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22550, Loss: 1.473e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22560, Loss: 1.279e+01, Y0: 77.072, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 22570, Loss: 1.173e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 22580, Loss: 1.328e+01, Y0: 77.136, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22590, Loss: 1.278e+01, Y0: 77.092, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22600, Loss: 1.467e+01, Y0: 77.260, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 22610, Loss: 1.441e+01, Y0: 77.082, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22620, Loss: 1.775e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22630, Loss: 2.024e+01, Y0: 76.684, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22640, Loss: 1.333e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22650, Loss: 1.328e+01, Y0: 77.076, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22660, Loss: 1.297e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22670, Loss: 1.410e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22680, Loss: 1.150e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 22690, Loss: 1.166e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22700, Loss: 1.089e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22710, Loss: 2.605e+01, Y0: 76.710, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22720, Loss: 1.309e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22730, Loss: 1.331e+01, Y0: 76.913, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22740, Loss: 1.885e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 22750, Loss: 1.263e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 22760, Loss: 1.404e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 22770, Loss: 1.573e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22780, Loss: 3.762e+01, Y0: 76.577, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22790, Loss: 1.558e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22800, Loss: 1.446e+01, Y0: 77.060, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22810, Loss: 1.236e+01, Y0: 76.985, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 22820, Loss: 1.185e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22830, Loss: 1.445e+01, Y0: 76.863, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22840, Loss: 1.628e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 22850, Loss: 1.262e+01, Y0: 76.997, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22860, Loss: 1.359e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22870, Loss: 1.302e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22880, Loss: 1.186e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22890, Loss: 1.274e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22900, Loss: 1.242e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22910, Loss: 1.322e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22920, Loss: 1.349e+01, Y0: 77.066, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22930, Loss: 1.131e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 22940, Loss: 1.156e+01, Y0: 77.031, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 22950, Loss: 1.225e+01, Y0: 77.048, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 22960, Loss: 1.309e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22970, Loss: 1.200e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 22980, Loss: 1.462e+01, Y0: 77.167, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 22990, Loss: 1.444e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23000, Loss: 1.548e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23010, Loss: 1.411e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 23020, Loss: 1.356e+01, Y0: 77.017, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23030, Loss: 1.436e+01, Y0: 76.891, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23040, Loss: 1.300e+01, Y0: 77.022, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23050, Loss: 1.285e+01, Y0: 77.073, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23060, Loss: 1.399e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23070, Loss: 1.287e+01, Y0: 77.099, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23080, Loss: 1.444e+01, Y0: 77.058, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 23090, Loss: 1.422e+01, Y0: 76.934, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 23100, Loss: 1.298e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23110, Loss: 1.226e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23120, Loss: 1.388e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 23130, Loss: 1.324e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.88s\n",
      "Epoch: 23140, Loss: 1.651e+01, Y0: 77.153, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23150, Loss: 1.287e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23160, Loss: 1.407e+01, Y0: 76.853, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23170, Loss: 1.485e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23180, Loss: 1.422e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23190, Loss: 1.265e+01, Y0: 76.867, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23200, Loss: 1.391e+01, Y0: 76.802, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23210, Loss: 1.444e+01, Y0: 77.076, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23220, Loss: 1.253e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23230, Loss: 1.267e+01, Y0: 76.860, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23240, Loss: 2.671e+01, Y0: 77.046, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23250, Loss: 1.681e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23260, Loss: 1.260e+01, Y0: 76.887, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23270, Loss: 1.274e+01, Y0: 77.097, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23280, Loss: 1.723e+01, Y0: 76.998, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23290, Loss: 1.462e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23300, Loss: 1.572e+01, Y0: 76.834, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 23310, Loss: 1.299e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 23320, Loss: 1.494e+01, Y0: 77.137, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 23330, Loss: 1.338e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23340, Loss: 1.417e+01, Y0: 77.046, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23350, Loss: 1.452e+01, Y0: 76.982, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23360, Loss: 1.506e+01, Y0: 76.897, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23370, Loss: 1.271e+01, Y0: 77.073, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23380, Loss: 1.336e+01, Y0: 77.141, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23390, Loss: 1.363e+01, Y0: 76.994, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23400, Loss: 1.266e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23410, Loss: 1.199e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23420, Loss: 1.502e+01, Y0: 77.076, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23430, Loss: 1.232e+01, Y0: 76.891, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23440, Loss: 1.218e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23450, Loss: 1.711e+01, Y0: 76.771, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23460, Loss: 6.716e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23470, Loss: 2.018e+01, Y0: 77.159, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23480, Loss: 1.752e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23490, Loss: 1.513e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 23500, Loss: 1.263e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 23510, Loss: 1.193e+01, Y0: 76.923, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 23520, Loss: 1.399e+01, Y0: 76.999, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 23530, Loss: 1.255e+01, Y0: 76.871, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23540, Loss: 1.680e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23550, Loss: 1.117e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 23560, Loss: 1.402e+01, Y0: 76.978, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23570, Loss: 1.650e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23580, Loss: 1.153e+01, Y0: 77.069, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23590, Loss: 1.335e+01, Y0: 77.168, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23600, Loss: 1.322e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23610, Loss: 1.309e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23620, Loss: 1.167e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23630, Loss: 1.367e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23640, Loss: 1.301e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23650, Loss: 1.385e+01, Y0: 76.973, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23660, Loss: 1.340e+01, Y0: 76.976, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 23670, Loss: 1.184e+01, Y0: 77.062, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 23680, Loss: 1.409e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 23690, Loss: 1.227e+01, Y0: 77.061, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 23700, Loss: 1.274e+01, Y0: 77.045, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23710, Loss: 1.219e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23720, Loss: 1.399e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23730, Loss: 1.196e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23740, Loss: 1.047e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23750, Loss: 1.307e+01, Y0: 76.979, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23760, Loss: 1.247e+01, Y0: 76.888, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23770, Loss: 1.232e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23780, Loss: 1.280e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 23790, Loss: 1.116e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23800, Loss: 1.345e+01, Y0: 77.021, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23810, Loss: 1.303e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23820, Loss: 1.259e+01, Y0: 76.893, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23830, Loss: 1.618e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23840, Loss: 1.120e+01, Y0: 76.955, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 23850, Loss: 1.252e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23860, Loss: 1.606e+01, Y0: 77.117, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 23870, Loss: 1.221e+01, Y0: 76.821, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 23880, Loss: 1.427e+01, Y0: 76.809, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 23890, Loss: 1.097e+01, Y0: 76.831, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23900, Loss: 1.586e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23910, Loss: 1.364e+01, Y0: 76.814, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23920, Loss: 1.285e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23930, Loss: 1.724e+01, Y0: 76.867, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23940, Loss: 1.237e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23950, Loss: 1.872e+01, Y0: 77.025, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23960, Loss: 1.379e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23970, Loss: 1.299e+01, Y0: 76.780, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 23980, Loss: 1.257e+01, Y0: 77.066, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 23990, Loss: 1.060e+02, Y0: 77.137, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 24000, Loss: 4.044e+01, Y0: 77.809, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24010, Loss: 2.897e+01, Y0: 77.486, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24020, Loss: 2.444e+01, Y0: 77.055, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24030, Loss: 1.661e+01, Y0: 76.746, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24040, Loss: 1.386e+01, Y0: 76.936, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24050, Loss: 1.398e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 24060, Loss: 1.944e+01, Y0: 76.736, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 24070, Loss: 1.489e+01, Y0: 76.963, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 24080, Loss: 1.472e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24090, Loss: 1.412e+01, Y0: 76.960, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24100, Loss: 1.306e+01, Y0: 77.078, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24110, Loss: 1.378e+01, Y0: 77.111, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24120, Loss: 1.241e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24130, Loss: 1.438e+01, Y0: 77.122, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24140, Loss: 1.343e+01, Y0: 77.040, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24150, Loss: 1.196e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24160, Loss: 1.219e+01, Y0: 76.967, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24170, Loss: 1.252e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24180, Loss: 1.198e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24190, Loss: 1.320e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24200, Loss: 1.168e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 24210, Loss: 1.225e+01, Y0: 76.955, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24220, Loss: 1.315e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24230, Loss: 1.342e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 24240, Loss: 1.233e+01, Y0: 76.969, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 24250, Loss: 1.407e+01, Y0: 77.076, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 24260, Loss: 1.292e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24270, Loss: 1.165e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24280, Loss: 1.595e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 24290, Loss: 1.354e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24300, Loss: 1.178e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24310, Loss: 1.231e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24320, Loss: 1.277e+01, Y0: 77.057, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24330, Loss: 1.256e+01, Y0: 77.165, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24340, Loss: 1.222e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24350, Loss: 1.311e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24360, Loss: 1.244e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24370, Loss: 1.375e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24380, Loss: 1.282e+01, Y0: 77.057, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24390, Loss: 1.156e+01, Y0: 77.057, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24400, Loss: 1.236e+01, Y0: 77.057, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24410, Loss: 5.558e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24420, Loss: 2.253e+01, Y0: 76.583, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 24430, Loss: 2.059e+01, Y0: 77.248, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 24440, Loss: 1.754e+01, Y0: 77.152, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 24450, Loss: 1.547e+01, Y0: 77.089, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24460, Loss: 1.675e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24470, Loss: 1.824e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24480, Loss: 1.188e+01, Y0: 77.021, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24490, Loss: 1.340e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24500, Loss: 3.214e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24510, Loss: 1.381e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24520, Loss: 1.312e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24530, Loss: 1.158e+01, Y0: 77.029, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24540, Loss: 1.179e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24550, Loss: 1.312e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24560, Loss: 1.261e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24570, Loss: 1.206e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24580, Loss: 1.146e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24590, Loss: 1.152e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24600, Loss: 1.302e+01, Y0: 77.059, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24610, Loss: 1.437e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 24620, Loss: 1.296e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 24630, Loss: 1.249e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 24640, Loss: 1.315e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24650, Loss: 1.410e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24660, Loss: 1.114e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24670, Loss: 1.300e+01, Y0: 76.921, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24680, Loss: 1.190e+01, Y0: 76.968, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24690, Loss: 1.120e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24700, Loss: 1.127e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24710, Loss: 1.175e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24720, Loss: 1.230e+01, Y0: 77.083, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24730, Loss: 1.416e+01, Y0: 77.134, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24740, Loss: 5.708e+01, Y0: 76.927, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24750, Loss: 1.360e+01, Y0: 77.106, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24760, Loss: 1.276e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24770, Loss: 1.332e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24780, Loss: 1.687e+01, Y0: 76.942, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24790, Loss: 1.465e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24800, Loss: 1.280e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 24810, Loss: 1.227e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 24820, Loss: 1.454e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 24830, Loss: 1.229e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24840, Loss: 1.745e+01, Y0: 76.837, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24850, Loss: 1.713e+01, Y0: 76.728, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24860, Loss: 1.888e+01, Y0: 76.772, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24870, Loss: 2.002e+01, Y0: 76.842, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24880, Loss: 1.375e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24890, Loss: 1.314e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24900, Loss: 1.475e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 24910, Loss: 1.242e+01, Y0: 77.038, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24920, Loss: 1.131e+01, Y0: 76.916, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24930, Loss: 1.277e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24940, Loss: 1.448e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 24950, Loss: 1.237e+01, Y0: 76.995, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24960, Loss: 1.303e+01, Y0: 77.019, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 24970, Loss: 1.228e+01, Y0: 76.992, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 24980, Loss: 1.234e+01, Y0: 77.110, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 24990, Loss: 1.196e+01, Y0: 77.088, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 25000, Loss: 2.183e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 25010, Loss: 1.685e+01, Y0: 77.050, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25020, Loss: 1.332e+01, Y0: 77.072, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25030, Loss: 1.258e+01, Y0: 77.056, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25040, Loss: 1.201e+01, Y0: 77.070, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25050, Loss: 1.183e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25060, Loss: 1.263e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25070, Loss: 1.262e+01, Y0: 76.978, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25080, Loss: 1.177e+01, Y0: 77.037, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25090, Loss: 1.162e+01, Y0: 77.027, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25100, Loss: 1.174e+01, Y0: 77.034, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25110, Loss: 2.216e+01, Y0: 77.102, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25120, Loss: 1.478e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25130, Loss: 1.365e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25140, Loss: 1.336e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25150, Loss: 1.554e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25160, Loss: 1.217e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25170, Loss: 1.423e+01, Y0: 77.099, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 25180, Loss: 1.333e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 25190, Loss: 1.136e+01, Y0: 77.095, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 25200, Loss: 1.106e+01, Y0: 76.961, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25210, Loss: 1.187e+01, Y0: 76.912, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25220, Loss: 1.187e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25230, Loss: 1.239e+01, Y0: 76.828, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 25240, Loss: 1.219e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25250, Loss: 1.644e+01, Y0: 77.087, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25260, Loss: 1.340e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25270, Loss: 1.311e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25280, Loss: 1.199e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25290, Loss: 1.256e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25300, Loss: 1.225e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25310, Loss: 1.132e+01, Y0: 77.117, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25320, Loss: 1.227e+01, Y0: 77.083, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25330, Loss: 1.470e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25340, Loss: 1.245e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25350, Loss: 1.288e+01, Y0: 77.096, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25360, Loss: 1.216e+01, Y0: 77.006, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 25370, Loss: 1.700e+01, Y0: 76.824, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 25380, Loss: 1.296e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 25390, Loss: 1.151e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25400, Loss: 1.440e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25410, Loss: 1.473e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25420, Loss: 6.738e+01, Y0: 77.489, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25430, Loss: 1.744e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25440, Loss: 1.559e+01, Y0: 76.737, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25450, Loss: 1.771e+01, Y0: 76.996, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 25460, Loss: 1.252e+01, Y0: 77.055, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 25470, Loss: 1.372e+01, Y0: 77.072, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 25480, Loss: 1.392e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25490, Loss: 1.332e+01, Y0: 77.019, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25500, Loss: 1.361e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25510, Loss: 1.247e+01, Y0: 76.960, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25520, Loss: 1.209e+01, Y0: 77.013, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25530, Loss: 1.257e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25540, Loss: 1.233e+01, Y0: 77.099, Learning Rate: 1.000e-04, Time: 0.66s\n",
      "Epoch: 25550, Loss: 1.205e+01, Y0: 77.145, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 25560, Loss: 1.189e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 25570, Loss: 1.186e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25580, Loss: 1.246e+01, Y0: 77.036, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25590, Loss: 1.261e+01, Y0: 77.066, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25600, Loss: 1.190e+01, Y0: 77.100, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25610, Loss: 1.116e+01, Y0: 77.003, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25620, Loss: 1.264e+01, Y0: 76.905, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25630, Loss: 1.413e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25640, Loss: 1.329e+01, Y0: 77.013, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 25650, Loss: 1.143e+01, Y0: 77.086, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 25660, Loss: 1.289e+01, Y0: 77.121, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25670, Loss: 1.245e+01, Y0: 77.003, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25680, Loss: 1.272e+01, Y0: 77.024, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25690, Loss: 1.375e+01, Y0: 77.122, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25700, Loss: 1.315e+01, Y0: 76.970, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25710, Loss: 1.222e+01, Y0: 77.000, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 25720, Loss: 1.227e+01, Y0: 77.027, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25730, Loss: 1.434e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 25740, Loss: 1.251e+01, Y0: 77.057, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 25750, Loss: 1.536e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 25760, Loss: 1.107e+01, Y0: 76.948, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25770, Loss: 1.310e+01, Y0: 77.097, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25780, Loss: 1.403e+01, Y0: 77.177, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25790, Loss: 1.605e+01, Y0: 76.930, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25800, Loss: 1.517e+01, Y0: 76.993, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25810, Loss: 1.295e+01, Y0: 76.900, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25820, Loss: 1.358e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25830, Loss: 1.224e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25840, Loss: 1.236e+01, Y0: 77.088, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25850, Loss: 1.519e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 25860, Loss: 1.720e+01, Y0: 77.105, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25870, Loss: 1.906e+01, Y0: 76.911, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25880, Loss: 1.207e+01, Y0: 77.149, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 25890, Loss: 1.234e+01, Y0: 77.078, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25900, Loss: 1.359e+01, Y0: 77.180, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25910, Loss: 1.228e+01, Y0: 77.177, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 25920, Loss: 1.616e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 25930, Loss: 1.417e+01, Y0: 77.072, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 25940, Loss: 1.181e+01, Y0: 76.828, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 25950, Loss: 1.281e+01, Y0: 76.955, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 25960, Loss: 1.448e+01, Y0: 77.154, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25970, Loss: 2.385e+01, Y0: 77.246, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25980, Loss: 1.406e+01, Y0: 76.961, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 25990, Loss: 2.149e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26000, Loss: 1.209e+01, Y0: 77.022, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26010, Loss: 1.177e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26020, Loss: 1.225e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26030, Loss: 1.245e+01, Y0: 76.923, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26040, Loss: 1.425e+01, Y0: 77.037, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26050, Loss: 1.231e+01, Y0: 77.051, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 26060, Loss: 1.224e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26070, Loss: 1.167e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 26080, Loss: 1.203e+01, Y0: 77.156, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26090, Loss: 1.391e+01, Y0: 77.184, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 26100, Loss: 1.464e+01, Y0: 77.235, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26110, Loss: 1.196e+01, Y0: 77.067, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 26120, Loss: 1.189e+01, Y0: 77.070, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 26130, Loss: 1.203e+01, Y0: 77.083, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26140, Loss: 1.253e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26150, Loss: 1.322e+01, Y0: 77.072, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26160, Loss: 1.173e+01, Y0: 77.172, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26170, Loss: 1.108e+01, Y0: 76.982, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26180, Loss: 1.226e+01, Y0: 76.913, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26190, Loss: 1.123e+01, Y0: 76.930, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26200, Loss: 1.127e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26210, Loss: 1.295e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26220, Loss: 1.177e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26230, Loss: 1.548e+01, Y0: 76.812, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26240, Loss: 1.163e+01, Y0: 76.972, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26250, Loss: 1.326e+01, Y0: 77.204, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26260, Loss: 1.440e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26270, Loss: 1.166e+01, Y0: 77.013, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26280, Loss: 1.305e+01, Y0: 77.027, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26290, Loss: 1.215e+01, Y0: 76.890, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 26300, Loss: 1.258e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 26310, Loss: 1.123e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 26320, Loss: 1.371e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26330, Loss: 1.191e+01, Y0: 76.914, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26340, Loss: 1.133e+01, Y0: 76.969, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 26350, Loss: 1.452e+01, Y0: 77.158, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 26360, Loss: 1.214e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26370, Loss: 1.278e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 26380, Loss: 1.329e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26390, Loss: 1.399e+01, Y0: 77.140, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26400, Loss: 1.197e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26410, Loss: 1.274e+01, Y0: 76.953, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26420, Loss: 1.509e+01, Y0: 77.050, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 26430, Loss: 1.228e+01, Y0: 77.012, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26440, Loss: 1.074e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26450, Loss: 1.197e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26460, Loss: 1.190e+01, Y0: 77.004, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26470, Loss: 1.200e+01, Y0: 77.172, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26480, Loss: 1.170e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.77s\n",
      "Epoch: 26490, Loss: 1.706e+01, Y0: 76.965, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 26500, Loss: 4.789e+01, Y0: 77.143, Learning Rate: 1.000e-04, Time: 0.69s\n",
      "Epoch: 26510, Loss: 2.182e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26520, Loss: 1.318e+01, Y0: 76.823, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 26530, Loss: 1.282e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 26540, Loss: 1.433e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26550, Loss: 1.135e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26560, Loss: 1.224e+01, Y0: 76.976, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26570, Loss: 1.160e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26580, Loss: 1.195e+01, Y0: 77.045, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26590, Loss: 1.114e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26600, Loss: 1.213e+01, Y0: 76.984, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26610, Loss: 1.171e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26620, Loss: 1.536e+01, Y0: 77.076, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26630, Loss: 1.078e+01, Y0: 77.062, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26640, Loss: 1.140e+01, Y0: 77.067, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26650, Loss: 1.408e+01, Y0: 76.952, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26660, Loss: 1.191e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26670, Loss: 1.301e+01, Y0: 77.150, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 26680, Loss: 1.246e+01, Y0: 76.919, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 26690, Loss: 1.423e+01, Y0: 76.830, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26700, Loss: 1.319e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26710, Loss: 1.163e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26720, Loss: 1.372e+01, Y0: 77.048, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26730, Loss: 1.139e+01, Y0: 77.017, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26740, Loss: 1.254e+01, Y0: 77.137, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26750, Loss: 1.322e+01, Y0: 77.042, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26760, Loss: 1.265e+01, Y0: 76.918, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26770, Loss: 2.022e+01, Y0: 76.863, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26780, Loss: 1.322e+01, Y0: 77.098, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26790, Loss: 1.426e+01, Y0: 77.277, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26800, Loss: 1.278e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26810, Loss: 1.246e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 26820, Loss: 1.536e+01, Y0: 76.910, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26830, Loss: 1.452e+01, Y0: 77.097, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26840, Loss: 1.205e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26850, Loss: 1.170e+01, Y0: 77.148, Learning Rate: 1.000e-04, Time: 0.68s\n",
      "Epoch: 26860, Loss: 1.228e+01, Y0: 77.214, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 26870, Loss: 1.936e+01, Y0: 76.723, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 26880, Loss: 1.274e+01, Y0: 76.926, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26890, Loss: 1.225e+01, Y0: 77.057, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 26900, Loss: 1.372e+01, Y0: 77.092, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26910, Loss: 1.409e+01, Y0: 77.097, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26920, Loss: 1.471e+01, Y0: 77.137, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 26930, Loss: 1.464e+01, Y0: 76.885, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 26940, Loss: 1.169e+01, Y0: 76.969, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 26950, Loss: 1.219e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26960, Loss: 1.176e+01, Y0: 77.037, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 26970, Loss: 1.452e+01, Y0: 77.170, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26980, Loss: 1.627e+01, Y0: 77.196, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 26990, Loss: 1.739e+01, Y0: 76.794, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 27000, Loss: 1.190e+01, Y0: 77.077, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27010, Loss: 1.062e+01, Y0: 77.146, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27020, Loss: 1.152e+01, Y0: 77.051, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27030, Loss: 1.552e+01, Y0: 76.746, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27040, Loss: 1.368e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 27050, Loss: 1.491e+01, Y0: 77.134, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 27060, Loss: 1.246e+01, Y0: 77.044, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 27070, Loss: 1.127e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27080, Loss: 1.157e+01, Y0: 77.118, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27090, Loss: 1.349e+01, Y0: 77.063, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 27100, Loss: 1.286e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27110, Loss: 2.177e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27120, Loss: 1.716e+01, Y0: 77.078, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27130, Loss: 1.474e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 27140, Loss: 1.375e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27150, Loss: 3.172e+01, Y0: 77.290, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 27160, Loss: 1.791e+01, Y0: 77.086, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27170, Loss: 1.429e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.55s\n",
      "Epoch: 27180, Loss: 1.359e+01, Y0: 77.080, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27190, Loss: 1.451e+01, Y0: 77.065, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27200, Loss: 1.262e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27210, Loss: 1.282e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 27220, Loss: 1.157e+01, Y0: 77.050, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27230, Loss: 2.585e+02, Y0: 76.768, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 27240, Loss: 2.126e+01, Y0: 76.791, Learning Rate: 1.000e-04, Time: 0.88s\n",
      "Epoch: 27250, Loss: 1.757e+01, Y0: 76.875, Learning Rate: 1.000e-04, Time: 0.65s\n",
      "Epoch: 27260, Loss: 1.793e+01, Y0: 76.945, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 27270, Loss: 1.309e+01, Y0: 76.966, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27280, Loss: 1.271e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27290, Loss: 1.236e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 27300, Loss: 1.269e+01, Y0: 76.903, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 27310, Loss: 1.206e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27320, Loss: 1.275e+01, Y0: 77.086, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27330, Loss: 1.287e+01, Y0: 77.099, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27340, Loss: 1.204e+01, Y0: 76.939, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27350, Loss: 1.305e+01, Y0: 76.967, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 27360, Loss: 1.193e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27370, Loss: 1.176e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 27380, Loss: 1.104e+01, Y0: 76.997, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27390, Loss: 1.168e+01, Y0: 76.998, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27400, Loss: 1.093e+01, Y0: 77.021, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27410, Loss: 1.124e+01, Y0: 77.093, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 27420, Loss: 1.098e+01, Y0: 76.883, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 27430, Loss: 1.133e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 27440, Loss: 1.119e+01, Y0: 76.931, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27450, Loss: 1.272e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27460, Loss: 1.545e+01, Y0: 76.941, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27470, Loss: 1.248e+01, Y0: 77.019, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27480, Loss: 1.177e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27490, Loss: 1.285e+01, Y0: 77.093, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27500, Loss: 1.113e+01, Y0: 76.946, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27510, Loss: 1.343e+01, Y0: 76.964, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 27520, Loss: 1.319e+01, Y0: 77.094, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27530, Loss: 1.214e+01, Y0: 77.039, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27540, Loss: 1.271e+01, Y0: 76.938, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27550, Loss: 1.382e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 27560, Loss: 1.046e+01, Y0: 76.978, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27570, Loss: 1.286e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27580, Loss: 1.247e+01, Y0: 77.132, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27590, Loss: 1.164e+01, Y0: 77.089, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27600, Loss: 1.187e+01, Y0: 77.093, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 27610, Loss: 1.313e+01, Y0: 77.048, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 27620, Loss: 1.103e+01, Y0: 77.016, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 27630, Loss: 1.328e+01, Y0: 77.223, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27640, Loss: 1.397e+01, Y0: 77.196, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27650, Loss: 1.235e+01, Y0: 77.113, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27660, Loss: 1.318e+01, Y0: 76.899, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27670, Loss: 1.325e+01, Y0: 77.039, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27680, Loss: 1.174e+01, Y0: 77.087, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27690, Loss: 1.404e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27700, Loss: 1.354e+01, Y0: 77.102, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27710, Loss: 1.718e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.55s\n",
      "Epoch: 27720, Loss: 1.388e+01, Y0: 77.179, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27730, Loss: 1.197e+01, Y0: 77.000, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27740, Loss: 1.459e+01, Y0: 76.852, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27750, Loss: 1.320e+01, Y0: 76.879, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27760, Loss: 1.238e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27770, Loss: 1.203e+01, Y0: 77.126, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27780, Loss: 1.488e+01, Y0: 76.921, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27790, Loss: 1.108e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.80s\n",
      "Epoch: 27800, Loss: 1.266e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 27810, Loss: 1.395e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.67s\n",
      "Epoch: 27820, Loss: 1.390e+01, Y0: 77.142, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27830, Loss: 1.326e+01, Y0: 77.178, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27840, Loss: 1.275e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27850, Loss: 1.368e+01, Y0: 76.993, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27860, Loss: 1.773e+01, Y0: 77.186, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27870, Loss: 1.286e+01, Y0: 77.088, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 27880, Loss: 1.589e+01, Y0: 76.824, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27890, Loss: 2.350e+01, Y0: 77.242, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27900, Loss: 1.469e+01, Y0: 76.908, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27910, Loss: 1.452e+01, Y0: 76.884, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 27920, Loss: 1.235e+01, Y0: 76.982, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27930, Loss: 1.315e+01, Y0: 77.101, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27940, Loss: 1.342e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27950, Loss: 1.182e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 27960, Loss: 1.180e+01, Y0: 76.949, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 27970, Loss: 1.167e+01, Y0: 77.007, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 27980, Loss: 1.275e+01, Y0: 77.007, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 27990, Loss: 2.086e+01, Y0: 76.886, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 28000, Loss: 1.855e+01, Y0: 77.224, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28010, Loss: 1.386e+01, Y0: 76.956, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28020, Loss: 1.138e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28030, Loss: 1.406e+01, Y0: 77.110, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28040, Loss: 1.277e+01, Y0: 77.121, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28050, Loss: 1.144e+01, Y0: 77.124, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28060, Loss: 1.178e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28070, Loss: 1.099e+01, Y0: 77.041, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28080, Loss: 1.153e+01, Y0: 77.100, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28090, Loss: 1.195e+01, Y0: 77.165, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28100, Loss: 1.191e+01, Y0: 77.162, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28110, Loss: 1.172e+01, Y0: 76.907, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28120, Loss: 1.551e+01, Y0: 76.940, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28130, Loss: 1.376e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28140, Loss: 1.549e+01, Y0: 76.882, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28150, Loss: 1.736e+01, Y0: 77.122, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28160, Loss: 1.299e+01, Y0: 77.131, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 28170, Loss: 1.319e+01, Y0: 76.734, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 28180, Loss: 1.167e+01, Y0: 77.108, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 28190, Loss: 1.265e+01, Y0: 77.046, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28200, Loss: 1.343e+01, Y0: 76.901, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28210, Loss: 1.493e+01, Y0: 76.965, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28220, Loss: 1.140e+01, Y0: 77.111, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28230, Loss: 1.339e+01, Y0: 77.061, Learning Rate: 1.000e-04, Time: 0.55s\n",
      "Epoch: 28240, Loss: 1.466e+01, Y0: 76.865, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28250, Loss: 1.130e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28260, Loss: 1.123e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 28270, Loss: 1.236e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28280, Loss: 1.150e+01, Y0: 77.118, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28290, Loss: 1.174e+01, Y0: 77.103, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28300, Loss: 1.407e+01, Y0: 77.244, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28310, Loss: 1.780e+01, Y0: 77.134, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28320, Loss: 1.598e+01, Y0: 76.848, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28330, Loss: 1.939e+01, Y0: 77.318, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 28340, Loss: 2.498e+01, Y0: 76.854, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28350, Loss: 1.467e+01, Y0: 76.958, Learning Rate: 1.000e-04, Time: 0.70s\n",
      "Epoch: 28360, Loss: 1.171e+01, Y0: 77.102, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 28370, Loss: 1.367e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 28380, Loss: 1.187e+01, Y0: 77.009, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28390, Loss: 1.321e+01, Y0: 76.943, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28400, Loss: 1.264e+01, Y0: 77.119, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28410, Loss: 1.236e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28420, Loss: 1.156e+01, Y0: 76.924, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28430, Loss: 1.142e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28440, Loss: 1.225e+01, Y0: 77.129, Learning Rate: 1.000e-04, Time: 0.63s\n",
      "Epoch: 28450, Loss: 1.130e+01, Y0: 76.988, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28460, Loss: 1.248e+02, Y0: 77.001, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28470, Loss: 1.716e+01, Y0: 76.814, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28480, Loss: 1.733e+01, Y0: 77.161, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28490, Loss: 1.583e+01, Y0: 77.254, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28500, Loss: 1.227e+01, Y0: 76.996, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28510, Loss: 1.148e+01, Y0: 77.026, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28520, Loss: 1.161e+01, Y0: 76.935, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28530, Loss: 1.218e+01, Y0: 76.965, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 28540, Loss: 1.374e+01, Y0: 77.043, Learning Rate: 1.000e-04, Time: 0.84s\n",
      "Epoch: 28550, Loss: 1.111e+01, Y0: 77.055, Learning Rate: 1.000e-04, Time: 0.89s\n",
      "Epoch: 28560, Loss: 1.357e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.74s\n",
      "Epoch: 28570, Loss: 1.177e+01, Y0: 77.152, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28580, Loss: 1.150e+01, Y0: 77.153, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 28590, Loss: 1.239e+01, Y0: 76.863, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28600, Loss: 1.313e+01, Y0: 77.064, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28610, Loss: 1.211e+01, Y0: 77.127, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28620, Loss: 1.143e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28630, Loss: 1.231e+01, Y0: 77.018, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28640, Loss: 1.217e+01, Y0: 77.061, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28650, Loss: 1.123e+01, Y0: 77.041, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28660, Loss: 1.222e+01, Y0: 77.093, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28670, Loss: 1.199e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28680, Loss: 1.246e+01, Y0: 77.005, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28690, Loss: 1.091e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28700, Loss: 1.848e+01, Y0: 77.191, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 28710, Loss: 1.320e+01, Y0: 77.027, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28720, Loss: 1.196e+01, Y0: 76.933, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 28730, Loss: 1.269e+01, Y0: 77.061, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 28740, Loss: 1.117e+01, Y0: 76.932, Learning Rate: 1.000e-04, Time: 0.79s\n",
      "Epoch: 28750, Loss: 1.090e+01, Y0: 77.068, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28760, Loss: 1.163e+01, Y0: 76.959, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28770, Loss: 1.131e+01, Y0: 76.944, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28780, Loss: 1.212e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28790, Loss: 1.147e+01, Y0: 77.011, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28800, Loss: 1.143e+01, Y0: 77.117, Learning Rate: 1.000e-04, Time: 0.71s\n",
      "Epoch: 28810, Loss: 1.172e+01, Y0: 76.975, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28820, Loss: 1.145e+01, Y0: 77.119, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28830, Loss: 1.187e+01, Y0: 76.929, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28840, Loss: 1.211e+01, Y0: 76.816, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28850, Loss: 1.100e+01, Y0: 76.951, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 28860, Loss: 1.125e+01, Y0: 76.986, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28870, Loss: 1.304e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28880, Loss: 1.605e+01, Y0: 76.840, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28890, Loss: 1.121e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 28900, Loss: 1.206e+01, Y0: 77.090, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28910, Loss: 1.841e+01, Y0: 76.869, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 28920, Loss: 1.258e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.85s\n",
      "Epoch: 28930, Loss: 1.191e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28940, Loss: 1.148e+01, Y0: 77.131, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28950, Loss: 1.108e+01, Y0: 76.892, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 28960, Loss: 1.165e+01, Y0: 76.920, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 28970, Loss: 1.268e+01, Y0: 76.967, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 28980, Loss: 1.112e+01, Y0: 77.112, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 28990, Loss: 1.029e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29000, Loss: 1.123e+01, Y0: 76.981, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29010, Loss: 1.305e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29020, Loss: 1.260e+01, Y0: 77.003, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29030, Loss: 1.155e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29040, Loss: 1.182e+01, Y0: 77.065, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29050, Loss: 1.336e+01, Y0: 77.052, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 29060, Loss: 1.186e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29070, Loss: 1.116e+01, Y0: 77.001, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29080, Loss: 1.744e+01, Y0: 77.188, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29090, Loss: 1.250e+01, Y0: 77.141, Learning Rate: 1.000e-04, Time: 0.72s\n",
      "Epoch: 29100, Loss: 1.709e+01, Y0: 76.898, Learning Rate: 1.000e-04, Time: 0.81s\n",
      "Epoch: 29110, Loss: 1.617e+01, Y0: 77.177, Learning Rate: 1.000e-04, Time: 0.78s\n",
      "Epoch: 29120, Loss: 1.330e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29130, Loss: 1.502e+01, Y0: 77.103, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29140, Loss: 1.116e+01, Y0: 77.220, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 29150, Loss: 1.137e+01, Y0: 76.904, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29160, Loss: 1.592e+01, Y0: 76.914, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29170, Loss: 1.165e+01, Y0: 76.960, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29180, Loss: 1.838e+01, Y0: 76.925, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29190, Loss: 1.622e+01, Y0: 77.173, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 29200, Loss: 1.382e+01, Y0: 77.047, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29210, Loss: 1.165e+01, Y0: 77.079, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29220, Loss: 1.425e+01, Y0: 77.082, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29230, Loss: 1.474e+01, Y0: 77.094, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29240, Loss: 1.157e+01, Y0: 77.181, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29250, Loss: 1.220e+01, Y0: 77.027, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29260, Loss: 1.166e+01, Y0: 77.100, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29270, Loss: 1.417e+01, Y0: 77.033, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29280, Loss: 1.466e+01, Y0: 76.859, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 29290, Loss: 1.239e+01, Y0: 77.134, Learning Rate: 1.000e-04, Time: 0.86s\n",
      "Epoch: 29300, Loss: 1.218e+01, Y0: 77.135, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 29310, Loss: 1.043e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29320, Loss: 1.266e+01, Y0: 77.021, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29330, Loss: 1.231e+01, Y0: 77.220, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29340, Loss: 1.286e+01, Y0: 77.031, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29350, Loss: 1.214e+01, Y0: 77.085, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29360, Loss: 1.564e+01, Y0: 77.141, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29370, Loss: 1.351e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29380, Loss: 1.237e+01, Y0: 77.042, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29390, Loss: 1.276e+01, Y0: 76.930, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29400, Loss: 1.165e+01, Y0: 77.058, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29410, Loss: 1.163e+01, Y0: 77.100, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29420, Loss: 1.676e+01, Y0: 76.879, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29430, Loss: 1.767e+01, Y0: 76.957, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29440, Loss: 1.138e+01, Y0: 77.021, Learning Rate: 1.000e-04, Time: 0.60s\n",
      "Epoch: 29450, Loss: 1.777e+01, Y0: 77.088, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29460, Loss: 1.365e+01, Y0: 77.139, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 29470, Loss: 1.115e+01, Y0: 77.017, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 29480, Loss: 1.117e+01, Y0: 76.866, Learning Rate: 1.000e-04, Time: 0.75s\n",
      "Epoch: 29490, Loss: 1.275e+01, Y0: 76.971, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29500, Loss: 1.548e+01, Y0: 77.032, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29510, Loss: 1.181e+01, Y0: 77.093, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29520, Loss: 1.114e+01, Y0: 76.979, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29530, Loss: 1.204e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29540, Loss: 1.364e+01, Y0: 77.035, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29550, Loss: 1.248e+01, Y0: 77.053, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29560, Loss: 2.039e+01, Y0: 77.017, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29570, Loss: 1.341e+01, Y0: 76.991, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29580, Loss: 1.094e+01, Y0: 77.002, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29590, Loss: 1.191e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29600, Loss: 1.172e+01, Y0: 77.039, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29610, Loss: 1.227e+01, Y0: 77.030, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29620, Loss: 1.171e+01, Y0: 76.947, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29630, Loss: 1.214e+01, Y0: 76.980, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29640, Loss: 1.577e+01, Y0: 76.915, Learning Rate: 1.000e-04, Time: 0.64s\n",
      "Epoch: 29650, Loss: 1.302e+01, Y0: 77.125, Learning Rate: 1.000e-04, Time: 0.83s\n",
      "Epoch: 29660, Loss: 1.233e+01, Y0: 76.891, Learning Rate: 1.000e-04, Time: 0.87s\n",
      "Epoch: 29670, Loss: 1.155e+01, Y0: 76.987, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29680, Loss: 1.096e+01, Y0: 77.102, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29690, Loss: 1.290e+01, Y0: 76.896, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29700, Loss: 3.043e+01, Y0: 77.114, Learning Rate: 1.000e-04, Time: 0.61s\n",
      "Epoch: 29710, Loss: 1.635e+01, Y0: 76.962, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29720, Loss: 1.225e+01, Y0: 76.812, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29730, Loss: 1.310e+01, Y0: 76.983, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29740, Loss: 1.083e+01, Y0: 77.045, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29750, Loss: 1.186e+01, Y0: 77.170, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29760, Loss: 1.082e+01, Y0: 77.112, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 29770, Loss: 1.349e+01, Y0: 77.091, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29780, Loss: 1.231e+01, Y0: 77.014, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29790, Loss: 1.351e+01, Y0: 77.015, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29800, Loss: 1.113e+01, Y0: 77.135, Learning Rate: 1.000e-04, Time: 0.62s\n",
      "Epoch: 29810, Loss: 1.132e+01, Y0: 76.990, Learning Rate: 1.000e-04, Time: 0.56s\n",
      "Epoch: 29820, Loss: 1.134e+01, Y0: 77.037, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29830, Loss: 1.091e+01, Y0: 77.006, Learning Rate: 1.000e-04, Time: 0.73s\n",
      "Epoch: 29840, Loss: 1.225e+01, Y0: 77.121, Learning Rate: 1.000e-04, Time: 0.82s\n",
      "Epoch: 29850, Loss: 1.697e+01, Y0: 77.084, Learning Rate: 1.000e-04, Time: 0.76s\n",
      "Epoch: 29860, Loss: 1.514e+01, Y0: 76.954, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29870, Loss: 1.076e+01, Y0: 77.020, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29880, Loss: 1.328e+01, Y0: 77.028, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29890, Loss: 1.200e+01, Y0: 77.049, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29900, Loss: 1.268e+01, Y0: 76.997, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29910, Loss: 1.060e+01, Y0: 76.977, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29920, Loss: 1.120e+01, Y0: 76.984, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29930, Loss: 1.089e+01, Y0: 77.100, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29940, Loss: 1.129e+01, Y0: 77.086, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29950, Loss: 1.056e+01, Y0: 76.873, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 29960, Loss: 1.266e+01, Y0: 77.128, Learning Rate: 1.000e-04, Time: 0.59s\n",
      "Epoch: 29970, Loss: 1.396e+01, Y0: 77.010, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29980, Loss: 1.290e+01, Y0: 77.092, Learning Rate: 1.000e-04, Time: 0.57s\n",
      "Epoch: 29990, Loss: 2.006e+01, Y0: 77.227, Learning Rate: 1.000e-04, Time: 0.58s\n",
      "Epoch: 0, Loss: 1.486e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.06s\n",
      "Epoch: 10, Loss: 1.257e+01, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20, Loss: 1.124e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 30, Loss: 1.173e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 40, Loss: 1.142e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 50, Loss: 1.184e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 60, Loss: 1.116e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 70, Loss: 2.039e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 80, Loss: 1.062e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 90, Loss: 1.045e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 100, Loss: 1.065e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 110, Loss: 1.194e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 120, Loss: 1.065e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 130, Loss: 1.145e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 140, Loss: 1.174e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 150, Loss: 1.325e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 160, Loss: 1.167e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 170, Loss: 1.191e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 180, Loss: 1.081e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 190, Loss: 1.096e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 200, Loss: 9.824e+00, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 210, Loss: 1.047e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 220, Loss: 1.044e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 230, Loss: 1.208e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 240, Loss: 1.225e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 250, Loss: 1.156e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 260, Loss: 1.210e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 270, Loss: 1.064e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 280, Loss: 1.193e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 290, Loss: 1.078e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 300, Loss: 1.054e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 310, Loss: 1.165e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 320, Loss: 1.132e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 330, Loss: 1.050e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 340, Loss: 1.236e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 350, Loss: 1.057e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 360, Loss: 1.132e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 370, Loss: 1.151e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 380, Loss: 1.133e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 390, Loss: 1.039e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 400, Loss: 1.008e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 410, Loss: 9.807e+00, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 420, Loss: 1.217e+01, Y0: 77.230, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 430, Loss: 1.234e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 440, Loss: 1.092e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 450, Loss: 1.176e+01, Y0: 77.146, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 460, Loss: 1.078e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 470, Loss: 1.204e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 480, Loss: 1.163e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 490, Loss: 1.162e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 500, Loss: 1.098e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 510, Loss: 1.069e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 520, Loss: 1.156e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 530, Loss: 1.035e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 540, Loss: 1.077e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 550, Loss: 1.047e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 560, Loss: 1.258e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 570, Loss: 1.260e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 580, Loss: 1.094e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 590, Loss: 1.061e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 600, Loss: 1.120e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 610, Loss: 1.125e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 620, Loss: 1.087e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 630, Loss: 2.799e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 640, Loss: 1.116e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 650, Loss: 9.964e+00, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 660, Loss: 1.101e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 670, Loss: 1.136e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 680, Loss: 1.136e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 690, Loss: 1.046e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 700, Loss: 1.098e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 710, Loss: 1.060e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 720, Loss: 1.142e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 730, Loss: 1.125e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 740, Loss: 1.031e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 750, Loss: 1.082e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 760, Loss: 1.129e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 770, Loss: 1.124e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 780, Loss: 1.117e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 790, Loss: 1.004e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 800, Loss: 2.698e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 810, Loss: 1.080e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 820, Loss: 1.148e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 830, Loss: 1.101e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 840, Loss: 1.067e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 850, Loss: 1.124e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 860, Loss: 1.064e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 870, Loss: 1.099e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 880, Loss: 1.083e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 890, Loss: 1.039e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 900, Loss: 1.072e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 910, Loss: 1.180e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 920, Loss: 1.079e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 930, Loss: 1.160e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 940, Loss: 1.188e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 950, Loss: 1.131e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 960, Loss: 1.105e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 970, Loss: 1.047e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 980, Loss: 1.216e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 990, Loss: 1.085e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1000, Loss: 1.143e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1010, Loss: 1.145e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1020, Loss: 1.067e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1030, Loss: 1.075e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1040, Loss: 1.182e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1050, Loss: 1.093e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1060, Loss: 1.045e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1070, Loss: 1.108e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1080, Loss: 9.464e+00, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1090, Loss: 1.048e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1100, Loss: 1.202e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1110, Loss: 1.207e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1120, Loss: 1.051e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1130, Loss: 9.899e+00, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1140, Loss: 1.156e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 1150, Loss: 1.037e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 1160, Loss: 1.089e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 1170, Loss: 1.128e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1180, Loss: 1.165e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1190, Loss: 1.246e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1200, Loss: 1.209e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1210, Loss: 1.054e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1220, Loss: 1.109e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1230, Loss: 1.156e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1240, Loss: 1.015e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1250, Loss: 1.070e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1260, Loss: 1.050e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1270, Loss: 1.086e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1280, Loss: 1.054e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1290, Loss: 1.062e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1300, Loss: 1.057e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 1310, Loss: 1.093e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1320, Loss: 1.087e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1330, Loss: 1.160e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 1340, Loss: 1.003e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 1350, Loss: 1.020e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 1360, Loss: 1.077e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 1370, Loss: 1.113e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1380, Loss: 1.202e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1390, Loss: 1.144e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1400, Loss: 1.076e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1410, Loss: 1.088e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 1420, Loss: 1.229e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1430, Loss: 1.070e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1440, Loss: 1.105e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1450, Loss: 1.081e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1460, Loss: 1.057e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1470, Loss: 1.107e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1480, Loss: 1.121e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1490, Loss: 1.081e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1500, Loss: 1.150e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 1510, Loss: 1.039e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1520, Loss: 1.104e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 1530, Loss: 1.068e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 1540, Loss: 1.181e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1550, Loss: 1.111e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1560, Loss: 1.082e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1570, Loss: 1.014e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1580, Loss: 1.091e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1590, Loss: 1.226e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1600, Loss: 1.157e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1610, Loss: 1.053e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 1620, Loss: 1.109e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 1630, Loss: 1.101e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1640, Loss: 1.096e+01, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1650, Loss: 1.027e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 1660, Loss: 1.065e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1670, Loss: 1.169e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1680, Loss: 1.091e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1690, Loss: 1.136e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1700, Loss: 9.944e+00, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 1710, Loss: 1.060e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 1720, Loss: 1.052e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 1730, Loss: 1.219e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1740, Loss: 1.322e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1750, Loss: 1.114e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1760, Loss: 1.138e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1770, Loss: 1.052e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1780, Loss: 1.017e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1790, Loss: 1.123e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1800, Loss: 1.141e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1810, Loss: 1.160e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1820, Loss: 1.100e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 1830, Loss: 1.102e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1840, Loss: 1.094e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1850, Loss: 1.184e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1860, Loss: 1.121e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1870, Loss: 1.096e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1880, Loss: 1.110e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1890, Loss: 1.171e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 1900, Loss: 1.129e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 1910, Loss: 1.099e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 1920, Loss: 1.065e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1930, Loss: 1.076e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 1940, Loss: 1.043e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1950, Loss: 1.112e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1960, Loss: 1.045e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 1970, Loss: 1.135e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 1980, Loss: 9.698e+00, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 1990, Loss: 1.216e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2000, Loss: 1.196e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2010, Loss: 9.996e+00, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2020, Loss: 1.226e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2030, Loss: 1.066e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2040, Loss: 1.163e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2050, Loss: 9.940e+00, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2060, Loss: 1.062e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2070, Loss: 1.116e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 2080, Loss: 1.147e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 2090, Loss: 1.162e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 2100, Loss: 1.037e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2110, Loss: 1.142e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2120, Loss: 1.217e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 2130, Loss: 1.066e+01, Y0: 76.977, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2140, Loss: 1.090e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 2150, Loss: 1.012e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2160, Loss: 1.281e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2170, Loss: 1.044e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2180, Loss: 1.136e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2190, Loss: 1.039e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2200, Loss: 1.107e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2210, Loss: 1.180e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2220, Loss: 1.157e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2230, Loss: 1.012e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2240, Loss: 1.037e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2250, Loss: 1.080e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2260, Loss: 1.147e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 2270, Loss: 1.088e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 2280, Loss: 1.300e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 2290, Loss: 1.171e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2300, Loss: 1.083e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2310, Loss: 9.954e+00, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2320, Loss: 1.173e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2330, Loss: 1.115e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2340, Loss: 1.079e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2350, Loss: 1.059e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 2360, Loss: 1.042e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2370, Loss: 1.359e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2380, Loss: 1.107e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2390, Loss: 1.077e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2400, Loss: 1.075e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2410, Loss: 1.078e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2420, Loss: 1.061e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2430, Loss: 1.234e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2440, Loss: 1.036e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2450, Loss: 9.682e+00, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 2460, Loss: 1.100e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 2470, Loss: 1.113e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 2480, Loss: 1.166e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2490, Loss: 1.058e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2500, Loss: 1.034e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2510, Loss: 1.097e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2520, Loss: 1.171e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2530, Loss: 1.034e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2540, Loss: 1.115e+01, Y0: 76.971, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2550, Loss: 1.104e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2560, Loss: 1.087e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2570, Loss: 1.125e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2580, Loss: 1.035e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2590, Loss: 1.215e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2600, Loss: 1.028e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 2610, Loss: 1.064e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2620, Loss: 1.113e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2630, Loss: 1.119e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 2640, Loss: 1.080e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 2650, Loss: 1.030e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 2660, Loss: 9.709e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2670, Loss: 1.123e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2680, Loss: 1.059e+01, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2690, Loss: 1.116e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2700, Loss: 1.112e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2710, Loss: 1.043e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2720, Loss: 1.060e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2730, Loss: 1.121e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2740, Loss: 1.187e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2750, Loss: 1.127e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2760, Loss: 1.245e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2770, Loss: 1.058e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2780, Loss: 1.172e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2790, Loss: 1.093e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2800, Loss: 1.213e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2810, Loss: 1.077e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2820, Loss: 1.047e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 2830, Loss: 1.091e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 2840, Loss: 1.083e+01, Y0: 76.938, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 2850, Loss: 1.041e+01, Y0: 77.137, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2860, Loss: 1.134e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2870, Loss: 1.002e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 2880, Loss: 1.272e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2890, Loss: 1.035e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2900, Loss: 1.049e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2910, Loss: 1.102e+01, Y0: 77.143, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2920, Loss: 1.229e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2930, Loss: 1.014e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2940, Loss: 1.149e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2950, Loss: 1.062e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 2960, Loss: 1.288e+02, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 2970, Loss: 1.333e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 2980, Loss: 1.139e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 2990, Loss: 1.086e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3000, Loss: 1.006e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3010, Loss: 1.126e+01, Y0: 77.181, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 3020, Loss: 1.279e+01, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 3030, Loss: 1.114e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 3040, Loss: 1.145e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3050, Loss: 1.156e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3060, Loss: 1.072e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3070, Loss: 1.114e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3080, Loss: 1.055e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3090, Loss: 1.137e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3100, Loss: 1.136e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3110, Loss: 1.183e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3120, Loss: 1.077e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3130, Loss: 1.120e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3140, Loss: 1.118e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3150, Loss: 1.098e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3160, Loss: 1.076e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3170, Loss: 1.127e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3180, Loss: 1.153e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3190, Loss: 1.050e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 3200, Loss: 1.072e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 3210, Loss: 1.036e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 3220, Loss: 9.520e+00, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3230, Loss: 1.019e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3240, Loss: 1.187e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3250, Loss: 1.002e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3260, Loss: 1.151e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3270, Loss: 1.060e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3280, Loss: 1.129e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3290, Loss: 1.201e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3300, Loss: 1.241e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 3310, Loss: 1.307e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3320, Loss: 1.102e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3330, Loss: 1.038e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3340, Loss: 1.069e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 3350, Loss: 1.148e+01, Y0: 77.124, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3360, Loss: 1.112e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3370, Loss: 1.286e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3380, Loss: 1.127e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 3390, Loss: 1.034e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 3400, Loss: 1.027e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.73s\n",
      "Epoch: 3410, Loss: 1.033e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3420, Loss: 1.216e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3430, Loss: 1.054e+01, Y0: 76.972, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3440, Loss: 1.028e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 3450, Loss: 1.111e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3460, Loss: 1.020e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3470, Loss: 1.193e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3480, Loss: 1.038e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3490, Loss: 1.037e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3500, Loss: 1.195e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3510, Loss: 1.179e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3520, Loss: 1.187e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3530, Loss: 1.067e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3540, Loss: 1.005e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3550, Loss: 1.084e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 3560, Loss: 1.174e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3570, Loss: 1.047e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 3580, Loss: 1.029e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 3590, Loss: 1.195e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 3600, Loss: 1.151e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3610, Loss: 1.117e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3620, Loss: 1.112e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3630, Loss: 1.171e+01, Y0: 76.932, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3640, Loss: 1.177e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3650, Loss: 1.117e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3660, Loss: 1.150e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 3670, Loss: 1.094e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3680, Loss: 1.057e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3690, Loss: 1.316e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3700, Loss: 1.083e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3710, Loss: 1.034e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3720, Loss: 9.870e+00, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3730, Loss: 1.238e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3740, Loss: 1.310e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3750, Loss: 1.043e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 3760, Loss: 1.056e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 3770, Loss: 1.018e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 3780, Loss: 1.118e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3790, Loss: 1.131e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3800, Loss: 1.157e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3810, Loss: 1.054e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3820, Loss: 1.202e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3830, Loss: 1.220e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3840, Loss: 1.043e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3850, Loss: 1.082e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3860, Loss: 1.098e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3870, Loss: 1.194e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3880, Loss: 1.053e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 3890, Loss: 1.114e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3900, Loss: 1.099e+01, Y0: 76.963, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3910, Loss: 1.198e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 3920, Loss: 1.068e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 3930, Loss: 1.188e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3940, Loss: 1.049e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 3950, Loss: 1.038e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 3960, Loss: 1.195e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 3970, Loss: 1.125e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 3980, Loss: 9.978e+00, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 3990, Loss: 1.026e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4000, Loss: 1.121e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4010, Loss: 1.168e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4020, Loss: 1.070e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 4030, Loss: 1.037e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4040, Loss: 1.160e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4050, Loss: 1.126e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4060, Loss: 1.098e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4070, Loss: 1.138e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4080, Loss: 1.155e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 4090, Loss: 1.040e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4100, Loss: 1.047e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4110, Loss: 1.129e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4120, Loss: 1.143e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4130, Loss: 1.093e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 4140, Loss: 1.065e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 4150, Loss: 1.108e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 4160, Loss: 1.005e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4170, Loss: 1.139e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4180, Loss: 1.145e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4190, Loss: 1.061e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4200, Loss: 1.185e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4210, Loss: 1.088e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 4220, Loss: 1.095e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4230, Loss: 1.123e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4240, Loss: 1.049e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.55s\n",
      "Epoch: 4250, Loss: 1.107e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4260, Loss: 1.046e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4270, Loss: 1.076e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4280, Loss: 1.172e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4290, Loss: 1.110e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4300, Loss: 1.107e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4310, Loss: 9.951e+00, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 4320, Loss: 1.034e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 4330, Loss: 1.071e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 4340, Loss: 1.110e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4350, Loss: 1.005e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4360, Loss: 1.133e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4370, Loss: 1.162e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4380, Loss: 1.118e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4390, Loss: 1.079e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4400, Loss: 1.149e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4410, Loss: 1.128e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4420, Loss: 1.048e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4430, Loss: 1.124e+01, Y0: 76.960, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4440, Loss: 1.019e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4450, Loss: 1.073e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4460, Loss: 1.266e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4470, Loss: 1.082e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4480, Loss: 1.000e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4490, Loss: 1.107e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4500, Loss: 1.215e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 4510, Loss: 1.191e+01, Y0: 76.986, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 4520, Loss: 1.115e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 4530, Loss: 1.073e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4540, Loss: 1.103e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4550, Loss: 1.071e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 4560, Loss: 1.059e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4570, Loss: 1.089e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 4580, Loss: 1.040e+01, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4590, Loss: 1.068e+01, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4600, Loss: 1.020e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4610, Loss: 1.015e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4620, Loss: 1.062e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4630, Loss: 1.056e+01, Y0: 76.977, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4640, Loss: 1.032e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4650, Loss: 1.109e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 4660, Loss: 1.224e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4670, Loss: 1.077e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4680, Loss: 1.124e+01, Y0: 76.958, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4690, Loss: 1.121e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 4700, Loss: 1.155e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 4710, Loss: 1.059e+01, Y0: 76.970, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 4720, Loss: 1.246e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4730, Loss: 1.037e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4740, Loss: 1.111e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4750, Loss: 1.102e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4760, Loss: 1.030e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4770, Loss: 1.126e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4780, Loss: 1.035e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4790, Loss: 1.081e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4800, Loss: 1.113e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4810, Loss: 9.552e+00, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4820, Loss: 1.034e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4830, Loss: 1.066e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4840, Loss: 1.223e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4850, Loss: 1.036e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4860, Loss: 1.069e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4870, Loss: 1.065e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4880, Loss: 1.035e+01, Y0: 76.986, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 4890, Loss: 1.070e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 4900, Loss: 1.148e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 4910, Loss: 1.160e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 4920, Loss: 1.140e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4930, Loss: 1.102e+01, Y0: 76.943, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4940, Loss: 1.215e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 4950, Loss: 1.151e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4960, Loss: 1.067e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 4970, Loss: 1.092e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 4980, Loss: 1.089e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 4990, Loss: 1.027e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5000, Loss: 1.096e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5010, Loss: 1.059e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5020, Loss: 1.041e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5030, Loss: 1.037e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5040, Loss: 1.069e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5050, Loss: 9.646e+00, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5060, Loss: 1.092e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 5070, Loss: 1.355e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 5080, Loss: 1.152e+01, Y0: 77.139, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 5090, Loss: 1.120e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5100, Loss: 1.491e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5110, Loss: 1.036e+01, Y0: 76.980, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5120, Loss: 1.251e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5130, Loss: 1.139e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 5140, Loss: 1.097e+01, Y0: 76.979, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5150, Loss: 1.127e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 5160, Loss: 1.105e+01, Y0: 76.957, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5170, Loss: 1.104e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5180, Loss: 1.244e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5190, Loss: 1.339e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5200, Loss: 1.685e+01, Y0: 76.942, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5210, Loss: 1.112e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5220, Loss: 1.156e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5230, Loss: 1.132e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5240, Loss: 1.141e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5250, Loss: 1.015e+01, Y0: 76.963, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 5260, Loss: 1.044e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 5270, Loss: 1.090e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 5280, Loss: 1.131e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5290, Loss: 1.155e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5300, Loss: 1.040e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5310, Loss: 1.102e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 5320, Loss: 1.059e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5330, Loss: 1.123e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5340, Loss: 1.007e+01, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5350, Loss: 1.085e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5360, Loss: 1.044e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5370, Loss: 1.056e+01, Y0: 77.114, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5380, Loss: 1.007e+01, Y0: 76.977, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5390, Loss: 1.109e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5400, Loss: 1.139e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5410, Loss: 1.060e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5420, Loss: 1.227e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5430, Loss: 1.168e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5440, Loss: 1.242e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 5450, Loss: 1.022e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 5460, Loss: 9.976e+00, Y0: 76.969, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 5470, Loss: 1.192e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5480, Loss: 1.150e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5490, Loss: 1.135e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5500, Loss: 1.100e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5510, Loss: 1.028e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5520, Loss: 1.267e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5530, Loss: 1.215e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5540, Loss: 1.154e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5550, Loss: 1.206e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5560, Loss: 1.044e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5570, Loss: 1.047e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5580, Loss: 1.160e+01, Y0: 76.938, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5590, Loss: 1.164e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5600, Loss: 1.128e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5610, Loss: 1.033e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5620, Loss: 1.108e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5630, Loss: 1.129e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 5640, Loss: 1.116e+01, Y0: 76.964, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 5650, Loss: 1.055e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5660, Loss: 1.095e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5670, Loss: 1.032e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 5680, Loss: 1.168e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5690, Loss: 1.133e+01, Y0: 76.944, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5700, Loss: 1.238e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 5710, Loss: 1.103e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5720, Loss: 1.135e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5730, Loss: 1.079e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5740, Loss: 1.077e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5750, Loss: 1.012e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5760, Loss: 1.075e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5770, Loss: 1.153e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 5780, Loss: 1.172e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5790, Loss: 1.070e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5800, Loss: 1.153e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5810, Loss: 1.034e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 5820, Loss: 1.094e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 5830, Loss: 1.073e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 5840, Loss: 1.141e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5850, Loss: 1.075e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 5860, Loss: 1.088e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5870, Loss: 8.523e+01, Y0: 76.948, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5880, Loss: 1.092e+01, Y0: 76.968, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5890, Loss: 1.148e+01, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5900, Loss: 1.083e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5910, Loss: 1.162e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5920, Loss: 1.100e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5930, Loss: 1.011e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 5940, Loss: 1.185e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5950, Loss: 1.144e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5960, Loss: 1.117e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 5970, Loss: 1.085e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 5980, Loss: 1.026e+01, Y0: 76.970, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 5990, Loss: 1.020e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6000, Loss: 1.130e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 6010, Loss: 1.173e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 6020, Loss: 1.384e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 6030, Loss: 1.093e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6040, Loss: 9.861e+00, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6050, Loss: 1.088e+01, Y0: 76.976, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6060, Loss: 1.058e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6070, Loss: 1.019e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6080, Loss: 1.031e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6090, Loss: 1.147e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6100, Loss: 1.127e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6110, Loss: 1.160e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 6120, Loss: 1.020e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6130, Loss: 1.037e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6140, Loss: 1.094e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6150, Loss: 1.077e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6160, Loss: 1.040e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6170, Loss: 9.497e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6180, Loss: 1.020e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 6190, Loss: 1.049e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 6200, Loss: 1.129e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 6210, Loss: 1.162e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6220, Loss: 9.724e+00, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6230, Loss: 1.055e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6240, Loss: 1.114e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6250, Loss: 1.179e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6260, Loss: 1.084e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6270, Loss: 1.020e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6280, Loss: 1.147e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6290, Loss: 1.006e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6300, Loss: 1.237e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6310, Loss: 1.075e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6320, Loss: 1.267e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6330, Loss: 1.063e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6340, Loss: 9.912e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 6350, Loss: 1.128e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 6360, Loss: 5.304e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6370, Loss: 1.158e+01, Y0: 76.977, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 6380, Loss: 1.118e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 6390, Loss: 1.016e+01, Y0: 76.963, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 6400, Loss: 2.243e+01, Y0: 77.131, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6410, Loss: 1.185e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6420, Loss: 1.126e+01, Y0: 76.978, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6430, Loss: 1.096e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6440, Loss: 1.130e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6450, Loss: 1.001e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 6460, Loss: 1.093e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6470, Loss: 1.080e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6480, Loss: 1.181e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6490, Loss: 1.100e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6500, Loss: 1.122e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 6510, Loss: 9.717e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6520, Loss: 1.219e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6530, Loss: 1.109e+01, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6540, Loss: 1.204e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6550, Loss: 1.112e+01, Y0: 76.960, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6560, Loss: 1.235e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 6570, Loss: 9.885e+00, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 6580, Loss: 1.075e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 6590, Loss: 1.082e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6600, Loss: 1.109e+01, Y0: 76.966, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6610, Loss: 1.142e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6620, Loss: 1.088e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6630, Loss: 9.720e+00, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6640, Loss: 1.124e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6650, Loss: 1.089e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6660, Loss: 1.137e+01, Y0: 76.978, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6670, Loss: 2.238e+01, Y0: 76.966, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6680, Loss: 1.027e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6690, Loss: 1.135e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6700, Loss: 1.062e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6710, Loss: 1.426e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6720, Loss: 1.328e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6730, Loss: 1.822e+01, Y0: 76.969, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6740, Loss: 1.208e+01, Y0: 76.974, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 6750, Loss: 1.139e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 6760, Loss: 1.233e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 6770, Loss: 2.792e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6780, Loss: 1.102e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6790, Loss: 1.113e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6800, Loss: 1.191e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6810, Loss: 1.137e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6820, Loss: 1.066e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 6830, Loss: 1.126e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6840, Loss: 1.069e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6850, Loss: 1.028e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6860, Loss: 1.073e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6870, Loss: 1.236e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6880, Loss: 1.021e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 6890, Loss: 1.086e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6900, Loss: 1.055e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 6910, Loss: 1.240e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6920, Loss: 1.057e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 6930, Loss: 1.048e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 6940, Loss: 1.397e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 6950, Loss: 1.095e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 6960, Loss: 1.120e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6970, Loss: 1.109e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 6980, Loss: 1.055e+01, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 6990, Loss: 1.047e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7000, Loss: 1.149e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7010, Loss: 1.197e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7020, Loss: 9.692e+00, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7030, Loss: 9.820e+00, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7040, Loss: 1.038e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7050, Loss: 1.367e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7060, Loss: 1.259e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7070, Loss: 1.155e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7080, Loss: 1.126e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7090, Loss: 1.024e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7100, Loss: 1.171e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7110, Loss: 1.035e+01, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7120, Loss: 1.124e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 7130, Loss: 1.078e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 7140, Loss: 1.052e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7150, Loss: 1.127e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7160, Loss: 1.021e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7170, Loss: 1.039e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7180, Loss: 1.036e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7190, Loss: 1.095e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7200, Loss: 1.082e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7210, Loss: 1.015e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7220, Loss: 1.540e+01, Y0: 77.173, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7230, Loss: 1.901e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7240, Loss: 1.277e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 7250, Loss: 1.111e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7260, Loss: 1.000e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7270, Loss: 1.176e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7280, Loss: 1.081e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7290, Loss: 1.112e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7300, Loss: 1.103e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 7310, Loss: 1.180e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 7320, Loss: 1.076e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 7330, Loss: 1.214e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7340, Loss: 1.069e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7350, Loss: 1.173e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7360, Loss: 1.190e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 7370, Loss: 1.067e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7380, Loss: 9.898e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 7390, Loss: 1.149e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7400, Loss: 1.139e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7410, Loss: 1.072e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7420, Loss: 9.870e+00, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 7430, Loss: 1.226e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7440, Loss: 1.187e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7450, Loss: 1.069e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7460, Loss: 1.010e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7470, Loss: 1.047e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7480, Loss: 1.081e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7490, Loss: 1.289e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 7500, Loss: 1.141e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 7510, Loss: 1.118e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 7520, Loss: 1.121e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7530, Loss: 1.086e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7540, Loss: 1.090e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7550, Loss: 1.127e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7560, Loss: 1.017e+01, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7570, Loss: 1.169e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7580, Loss: 1.103e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7590, Loss: 1.159e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7600, Loss: 9.994e+00, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7610, Loss: 1.162e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7620, Loss: 1.173e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7630, Loss: 1.257e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7640, Loss: 1.094e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7650, Loss: 1.122e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7660, Loss: 1.344e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7670, Loss: 1.122e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7680, Loss: 1.062e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 7690, Loss: 1.070e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 7700, Loss: 1.094e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7710, Loss: 1.074e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7720, Loss: 9.941e+00, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7730, Loss: 1.171e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7740, Loss: 1.098e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7750, Loss: 1.040e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 7760, Loss: 1.065e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7770, Loss: 1.193e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 7780, Loss: 1.084e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 7790, Loss: 1.123e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7800, Loss: 1.117e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 7810, Loss: 1.111e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7820, Loss: 1.078e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7830, Loss: 1.118e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7840, Loss: 1.027e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 7850, Loss: 1.043e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7860, Loss: 1.108e+01, Y0: 76.962, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 7870, Loss: 1.010e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 7880, Loss: 1.033e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 7890, Loss: 1.173e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7900, Loss: 1.037e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 7910, Loss: 1.035e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7920, Loss: 1.049e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7930, Loss: 1.080e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7940, Loss: 1.198e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 7950, Loss: 1.098e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7960, Loss: 1.144e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 7970, Loss: 1.060e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 7980, Loss: 1.140e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 7990, Loss: 1.103e+01, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8000, Loss: 1.386e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8010, Loss: 9.782e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8020, Loss: 1.062e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8030, Loss: 1.128e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8040, Loss: 1.213e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 8050, Loss: 1.013e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 8060, Loss: 9.761e+00, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 8070, Loss: 1.158e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8080, Loss: 1.001e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8090, Loss: 1.021e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8100, Loss: 1.068e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8110, Loss: 1.110e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8120, Loss: 1.018e+01, Y0: 76.959, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8130, Loss: 1.014e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8140, Loss: 1.372e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8150, Loss: 1.167e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8160, Loss: 1.361e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8170, Loss: 1.042e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8180, Loss: 1.068e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8190, Loss: 1.126e+01, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8200, Loss: 1.051e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8210, Loss: 1.021e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8220, Loss: 9.731e+00, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 8230, Loss: 1.100e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 8240, Loss: 1.047e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 8250, Loss: 1.012e+01, Y0: 76.957, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 8260, Loss: 1.075e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8270, Loss: 1.100e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8280, Loss: 1.034e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8290, Loss: 1.191e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8300, Loss: 9.555e+00, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 8310, Loss: 1.017e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8320, Loss: 1.025e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 8330, Loss: 1.525e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8340, Loss: 1.406e+01, Y0: 77.138, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8350, Loss: 1.254e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8360, Loss: 1.286e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 8370, Loss: 1.121e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8380, Loss: 1.106e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8390, Loss: 1.136e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8400, Loss: 1.056e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8410, Loss: 1.106e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 8420, Loss: 1.150e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 8430, Loss: 1.014e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 8440, Loss: 1.071e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8450, Loss: 1.140e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 8460, Loss: 1.145e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8470, Loss: 1.069e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 8480, Loss: 1.041e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8490, Loss: 1.000e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8500, Loss: 1.076e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8510, Loss: 1.044e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8520, Loss: 1.074e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 8530, Loss: 1.242e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8540, Loss: 1.010e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8550, Loss: 1.188e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8560, Loss: 1.123e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8570, Loss: 1.138e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8580, Loss: 1.156e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8590, Loss: 1.340e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8600, Loss: 1.150e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 8610, Loss: 1.157e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 8620, Loss: 1.261e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 8630, Loss: 1.028e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8640, Loss: 1.062e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8650, Loss: 1.062e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8660, Loss: 1.115e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8670, Loss: 1.089e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8680, Loss: 1.054e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8690, Loss: 9.420e+00, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8700, Loss: 1.147e+01, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8710, Loss: 1.134e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8720, Loss: 1.002e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8730, Loss: 1.028e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8740, Loss: 1.357e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8750, Loss: 1.069e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8760, Loss: 1.040e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8770, Loss: 1.058e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8780, Loss: 1.035e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 8790, Loss: 1.029e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 8800, Loss: 1.074e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 8810, Loss: 1.202e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8820, Loss: 1.053e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8830, Loss: 1.112e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8840, Loss: 1.232e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8850, Loss: 1.181e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8860, Loss: 9.968e+00, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8870, Loss: 1.918e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8880, Loss: 1.119e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8890, Loss: 1.046e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8900, Loss: 1.164e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 8910, Loss: 9.358e+00, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8920, Loss: 1.081e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8930, Loss: 1.096e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8940, Loss: 9.603e+00, Y0: 76.951, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 8950, Loss: 1.035e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 8960, Loss: 1.099e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 8970, Loss: 1.046e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 8980, Loss: 1.022e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 8990, Loss: 1.028e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 9000, Loss: 9.638e+00, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9010, Loss: 9.917e+00, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9020, Loss: 1.144e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9030, Loss: 1.096e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9040, Loss: 3.376e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9050, Loss: 1.172e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9060, Loss: 1.090e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9070, Loss: 1.129e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9080, Loss: 1.088e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9090, Loss: 1.029e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9100, Loss: 1.059e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9110, Loss: 1.162e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9120, Loss: 1.042e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9130, Loss: 1.093e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9140, Loss: 1.038e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9150, Loss: 1.053e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 9160, Loss: 1.096e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 9170, Loss: 1.107e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 9180, Loss: 1.150e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9190, Loss: 1.028e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9200, Loss: 1.040e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9210, Loss: 1.145e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9220, Loss: 1.164e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9230, Loss: 1.134e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9240, Loss: 1.069e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9250, Loss: 9.837e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 9260, Loss: 1.160e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9270, Loss: 1.058e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9280, Loss: 1.034e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 9290, Loss: 1.016e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9300, Loss: 1.014e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9310, Loss: 1.097e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9320, Loss: 1.038e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9330, Loss: 9.985e+00, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9340, Loss: 1.098e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 9350, Loss: 1.043e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 9360, Loss: 1.109e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9370, Loss: 1.167e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9380, Loss: 1.097e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9390, Loss: 1.174e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9400, Loss: 9.956e+00, Y0: 76.939, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9410, Loss: 1.097e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 9420, Loss: 1.040e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9430, Loss: 1.093e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9440, Loss: 1.012e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9450, Loss: 1.094e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9460, Loss: 1.112e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9470, Loss: 9.596e+00, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9480, Loss: 1.060e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9490, Loss: 1.132e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9500, Loss: 1.173e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9510, Loss: 1.196e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9520, Loss: 1.021e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 9530, Loss: 1.022e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 9540, Loss: 1.100e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 9550, Loss: 1.026e+01, Y0: 76.979, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9560, Loss: 1.080e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 9570, Loss: 1.089e+01, Y0: 77.122, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9580, Loss: 1.026e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9590, Loss: 1.114e+01, Y0: 77.155, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9600, Loss: 1.008e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9610, Loss: 1.007e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9620, Loss: 1.030e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9630, Loss: 9.938e+00, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9640, Loss: 1.167e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 9650, Loss: 1.023e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9660, Loss: 1.085e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 9670, Loss: 1.128e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9680, Loss: 1.039e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 9690, Loss: 1.125e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9700, Loss: 1.217e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9710, Loss: 1.170e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 9720, Loss: 1.382e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 9730, Loss: 1.017e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 9740, Loss: 1.042e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9750, Loss: 1.132e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9760, Loss: 1.117e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9770, Loss: 1.070e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9780, Loss: 1.028e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9790, Loss: 1.027e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9800, Loss: 1.072e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9810, Loss: 1.138e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9820, Loss: 1.158e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9830, Loss: 1.038e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 9840, Loss: 1.078e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9850, Loss: 1.189e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9860, Loss: 1.230e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9870, Loss: 1.120e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9880, Loss: 1.108e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9890, Loss: 1.091e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9900, Loss: 1.067e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 9910, Loss: 1.097e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 9920, Loss: 1.174e+01, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 9930, Loss: 1.047e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9940, Loss: 1.184e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 9950, Loss: 1.056e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9960, Loss: 9.954e+00, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9970, Loss: 1.089e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 9980, Loss: 9.758e+00, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 9990, Loss: 1.279e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10000, Loss: 1.128e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10010, Loss: 1.068e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10020, Loss: 1.126e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 10030, Loss: 1.112e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10040, Loss: 1.085e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10050, Loss: 1.119e+01, Y0: 76.972, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10060, Loss: 1.114e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10070, Loss: 1.143e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10080, Loss: 1.114e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 10090, Loss: 1.087e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 10100, Loss: 9.923e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 10110, Loss: 9.586e+00, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10120, Loss: 1.045e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10130, Loss: 1.124e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10140, Loss: 1.122e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10150, Loss: 1.024e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 10160, Loss: 1.074e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10170, Loss: 1.015e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10180, Loss: 1.206e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10190, Loss: 1.145e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10200, Loss: 1.234e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 10210, Loss: 9.750e+00, Y0: 77.130, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10220, Loss: 1.004e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10230, Loss: 9.809e+00, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10240, Loss: 1.093e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 10250, Loss: 9.894e+00, Y0: 77.129, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10260, Loss: 1.120e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10270, Loss: 9.925e+00, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 10280, Loss: 1.098e+01, Y0: 77.163, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 10290, Loss: 1.188e+01, Y0: 76.974, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 10300, Loss: 1.311e+01, Y0: 77.122, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10310, Loss: 1.068e+01, Y0: 76.980, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10320, Loss: 1.148e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10330, Loss: 1.027e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10340, Loss: 1.015e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10350, Loss: 9.949e+00, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10360, Loss: 1.104e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10370, Loss: 1.090e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10380, Loss: 1.186e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10390, Loss: 1.151e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10400, Loss: 1.142e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10410, Loss: 1.172e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10420, Loss: 1.126e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10430, Loss: 1.187e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10440, Loss: 1.186e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10450, Loss: 1.017e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 10460, Loss: 1.033e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 10470, Loss: 1.088e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 10480, Loss: 1.129e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10490, Loss: 1.070e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10500, Loss: 1.044e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10510, Loss: 1.268e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10520, Loss: 1.088e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10530, Loss: 1.010e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10540, Loss: 1.030e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10550, Loss: 1.015e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10560, Loss: 1.050e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10570, Loss: 1.060e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10580, Loss: 1.086e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10590, Loss: 1.107e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 10600, Loss: 1.070e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 10610, Loss: 1.024e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10620, Loss: 1.087e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 10630, Loss: 1.157e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10640, Loss: 1.078e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 10650, Loss: 1.118e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 10660, Loss: 1.053e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 10670, Loss: 1.088e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 10680, Loss: 1.034e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10690, Loss: 1.173e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 10700, Loss: 1.115e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10710, Loss: 1.067e+01, Y0: 76.963, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10720, Loss: 9.777e+00, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 10730, Loss: 1.381e+01, Y0: 77.151, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10740, Loss: 1.033e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10750, Loss: 1.167e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10760, Loss: 1.056e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10770, Loss: 1.086e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10780, Loss: 1.039e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 10790, Loss: 1.022e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10800, Loss: 1.008e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10810, Loss: 1.170e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10820, Loss: 1.032e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 10830, Loss: 1.002e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 10840, Loss: 1.130e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 10850, Loss: 9.911e+00, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10860, Loss: 1.123e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10870, Loss: 9.619e+00, Y0: 76.956, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10880, Loss: 1.059e+01, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10890, Loss: 1.058e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10900, Loss: 1.076e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10910, Loss: 1.065e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 10920, Loss: 1.031e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10930, Loss: 1.076e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 10940, Loss: 1.030e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 10950, Loss: 1.134e+01, Y0: 77.164, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10960, Loss: 1.193e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 10970, Loss: 1.093e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 10980, Loss: 1.119e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 10990, Loss: 1.072e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11000, Loss: 1.763e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11010, Loss: 1.246e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 11020, Loss: 1.214e+01, Y0: 76.936, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 11030, Loss: 1.000e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 11040, Loss: 1.122e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11050, Loss: 1.094e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11060, Loss: 9.826e+00, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11070, Loss: 5.973e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11080, Loss: 1.141e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11090, Loss: 1.093e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11100, Loss: 1.017e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11110, Loss: 1.058e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11120, Loss: 1.035e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11130, Loss: 9.778e+00, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11140, Loss: 1.104e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11150, Loss: 1.153e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 11160, Loss: 1.150e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11170, Loss: 1.186e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11180, Loss: 1.062e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11190, Loss: 1.046e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 11200, Loss: 1.246e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 11210, Loss: 1.086e+01, Y0: 77.140, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 11220, Loss: 1.044e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11230, Loss: 1.092e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11240, Loss: 1.045e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11250, Loss: 1.080e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11260, Loss: 1.031e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11270, Loss: 1.023e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11280, Loss: 1.726e+01, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11290, Loss: 1.098e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11300, Loss: 1.233e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11310, Loss: 1.027e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11320, Loss: 1.149e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 11330, Loss: 1.012e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11340, Loss: 1.097e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11350, Loss: 1.011e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11360, Loss: 1.141e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11370, Loss: 1.097e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11380, Loss: 1.021e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 11390, Loss: 9.767e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 11400, Loss: 1.001e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11410, Loss: 1.024e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11420, Loss: 1.049e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11430, Loss: 1.061e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11440, Loss: 1.023e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11450, Loss: 9.211e+00, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11460, Loss: 1.031e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11470, Loss: 1.299e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11480, Loss: 1.056e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11490, Loss: 1.153e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11500, Loss: 9.568e+00, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 11510, Loss: 9.821e+00, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11520, Loss: 1.122e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11530, Loss: 1.030e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11540, Loss: 1.179e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11550, Loss: 1.085e+01, Y0: 76.980, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11560, Loss: 1.238e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 11570, Loss: 1.086e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 11580, Loss: 1.025e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 11590, Loss: 1.071e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11600, Loss: 1.124e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11610, Loss: 1.116e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11620, Loss: 1.125e+01, Y0: 76.980, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 11630, Loss: 1.309e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11640, Loss: 1.232e+01, Y0: 76.954, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11650, Loss: 1.106e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11660, Loss: 1.140e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11670, Loss: 1.113e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11680, Loss: 1.005e+01, Y0: 76.968, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11690, Loss: 1.152e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 11700, Loss: 1.057e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11710, Loss: 1.023e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11720, Loss: 1.209e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11730, Loss: 1.081e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 11740, Loss: 1.079e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11750, Loss: 1.052e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 11760, Loss: 1.023e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 11770, Loss: 1.018e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 11780, Loss: 1.014e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11790, Loss: 1.037e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11800, Loss: 1.055e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11810, Loss: 1.072e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11820, Loss: 1.363e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11830, Loss: 1.165e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11840, Loss: 1.032e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11850, Loss: 1.130e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11860, Loss: 1.177e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11870, Loss: 1.161e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11880, Loss: 1.077e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 11890, Loss: 1.104e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 11900, Loss: 9.958e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11910, Loss: 1.061e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11920, Loss: 1.086e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 11930, Loss: 1.046e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 11940, Loss: 1.012e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 11950, Loss: 1.214e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 11960, Loss: 1.055e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 11970, Loss: 1.095e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 11980, Loss: 1.103e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 11990, Loss: 1.217e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12000, Loss: 9.991e+00, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12010, Loss: 1.036e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12020, Loss: 1.018e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12030, Loss: 1.089e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12040, Loss: 1.049e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12050, Loss: 9.694e+00, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12060, Loss: 1.078e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12070, Loss: 1.036e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12080, Loss: 1.074e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12090, Loss: 1.145e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12100, Loss: 1.017e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12110, Loss: 1.030e+01, Y0: 76.963, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12120, Loss: 9.966e+00, Y0: 77.146, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 12130, Loss: 1.100e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 12140, Loss: 1.113e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 12150, Loss: 1.075e+01, Y0: 76.978, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12160, Loss: 1.127e+01, Y0: 77.142, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12170, Loss: 1.012e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 12180, Loss: 1.214e+01, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12190, Loss: 1.032e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12200, Loss: 1.008e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12210, Loss: 1.196e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12220, Loss: 1.049e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12230, Loss: 1.072e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12240, Loss: 9.650e+00, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12250, Loss: 1.121e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 12260, Loss: 1.121e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12270, Loss: 1.105e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12280, Loss: 1.208e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12290, Loss: 9.875e+00, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12300, Loss: 1.072e+01, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12310, Loss: 9.765e+00, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 12320, Loss: 1.141e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 12330, Loss: 9.873e+00, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12340, Loss: 1.069e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12350, Loss: 1.022e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12360, Loss: 1.152e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12370, Loss: 9.372e+00, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12380, Loss: 1.122e+01, Y0: 77.191, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12390, Loss: 1.188e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12400, Loss: 9.596e+00, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12410, Loss: 9.998e+00, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12420, Loss: 1.364e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12430, Loss: 1.115e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12440, Loss: 9.744e+00, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12450, Loss: 1.253e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12460, Loss: 1.097e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12470, Loss: 9.751e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12480, Loss: 1.090e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12490, Loss: 1.051e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 12500, Loss: 1.124e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 12510, Loss: 1.050e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 12520, Loss: 1.085e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12530, Loss: 1.052e+01, Y0: 77.134, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12540, Loss: 1.123e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12550, Loss: 1.058e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12560, Loss: 1.031e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12570, Loss: 9.756e+00, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 12580, Loss: 1.026e+01, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12590, Loss: 1.368e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12600, Loss: 1.099e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 12610, Loss: 1.046e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 12620, Loss: 1.045e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 12630, Loss: 1.053e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12640, Loss: 1.140e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12650, Loss: 1.106e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12660, Loss: 1.004e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12670, Loss: 1.014e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 12680, Loss: 9.668e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 12690, Loss: 1.102e+01, Y0: 77.148, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 12700, Loss: 1.120e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12710, Loss: 1.140e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12720, Loss: 1.096e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12730, Loss: 1.035e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12740, Loss: 1.076e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12750, Loss: 1.047e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12760, Loss: 1.093e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12770, Loss: 1.063e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12780, Loss: 1.185e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12790, Loss: 1.165e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 12800, Loss: 1.052e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 12810, Loss: 1.111e+01, Y0: 76.958, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12820, Loss: 1.077e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12830, Loss: 9.319e+00, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12840, Loss: 9.638e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 12850, Loss: 1.034e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.73s\n",
      "Epoch: 12860, Loss: 9.650e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 12870, Loss: 1.002e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 12880, Loss: 1.083e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12890, Loss: 1.061e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12900, Loss: 1.096e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12910, Loss: 1.166e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12920, Loss: 1.199e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12930, Loss: 1.070e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 12940, Loss: 1.063e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 12950, Loss: 9.506e+00, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12960, Loss: 1.071e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12970, Loss: 1.087e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 12980, Loss: 1.291e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 12990, Loss: 1.014e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13000, Loss: 1.084e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13010, Loss: 1.081e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13020, Loss: 1.114e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13030, Loss: 1.051e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 13040, Loss: 1.072e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 13050, Loss: 1.028e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 13060, Loss: 1.202e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13070, Loss: 1.084e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13080, Loss: 1.010e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13090, Loss: 1.050e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13100, Loss: 1.079e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13110, Loss: 1.196e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 13120, Loss: 1.032e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13130, Loss: 1.015e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13140, Loss: 1.014e+01, Y0: 77.136, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13150, Loss: 1.046e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13160, Loss: 1.014e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13170, Loss: 1.117e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13180, Loss: 1.073e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13190, Loss: 1.079e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13200, Loss: 1.058e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13210, Loss: 1.048e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 13220, Loss: 1.046e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 13230, Loss: 1.141e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 13240, Loss: 1.051e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 13250, Loss: 1.027e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13260, Loss: 1.079e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13270, Loss: 1.205e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13280, Loss: 9.590e+00, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13290, Loss: 1.027e+01, Y0: 76.987, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13300, Loss: 1.132e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13310, Loss: 9.926e+00, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13320, Loss: 1.028e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13330, Loss: 1.067e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13340, Loss: 1.047e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13350, Loss: 9.839e+00, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13360, Loss: 1.174e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13370, Loss: 1.058e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13380, Loss: 9.757e+00, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13390, Loss: 1.152e+01, Y0: 77.140, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 13400, Loss: 1.072e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.91s\n",
      "Epoch: 13410, Loss: 1.004e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 13420, Loss: 1.105e+01, Y0: 77.130, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13430, Loss: 1.122e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13440, Loss: 1.047e+01, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13450, Loss: 9.670e+00, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13460, Loss: 1.138e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13470, Loss: 1.050e+01, Y0: 76.952, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13480, Loss: 1.097e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 13490, Loss: 1.037e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13500, Loss: 1.016e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13510, Loss: 1.096e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13520, Loss: 1.094e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13530, Loss: 2.818e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13540, Loss: 1.064e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13550, Loss: 1.071e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13560, Loss: 9.942e+00, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13570, Loss: 1.062e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 13580, Loss: 1.182e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 13590, Loss: 9.923e+00, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 13600, Loss: 1.031e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13610, Loss: 1.098e+01, Y0: 77.134, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13620, Loss: 9.554e+00, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13630, Loss: 1.107e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13640, Loss: 1.058e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13650, Loss: 1.097e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13660, Loss: 1.114e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13670, Loss: 1.036e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13680, Loss: 1.023e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13690, Loss: 1.164e+01, Y0: 76.970, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13700, Loss: 1.081e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13710, Loss: 1.002e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13720, Loss: 1.181e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13730, Loss: 1.202e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13740, Loss: 1.122e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13750, Loss: 9.434e+00, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 13760, Loss: 9.969e+00, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.91s\n",
      "Epoch: 13770, Loss: 1.029e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 13780, Loss: 1.070e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13790, Loss: 1.093e+01, Y0: 77.139, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13800, Loss: 1.033e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13810, Loss: 1.333e+01, Y0: 77.159, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13820, Loss: 1.152e+01, Y0: 76.951, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13830, Loss: 1.023e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13840, Loss: 1.212e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13850, Loss: 1.027e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13860, Loss: 1.033e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13870, Loss: 1.062e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13880, Loss: 1.007e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13890, Loss: 1.058e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13900, Loss: 9.544e+00, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 13910, Loss: 1.148e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 13920, Loss: 1.125e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13930, Loss: 1.066e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 13940, Loss: 1.183e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.91s\n",
      "Epoch: 13950, Loss: 1.137e+01, Y0: 76.974, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 13960, Loss: 9.772e+00, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13970, Loss: 1.067e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 13980, Loss: 1.153e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 13990, Loss: 1.029e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14000, Loss: 1.084e+01, Y0: 77.130, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14010, Loss: 1.210e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14020, Loss: 1.009e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14030, Loss: 1.031e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14040, Loss: 1.044e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14050, Loss: 9.977e+00, Y0: 76.951, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14060, Loss: 1.056e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14070, Loss: 1.144e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14080, Loss: 1.093e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14090, Loss: 1.179e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14100, Loss: 1.124e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14110, Loss: 9.581e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 14120, Loss: 1.230e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 14130, Loss: 9.958e+00, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 14140, Loss: 1.128e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14150, Loss: 1.089e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14160, Loss: 9.990e+00, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14170, Loss: 1.068e+01, Y0: 76.987, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14180, Loss: 1.042e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14190, Loss: 1.035e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14200, Loss: 1.072e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14210, Loss: 1.033e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14220, Loss: 1.039e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14230, Loss: 1.161e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14240, Loss: 1.170e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14250, Loss: 9.999e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14260, Loss: 1.116e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14270, Loss: 1.145e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14280, Loss: 1.115e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14290, Loss: 1.030e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 14300, Loss: 1.021e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 14310, Loss: 1.146e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 14320, Loss: 1.109e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14330, Loss: 1.118e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14340, Loss: 1.040e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14350, Loss: 1.008e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14360, Loss: 1.060e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14370, Loss: 1.102e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14380, Loss: 1.317e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14390, Loss: 1.124e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14400, Loss: 1.123e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 14410, Loss: 1.231e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14420, Loss: 1.129e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14430, Loss: 1.108e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14440, Loss: 1.072e+01, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14450, Loss: 9.855e+00, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14460, Loss: 1.096e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 14470, Loss: 1.171e+01, Y0: 76.987, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 14480, Loss: 1.003e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 14490, Loss: 1.053e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 14500, Loss: 1.051e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14510, Loss: 1.024e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14520, Loss: 1.024e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14530, Loss: 1.006e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14540, Loss: 1.024e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14550, Loss: 1.030e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14560, Loss: 1.000e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14570, Loss: 9.793e+00, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14580, Loss: 1.081e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14590, Loss: 9.637e+00, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14600, Loss: 1.043e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14610, Loss: 1.135e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14620, Loss: 1.043e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14630, Loss: 1.034e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14640, Loss: 9.424e+00, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14650, Loss: 1.137e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 14660, Loss: 1.209e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 14670, Loss: 1.004e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 14680, Loss: 1.157e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14690, Loss: 9.886e+00, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14700, Loss: 1.235e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14710, Loss: 9.943e+00, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14720, Loss: 1.055e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14730, Loss: 9.924e+00, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14740, Loss: 1.007e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14750, Loss: 1.048e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14760, Loss: 1.068e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14770, Loss: 9.342e+00, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14780, Loss: 1.022e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14790, Loss: 1.057e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14800, Loss: 1.067e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14810, Loss: 1.008e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14820, Loss: 1.063e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 14830, Loss: 9.933e+00, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 14840, Loss: 1.008e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 14850, Loss: 1.024e+01, Y0: 77.189, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 14860, Loss: 1.060e+01, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14870, Loss: 1.084e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14880, Loss: 1.064e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14890, Loss: 9.590e+00, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14900, Loss: 1.083e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14910, Loss: 1.047e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14920, Loss: 1.072e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14930, Loss: 1.143e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 14940, Loss: 1.142e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14950, Loss: 1.062e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14960, Loss: 1.287e+01, Y0: 76.946, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 14970, Loss: 1.182e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14980, Loss: 1.286e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 14990, Loss: 1.126e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15000, Loss: 9.912e+00, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15010, Loss: 1.057e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 15020, Loss: 1.099e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 15030, Loss: 1.158e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15040, Loss: 1.081e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15050, Loss: 9.967e+00, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15060, Loss: 9.770e+00, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15070, Loss: 1.003e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15080, Loss: 9.982e+00, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15090, Loss: 1.010e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15100, Loss: 1.915e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15110, Loss: 1.020e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15120, Loss: 1.040e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15130, Loss: 1.087e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15140, Loss: 9.542e+00, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15150, Loss: 1.037e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15160, Loss: 1.077e+01, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15170, Loss: 1.378e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15180, Loss: 1.118e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15190, Loss: 1.104e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 15200, Loss: 9.906e+00, Y0: 76.974, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 15210, Loss: 1.046e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15220, Loss: 9.697e+00, Y0: 76.951, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15230, Loss: 1.116e+01, Y0: 77.137, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15240, Loss: 1.014e+01, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15250, Loss: 1.084e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15260, Loss: 9.869e+00, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15270, Loss: 1.015e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15280, Loss: 1.081e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15290, Loss: 1.083e+01, Y0: 76.976, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15300, Loss: 1.020e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15310, Loss: 9.711e+00, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15320, Loss: 1.002e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 15330, Loss: 1.010e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15340, Loss: 1.059e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15350, Loss: 1.063e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15360, Loss: 1.125e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 15370, Loss: 1.094e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 15380, Loss: 1.049e+01, Y0: 77.138, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 15390, Loss: 1.023e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 15400, Loss: 1.051e+01, Y0: 77.144, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15410, Loss: 1.040e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15420, Loss: 1.023e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15430, Loss: 1.156e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15440, Loss: 1.010e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15450, Loss: 1.017e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15460, Loss: 1.092e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15470, Loss: 1.285e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15480, Loss: 1.196e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15490, Loss: 1.074e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15500, Loss: 1.069e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15510, Loss: 9.583e+00, Y0: 77.139, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15520, Loss: 1.015e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15530, Loss: 1.051e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15540, Loss: 1.552e+01, Y0: 77.162, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 15550, Loss: 1.046e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 15560, Loss: 1.070e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 15570, Loss: 9.968e+00, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15580, Loss: 1.039e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15590, Loss: 1.107e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15600, Loss: 1.148e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15610, Loss: 1.713e+01, Y0: 76.975, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15620, Loss: 1.156e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15630, Loss: 1.028e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15640, Loss: 1.234e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15650, Loss: 1.193e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15660, Loss: 1.045e+01, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15670, Loss: 1.055e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15680, Loss: 1.277e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15690, Loss: 1.060e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15700, Loss: 1.074e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15710, Loss: 9.955e+00, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15720, Loss: 1.067e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 15730, Loss: 1.093e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 15740, Loss: 1.170e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 15750, Loss: 1.042e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15760, Loss: 1.004e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15770, Loss: 1.090e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 15780, Loss: 1.018e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15790, Loss: 1.142e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15800, Loss: 1.162e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15810, Loss: 1.011e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15820, Loss: 1.014e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15830, Loss: 1.084e+01, Y0: 76.962, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15840, Loss: 1.116e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15850, Loss: 1.082e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15860, Loss: 1.037e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15870, Loss: 1.078e+01, Y0: 77.184, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15880, Loss: 1.123e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15890, Loss: 9.857e+00, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15900, Loss: 1.131e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 15910, Loss: 1.312e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 15920, Loss: 1.053e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 15930, Loss: 9.582e+00, Y0: 76.948, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 15940, Loss: 1.034e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 15950, Loss: 1.126e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15960, Loss: 1.098e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15970, Loss: 1.111e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 15980, Loss: 1.127e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 15990, Loss: 1.150e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16000, Loss: 9.505e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16010, Loss: 9.937e+00, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16020, Loss: 9.385e+00, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16030, Loss: 1.096e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16040, Loss: 1.068e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16050, Loss: 1.107e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16060, Loss: 1.010e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16070, Loss: 1.225e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16080, Loss: 1.113e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 16090, Loss: 1.128e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 16100, Loss: 1.066e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 16110, Loss: 1.083e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16120, Loss: 1.057e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16130, Loss: 1.167e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16140, Loss: 1.131e+01, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16150, Loss: 2.218e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16160, Loss: 1.177e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16170, Loss: 9.765e+00, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16180, Loss: 9.945e+00, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16190, Loss: 1.040e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16200, Loss: 1.014e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16210, Loss: 1.068e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16220, Loss: 1.007e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16230, Loss: 1.087e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 16240, Loss: 1.109e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16250, Loss: 1.044e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16260, Loss: 1.127e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 16270, Loss: 1.058e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 16280, Loss: 1.149e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16290, Loss: 1.092e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16300, Loss: 9.687e+00, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16310, Loss: 1.071e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16320, Loss: 9.840e+00, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16330, Loss: 1.015e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16340, Loss: 1.202e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16350, Loss: 1.029e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16360, Loss: 1.042e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16370, Loss: 1.011e+01, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16380, Loss: 9.567e+00, Y0: 76.987, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16390, Loss: 1.025e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16400, Loss: 1.089e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16410, Loss: 1.051e+01, Y0: 77.145, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16420, Loss: 2.981e+02, Y0: 76.914, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16430, Loss: 1.510e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16440, Loss: 1.184e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 16450, Loss: 1.075e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 16460, Loss: 1.111e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16470, Loss: 1.012e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16480, Loss: 1.060e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16490, Loss: 4.521e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16500, Loss: 1.056e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16510, Loss: 9.854e+00, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16520, Loss: 1.020e+01, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16530, Loss: 1.238e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16540, Loss: 1.119e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16550, Loss: 1.058e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16560, Loss: 1.045e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16570, Loss: 1.338e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16580, Loss: 1.272e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16590, Loss: 1.122e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16600, Loss: 1.488e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16610, Loss: 1.052e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 16620, Loss: 1.080e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 16630, Loss: 1.110e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 16640, Loss: 1.167e+01, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16650, Loss: 1.004e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16660, Loss: 1.088e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16670, Loss: 1.109e+01, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16680, Loss: 1.093e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 16690, Loss: 1.011e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16700, Loss: 1.172e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16710, Loss: 1.019e+01, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16720, Loss: 1.121e+01, Y0: 77.131, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16730, Loss: 1.039e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16740, Loss: 1.067e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16750, Loss: 1.107e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16760, Loss: 1.054e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16770, Loss: 1.031e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16780, Loss: 1.048e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16790, Loss: 9.866e+00, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 16800, Loss: 1.109e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 16810, Loss: 1.144e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 16820, Loss: 1.096e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16830, Loss: 9.840e+00, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16840, Loss: 1.061e+01, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16850, Loss: 1.029e+01, Y0: 76.965, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16860, Loss: 9.685e+00, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16870, Loss: 1.088e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16880, Loss: 1.030e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 16890, Loss: 1.093e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16900, Loss: 1.189e+01, Y0: 77.124, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16910, Loss: 9.350e+00, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16920, Loss: 1.110e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 16930, Loss: 9.936e+00, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16940, Loss: 1.020e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 16950, Loss: 1.953e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16960, Loss: 1.011e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 16970, Loss: 1.023e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 16980, Loss: 1.076e+01, Y0: 77.136, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 16990, Loss: 1.015e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 17000, Loss: 1.014e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17010, Loss: 1.096e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17020, Loss: 1.113e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17030, Loss: 1.140e+01, Y0: 76.967, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17040, Loss: 1.011e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 17050, Loss: 1.025e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17060, Loss: 1.120e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17070, Loss: 1.053e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17080, Loss: 9.999e+00, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17090, Loss: 1.050e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17100, Loss: 1.039e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17110, Loss: 1.103e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17120, Loss: 9.818e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17130, Loss: 1.040e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17140, Loss: 1.078e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17150, Loss: 1.088e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 17160, Loss: 9.645e+00, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 17170, Loss: 1.137e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 17180, Loss: 1.226e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 17190, Loss: 1.028e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17200, Loss: 1.145e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17210, Loss: 2.542e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17220, Loss: 1.133e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17230, Loss: 1.068e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17240, Loss: 1.047e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17250, Loss: 1.065e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17260, Loss: 1.061e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17270, Loss: 9.527e+00, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17280, Loss: 1.140e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 17290, Loss: 1.024e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17300, Loss: 9.732e+00, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17310, Loss: 1.088e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17320, Loss: 1.021e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17330, Loss: 1.115e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 17340, Loss: 1.094e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 17350, Loss: 1.026e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 17360, Loss: 1.116e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17370, Loss: 1.204e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17380, Loss: 1.096e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17390, Loss: 9.643e+00, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17400, Loss: 1.066e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17410, Loss: 1.092e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17420, Loss: 1.018e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17430, Loss: 9.874e+00, Y0: 77.152, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17440, Loss: 1.017e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17450, Loss: 1.063e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17460, Loss: 1.076e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17470, Loss: 1.055e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17480, Loss: 1.105e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17490, Loss: 1.102e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17500, Loss: 9.785e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17510, Loss: 1.000e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 17520, Loss: 1.012e+01, Y0: 76.969, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 17530, Loss: 1.139e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 17540, Loss: 1.117e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17550, Loss: 1.043e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17560, Loss: 1.054e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17570, Loss: 1.040e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17580, Loss: 9.682e+00, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17590, Loss: 1.007e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17600, Loss: 9.762e+00, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 17610, Loss: 1.181e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17620, Loss: 1.102e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17630, Loss: 9.761e+00, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17640, Loss: 1.023e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17650, Loss: 1.324e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17660, Loss: 1.035e+01, Y0: 76.950, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17670, Loss: 1.047e+01, Y0: 77.176, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17680, Loss: 1.274e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17690, Loss: 1.081e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 17700, Loss: 1.104e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 17710, Loss: 1.060e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 17720, Loss: 1.006e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 17730, Loss: 9.608e+00, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17740, Loss: 1.063e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17750, Loss: 1.232e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17760, Loss: 1.283e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17770, Loss: 9.918e+00, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17780, Loss: 1.057e+01, Y0: 76.962, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17790, Loss: 9.567e+00, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17800, Loss: 1.019e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17810, Loss: 1.077e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17820, Loss: 9.781e+00, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17830, Loss: 1.093e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 17840, Loss: 1.278e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 17850, Loss: 1.073e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17860, Loss: 1.058e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17870, Loss: 1.063e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 17880, Loss: 1.011e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 17890, Loss: 1.049e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17900, Loss: 1.018e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 17910, Loss: 1.240e+02, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17920, Loss: 9.687e+00, Y0: 76.945, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17930, Loss: 1.015e+01, Y0: 77.144, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17940, Loss: 1.085e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17950, Loss: 1.019e+01, Y0: 76.950, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 17960, Loss: 9.834e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 17970, Loss: 1.076e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 17980, Loss: 1.120e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 17990, Loss: 1.084e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18000, Loss: 1.108e+01, Y0: 77.172, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18010, Loss: 1.056e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18020, Loss: 1.246e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18030, Loss: 1.013e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18040, Loss: 1.076e+01, Y0: 77.152, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 18050, Loss: 1.137e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 18060, Loss: 2.508e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 18070, Loss: 1.005e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18080, Loss: 9.492e+00, Y0: 77.139, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18090, Loss: 1.081e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18100, Loss: 1.145e+01, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18110, Loss: 9.986e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18120, Loss: 1.079e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18130, Loss: 1.050e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18140, Loss: 1.141e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18150, Loss: 1.078e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18160, Loss: 1.117e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18170, Loss: 1.045e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18180, Loss: 1.075e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18190, Loss: 1.014e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18200, Loss: 1.077e+01, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18210, Loss: 1.104e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18220, Loss: 1.046e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 18230, Loss: 9.945e+00, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 18240, Loss: 1.146e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 18250, Loss: 1.045e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18260, Loss: 9.913e+00, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18270, Loss: 1.100e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18280, Loss: 1.108e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18290, Loss: 1.012e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18300, Loss: 1.074e+01, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18310, Loss: 1.088e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18320, Loss: 1.017e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18330, Loss: 1.110e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 18340, Loss: 1.183e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18350, Loss: 1.181e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 18360, Loss: 1.147e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 18370, Loss: 9.965e+00, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18380, Loss: 1.351e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18390, Loss: 1.024e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18400, Loss: 9.985e+00, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 18410, Loss: 1.163e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 18420, Loss: 1.049e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 18430, Loss: 1.043e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18440, Loss: 1.095e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18450, Loss: 1.053e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18460, Loss: 1.087e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18470, Loss: 1.024e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18480, Loss: 9.880e+00, Y0: 77.154, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18490, Loss: 1.124e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 18500, Loss: 1.004e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18510, Loss: 1.117e+01, Y0: 76.978, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 18520, Loss: 1.007e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18530, Loss: 1.108e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 18540, Loss: 1.005e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18550, Loss: 1.098e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18560, Loss: 1.019e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18570, Loss: 9.984e+00, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18580, Loss: 9.868e+00, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 18590, Loss: 1.061e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 18600, Loss: 9.881e+00, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 18610, Loss: 9.961e+00, Y0: 76.986, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18620, Loss: 1.094e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18630, Loss: 1.224e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18640, Loss: 1.006e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18650, Loss: 1.167e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18660, Loss: 1.157e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18670, Loss: 9.981e+00, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18680, Loss: 9.872e+00, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18690, Loss: 1.144e+01, Y0: 76.987, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18700, Loss: 1.093e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18710, Loss: 1.034e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18720, Loss: 1.080e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18730, Loss: 1.012e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18740, Loss: 1.006e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18750, Loss: 1.192e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18760, Loss: 1.051e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 18770, Loss: 1.043e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 18780, Loss: 1.281e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 18790, Loss: 1.124e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18800, Loss: 1.313e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18810, Loss: 9.912e+00, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18820, Loss: 9.673e+00, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18830, Loss: 1.209e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18840, Loss: 1.178e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18850, Loss: 9.698e+00, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18860, Loss: 9.313e+00, Y0: 76.952, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 18870, Loss: 1.167e+01, Y0: 77.135, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 18880, Loss: 1.188e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 18890, Loss: 1.071e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18900, Loss: 9.962e+00, Y0: 76.975, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 18910, Loss: 9.934e+00, Y0: 77.124, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18920, Loss: 1.009e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 18930, Loss: 1.015e+01, Y0: 77.138, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18940, Loss: 9.838e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 18950, Loss: 1.080e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 18960, Loss: 9.078e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 18970, Loss: 1.091e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18980, Loss: 1.130e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 18990, Loss: 9.542e+00, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19000, Loss: 9.781e+00, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19010, Loss: 9.467e+00, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19020, Loss: 1.108e+01, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19030, Loss: 1.084e+01, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19040, Loss: 1.133e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19050, Loss: 1.004e+01, Y0: 76.979, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19060, Loss: 9.301e+00, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19070, Loss: 9.938e+00, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 19080, Loss: 1.122e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19090, Loss: 1.176e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19100, Loss: 1.220e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19110, Loss: 1.146e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.73s\n",
      "Epoch: 19120, Loss: 1.047e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 19130, Loss: 1.045e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 19140, Loss: 1.065e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 19150, Loss: 1.161e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19160, Loss: 1.070e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19170, Loss: 1.216e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19180, Loss: 9.701e+00, Y0: 77.177, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19190, Loss: 1.117e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19200, Loss: 9.531e+00, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19210, Loss: 1.014e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19220, Loss: 9.949e+00, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19230, Loss: 1.065e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19240, Loss: 9.956e+00, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19250, Loss: 1.005e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19260, Loss: 1.079e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19270, Loss: 1.060e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19280, Loss: 1.064e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19290, Loss: 1.049e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 19300, Loss: 1.054e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 19310, Loss: 1.029e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 19320, Loss: 1.030e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19330, Loss: 1.076e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 19340, Loss: 1.080e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 19350, Loss: 1.272e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19360, Loss: 1.059e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19370, Loss: 1.155e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19380, Loss: 1.034e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19390, Loss: 9.995e+00, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19400, Loss: 1.158e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19410, Loss: 1.099e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19420, Loss: 1.040e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 19430, Loss: 9.440e+00, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19440, Loss: 1.015e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19450, Loss: 1.045e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19460, Loss: 1.024e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19470, Loss: 1.005e+01, Y0: 77.143, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 19480, Loss: 1.003e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 19490, Loss: 1.069e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 19500, Loss: 1.072e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19510, Loss: 1.092e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19520, Loss: 1.104e+01, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19530, Loss: 9.959e+00, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19540, Loss: 1.105e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19550, Loss: 1.093e+01, Y0: 77.151, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19560, Loss: 9.917e+00, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19570, Loss: 9.549e+00, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19580, Loss: 1.008e+01, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19590, Loss: 1.053e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19600, Loss: 1.027e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19610, Loss: 9.895e+00, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19620, Loss: 9.604e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19630, Loss: 1.006e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19640, Loss: 9.530e+00, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19650, Loss: 1.144e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 19660, Loss: 1.068e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 19670, Loss: 9.983e+00, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19680, Loss: 1.096e+01, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19690, Loss: 1.068e+01, Y0: 77.146, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 19700, Loss: 1.096e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19710, Loss: 1.116e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19720, Loss: 1.041e+01, Y0: 77.134, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19730, Loss: 1.076e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19740, Loss: 9.967e+00, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 19750, Loss: 1.098e+01, Y0: 76.979, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19760, Loss: 9.384e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19770, Loss: 9.826e+00, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19780, Loss: 1.138e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19790, Loss: 1.116e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19800, Loss: 9.836e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 19810, Loss: 1.036e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19820, Loss: 1.051e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 19830, Loss: 1.099e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 19840, Loss: 1.041e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 19850, Loss: 1.097e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19860, Loss: 9.887e+00, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19870, Loss: 9.427e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 19880, Loss: 9.249e+00, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19890, Loss: 1.231e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19900, Loss: 1.159e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19910, Loss: 1.016e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19920, Loss: 1.084e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19930, Loss: 9.715e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19940, Loss: 9.946e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19950, Loss: 1.047e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 19960, Loss: 1.006e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19970, Loss: 1.029e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 19980, Loss: 1.046e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 19990, Loss: 1.057e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20000, Loss: 1.071e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 20010, Loss: 1.030e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 20020, Loss: 1.114e+01, Y0: 77.140, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 20030, Loss: 9.925e+00, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20040, Loss: 1.063e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20050, Loss: 1.007e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20060, Loss: 1.051e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20070, Loss: 1.115e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20080, Loss: 1.027e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20090, Loss: 1.168e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20100, Loss: 1.029e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20110, Loss: 1.001e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20120, Loss: 1.097e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20130, Loss: 1.057e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20140, Loss: 1.093e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20150, Loss: 1.019e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20160, Loss: 1.278e+01, Y0: 76.966, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20170, Loss: 1.219e+01, Y0: 77.114, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20180, Loss: 1.126e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 20190, Loss: 1.015e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 20200, Loss: 1.121e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 20210, Loss: 1.208e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20220, Loss: 1.029e+01, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20230, Loss: 1.059e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20240, Loss: 1.588e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20250, Loss: 1.012e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20260, Loss: 1.075e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20270, Loss: 1.088e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 20280, Loss: 1.089e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20290, Loss: 1.018e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20300, Loss: 1.108e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20310, Loss: 9.495e+00, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20320, Loss: 9.946e+00, Y0: 76.975, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20330, Loss: 1.083e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20340, Loss: 1.086e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20350, Loss: 1.032e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20360, Loss: 1.019e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 20370, Loss: 1.035e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 20380, Loss: 9.983e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20390, Loss: 1.166e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20400, Loss: 1.059e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 20410, Loss: 1.010e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20420, Loss: 9.675e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20430, Loss: 1.311e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20440, Loss: 1.084e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20450, Loss: 1.025e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20460, Loss: 1.028e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20470, Loss: 1.011e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20480, Loss: 9.861e+00, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20490, Loss: 1.207e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20500, Loss: 1.007e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 20510, Loss: 1.000e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20520, Loss: 1.185e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20530, Loss: 9.940e+00, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 20540, Loss: 1.015e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 20550, Loss: 9.663e+00, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 20560, Loss: 1.037e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20570, Loss: 9.575e+00, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20580, Loss: 1.170e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20590, Loss: 1.044e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20600, Loss: 1.013e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20610, Loss: 9.828e+00, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20620, Loss: 9.834e+00, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20630, Loss: 1.040e+01, Y0: 76.976, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20640, Loss: 1.024e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20650, Loss: 9.715e+00, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20660, Loss: 1.055e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20670, Loss: 9.661e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 20680, Loss: 9.563e+00, Y0: 77.146, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20690, Loss: 1.012e+01, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20700, Loss: 1.095e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20710, Loss: 1.041e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 20720, Loss: 9.610e+00, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 20730, Loss: 9.486e+00, Y0: 77.142, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 20740, Loss: 1.144e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20750, Loss: 9.798e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20760, Loss: 1.101e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 20770, Loss: 9.739e+00, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20780, Loss: 1.082e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20790, Loss: 9.540e+00, Y0: 76.970, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20800, Loss: 1.224e+01, Y0: 77.149, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20810, Loss: 1.106e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20820, Loss: 1.032e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20830, Loss: 1.010e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20840, Loss: 1.176e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20850, Loss: 3.598e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 20860, Loss: 1.037e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20870, Loss: 1.159e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20880, Loss: 9.479e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 20890, Loss: 1.056e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 20900, Loss: 1.038e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 20910, Loss: 9.475e+00, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 20920, Loss: 1.081e+01, Y0: 76.963, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20930, Loss: 1.142e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20940, Loss: 1.064e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20950, Loss: 1.189e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20960, Loss: 1.037e+01, Y0: 77.129, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20970, Loss: 1.166e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 20980, Loss: 1.085e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 20990, Loss: 1.037e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21000, Loss: 1.097e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21010, Loss: 9.528e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21020, Loss: 1.030e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21030, Loss: 1.047e+01, Y0: 76.979, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21040, Loss: 1.042e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21050, Loss: 9.193e+00, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21060, Loss: 1.004e+01, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21070, Loss: 1.033e+01, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 21080, Loss: 1.059e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 21090, Loss: 9.940e+00, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 21100, Loss: 1.033e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21110, Loss: 1.007e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21120, Loss: 1.000e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21130, Loss: 9.692e+00, Y0: 77.141, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21140, Loss: 9.532e+00, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21150, Loss: 1.189e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21160, Loss: 1.025e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21170, Loss: 1.006e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21180, Loss: 9.042e+00, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21190, Loss: 1.160e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21200, Loss: 1.161e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21210, Loss: 1.086e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21220, Loss: 1.126e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21230, Loss: 1.002e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 21240, Loss: 1.059e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 21250, Loss: 9.676e+00, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 21260, Loss: 9.829e+00, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 21270, Loss: 9.800e+00, Y0: 77.144, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21280, Loss: 9.521e+00, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21290, Loss: 1.271e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21300, Loss: 1.034e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21310, Loss: 1.094e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21320, Loss: 1.028e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21330, Loss: 1.046e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21340, Loss: 9.130e+00, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21350, Loss: 1.013e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21360, Loss: 1.053e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21370, Loss: 1.086e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21380, Loss: 1.060e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21390, Loss: 1.033e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21400, Loss: 1.071e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21410, Loss: 9.670e+00, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21420, Loss: 1.170e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 21430, Loss: 9.302e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 21440, Loss: 1.019e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 21450, Loss: 1.229e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21460, Loss: 1.036e+01, Y0: 76.935, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 21470, Loss: 1.038e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 21480, Loss: 9.991e+00, Y0: 76.974, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21490, Loss: 1.100e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 21500, Loss: 1.160e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21510, Loss: 1.082e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21520, Loss: 1.036e+01, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21530, Loss: 1.058e+01, Y0: 76.905, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21540, Loss: 9.767e+00, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21550, Loss: 1.007e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21560, Loss: 1.060e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21570, Loss: 1.172e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21580, Loss: 1.017e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21590, Loss: 9.556e+00, Y0: 76.995, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21600, Loss: 1.115e+01, Y0: 77.141, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 21610, Loss: 9.480e+00, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 21620, Loss: 9.247e+00, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 21630, Loss: 1.071e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21640, Loss: 9.930e+00, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21650, Loss: 1.464e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21660, Loss: 1.180e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21670, Loss: 1.053e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21680, Loss: 1.033e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 21690, Loss: 1.158e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21700, Loss: 9.996e+00, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21710, Loss: 1.098e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21720, Loss: 1.015e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21730, Loss: 1.037e+01, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21740, Loss: 1.037e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 21750, Loss: 1.047e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21760, Loss: 9.730e+00, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21770, Loss: 9.904e+00, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21780, Loss: 1.135e+01, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 21790, Loss: 1.098e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.91s\n",
      "Epoch: 21800, Loss: 1.057e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 21810, Loss: 1.057e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21820, Loss: 9.815e+00, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21830, Loss: 1.180e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21840, Loss: 9.411e+00, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21850, Loss: 1.084e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21860, Loss: 1.064e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21870, Loss: 9.696e+00, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21880, Loss: 1.075e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21890, Loss: 9.410e+00, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 21900, Loss: 1.048e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21910, Loss: 1.099e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21920, Loss: 9.977e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21930, Loss: 1.040e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21940, Loss: 1.017e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 21950, Loss: 1.052e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 21960, Loss: 1.127e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 21970, Loss: 1.010e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 21980, Loss: 1.076e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 21990, Loss: 1.029e+01, Y0: 77.126, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22000, Loss: 9.770e+00, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 22010, Loss: 1.119e+01, Y0: 76.978, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22020, Loss: 1.064e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22030, Loss: 1.009e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22040, Loss: 1.041e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22050, Loss: 1.113e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22060, Loss: 1.110e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22070, Loss: 9.821e+00, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22080, Loss: 1.118e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22090, Loss: 1.162e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22100, Loss: 1.123e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22110, Loss: 1.396e+01, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22120, Loss: 1.178e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22130, Loss: 1.118e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22140, Loss: 1.098e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 22150, Loss: 1.085e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 22160, Loss: 1.029e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 22170, Loss: 9.979e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22180, Loss: 1.250e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22190, Loss: 9.909e+00, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22200, Loss: 1.034e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22210, Loss: 1.028e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22220, Loss: 9.756e+00, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22230, Loss: 1.200e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22240, Loss: 9.930e+00, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22250, Loss: 9.609e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22260, Loss: 9.908e+00, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22270, Loss: 1.143e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22280, Loss: 1.062e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22290, Loss: 1.109e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22300, Loss: 1.016e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22310, Loss: 9.255e+00, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22320, Loss: 9.920e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 22330, Loss: 9.644e+00, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.90s\n",
      "Epoch: 22340, Loss: 1.030e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 22350, Loss: 1.003e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22360, Loss: 1.028e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22370, Loss: 9.891e+00, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 22380, Loss: 9.733e+00, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22390, Loss: 1.080e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22400, Loss: 1.025e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22410, Loss: 9.648e+00, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 22420, Loss: 9.824e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22430, Loss: 1.031e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22440, Loss: 9.207e+00, Y0: 76.969, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22450, Loss: 1.067e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22460, Loss: 1.003e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22470, Loss: 9.652e+00, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22480, Loss: 9.729e+00, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 22490, Loss: 9.993e+00, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22500, Loss: 9.765e+00, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.91s\n",
      "Epoch: 22510, Loss: 1.096e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.93s\n",
      "Epoch: 22520, Loss: 1.115e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22530, Loss: 1.016e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22540, Loss: 9.810e+00, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22550, Loss: 1.089e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22560, Loss: 1.073e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22570, Loss: 1.201e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22580, Loss: 1.044e+01, Y0: 76.981, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22590, Loss: 1.019e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 22600, Loss: 9.896e+00, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22610, Loss: 1.034e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22620, Loss: 1.026e+01, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22630, Loss: 1.043e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22640, Loss: 9.965e+00, Y0: 77.140, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22650, Loss: 1.022e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22660, Loss: 9.975e+00, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22670, Loss: 1.059e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 22680, Loss: 1.032e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 22690, Loss: 1.080e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 22700, Loss: 1.107e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22710, Loss: 1.055e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22720, Loss: 1.049e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22730, Loss: 1.189e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22740, Loss: 1.054e+01, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22750, Loss: 1.039e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22760, Loss: 9.753e+00, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22770, Loss: 1.069e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22780, Loss: 1.005e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22790, Loss: 9.591e+00, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22800, Loss: 1.025e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22810, Loss: 1.112e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22820, Loss: 1.004e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22830, Loss: 9.512e+00, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22840, Loss: 1.026e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22850, Loss: 1.090e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 22860, Loss: 1.010e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 22870, Loss: 9.776e+00, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 22880, Loss: 9.425e+00, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22890, Loss: 1.013e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22900, Loss: 9.384e+00, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22910, Loss: 1.017e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22920, Loss: 1.103e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22930, Loss: 9.146e+00, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 22940, Loss: 1.106e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22950, Loss: 9.211e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22960, Loss: 9.898e+00, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 22970, Loss: 1.069e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 22980, Loss: 9.928e+00, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 22990, Loss: 9.846e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23000, Loss: 1.010e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23010, Loss: 1.002e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23020, Loss: 1.046e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23030, Loss: 9.408e+00, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 23040, Loss: 1.054e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 23050, Loss: 1.036e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.93s\n",
      "Epoch: 23060, Loss: 9.907e+00, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23070, Loss: 1.052e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23080, Loss: 9.714e+00, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23090, Loss: 1.125e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23100, Loss: 9.785e+00, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23110, Loss: 1.032e+01, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23120, Loss: 1.064e+01, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23130, Loss: 1.053e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23140, Loss: 1.095e+01, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23150, Loss: 1.123e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23160, Loss: 1.039e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23170, Loss: 1.041e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23180, Loss: 1.100e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23190, Loss: 1.060e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23200, Loss: 1.009e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23210, Loss: 9.871e+00, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23220, Loss: 1.102e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 23230, Loss: 1.094e+01, Y0: 76.971, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 23240, Loss: 1.260e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 23250, Loss: 1.141e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23260, Loss: 1.110e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23270, Loss: 9.992e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23280, Loss: 1.047e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23290, Loss: 1.034e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23300, Loss: 1.078e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23310, Loss: 1.071e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23320, Loss: 1.105e+01, Y0: 77.129, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23330, Loss: 9.678e+00, Y0: 76.961, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23340, Loss: 1.006e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23350, Loss: 1.045e+01, Y0: 76.975, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23360, Loss: 1.013e+01, Y0: 76.973, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23370, Loss: 1.001e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23380, Loss: 1.133e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23390, Loss: 1.093e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23400, Loss: 1.179e+01, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 23410, Loss: 1.071e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.94s\n",
      "Epoch: 23420, Loss: 1.096e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23430, Loss: 1.043e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23440, Loss: 1.093e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23450, Loss: 9.728e+00, Y0: 77.141, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23460, Loss: 1.051e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23470, Loss: 1.127e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23480, Loss: 9.693e+00, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23490, Loss: 9.797e+00, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23500, Loss: 1.038e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23510, Loss: 9.846e+00, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 23520, Loss: 9.744e+00, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 23530, Loss: 1.112e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23540, Loss: 1.043e+01, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23550, Loss: 1.042e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23560, Loss: 1.022e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23570, Loss: 9.075e+00, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 23580, Loss: 1.118e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 23590, Loss: 9.660e+00, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 23600, Loss: 9.590e+00, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23610, Loss: 9.640e+00, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23620, Loss: 1.033e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23630, Loss: 1.008e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 23640, Loss: 9.766e+00, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23650, Loss: 1.088e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 23660, Loss: 1.058e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23670, Loss: 9.716e+00, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 23680, Loss: 9.234e+00, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23690, Loss: 1.111e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23700, Loss: 1.035e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23710, Loss: 9.694e+00, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23720, Loss: 1.065e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23730, Loss: 9.548e+00, Y0: 77.150, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 23740, Loss: 1.033e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 23750, Loss: 1.094e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 23760, Loss: 1.013e+01, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 23770, Loss: 1.090e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 23780, Loss: 9.460e+00, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23790, Loss: 1.039e+01, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23800, Loss: 1.019e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23810, Loss: 1.087e+01, Y0: 76.951, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23820, Loss: 9.337e+00, Y0: 77.170, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 23830, Loss: 9.687e+00, Y0: 76.991, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23840, Loss: 1.036e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23850, Loss: 1.154e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23860, Loss: 1.015e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23870, Loss: 9.395e+00, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 23880, Loss: 1.235e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23890, Loss: 1.101e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 23900, Loss: 9.467e+00, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 23910, Loss: 9.575e+00, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 23920, Loss: 1.105e+01, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 23930, Loss: 9.778e+00, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 23940, Loss: 1.110e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 23950, Loss: 1.074e+01, Y0: 76.987, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 23960, Loss: 9.762e+00, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 23970, Loss: 1.225e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 23980, Loss: 1.093e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 23990, Loss: 9.972e+00, Y0: 77.144, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24000, Loss: 1.035e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24010, Loss: 9.592e+00, Y0: 77.122, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24020, Loss: 9.970e+00, Y0: 77.144, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24030, Loss: 9.862e+00, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24040, Loss: 9.833e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24050, Loss: 9.577e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24060, Loss: 1.023e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24070, Loss: 1.022e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24080, Loss: 1.052e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24090, Loss: 9.621e+00, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24100, Loss: 1.018e+01, Y0: 76.955, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24110, Loss: 9.648e+00, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24120, Loss: 1.119e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 24130, Loss: 9.476e+00, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 24140, Loss: 1.022e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 24150, Loss: 1.136e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24160, Loss: 1.045e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24170, Loss: 9.206e+00, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24180, Loss: 1.069e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24190, Loss: 1.011e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24200, Loss: 1.273e+01, Y0: 77.114, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24210, Loss: 1.271e+01, Y0: 77.178, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24220, Loss: 1.096e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24230, Loss: 1.176e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24240, Loss: 9.614e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24250, Loss: 1.059e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24260, Loss: 9.650e+00, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24270, Loss: 9.877e+00, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24280, Loss: 1.101e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24290, Loss: 1.016e+01, Y0: 76.985, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 24300, Loss: 9.249e+00, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 24310, Loss: 1.029e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 24320, Loss: 1.033e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 24330, Loss: 1.120e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24340, Loss: 9.719e+00, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24350, Loss: 1.110e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24360, Loss: 1.083e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24370, Loss: 1.129e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24380, Loss: 9.628e+00, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24390, Loss: 1.133e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24400, Loss: 1.066e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24410, Loss: 1.041e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24420, Loss: 1.219e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24430, Loss: 1.025e+01, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24440, Loss: 1.121e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 24450, Loss: 1.130e+01, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24460, Loss: 1.015e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24470, Loss: 9.386e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24480, Loss: 1.558e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 24490, Loss: 1.047e+01, Y0: 76.983, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 24500, Loss: 9.298e+00, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.81s\n",
      "Epoch: 24510, Loss: 1.158e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24520, Loss: 1.131e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24530, Loss: 1.035e+01, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24540, Loss: 9.726e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24550, Loss: 1.069e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24560, Loss: 1.155e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24570, Loss: 1.080e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24580, Loss: 1.168e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24590, Loss: 9.637e+00, Y0: 77.048, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24600, Loss: 1.055e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24610, Loss: 1.020e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24620, Loss: 9.347e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24630, Loss: 1.099e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24640, Loss: 1.055e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24650, Loss: 9.754e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 24660, Loss: 1.047e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 24670, Loss: 9.322e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 24680, Loss: 1.114e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 24690, Loss: 1.058e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24700, Loss: 1.118e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24710, Loss: 8.898e+00, Y0: 77.010, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24720, Loss: 1.090e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24730, Loss: 9.599e+00, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24740, Loss: 1.077e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24750, Loss: 9.366e+00, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24760, Loss: 1.041e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24770, Loss: 1.176e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24780, Loss: 1.041e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24790, Loss: 1.087e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24800, Loss: 1.020e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24810, Loss: 1.019e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24820, Loss: 1.118e+01, Y0: 77.130, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24830, Loss: 1.089e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24840, Loss: 1.009e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24850, Loss: 1.064e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 24860, Loss: 9.657e+00, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 24870, Loss: 9.787e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 24880, Loss: 1.082e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24890, Loss: 1.153e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24900, Loss: 1.005e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 24910, Loss: 1.206e+01, Y0: 77.147, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 24920, Loss: 1.228e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24930, Loss: 1.077e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 24940, Loss: 1.219e+01, Y0: 77.153, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 24950, Loss: 1.099e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 24960, Loss: 9.697e+00, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 24970, Loss: 9.854e+00, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 24980, Loss: 9.484e+00, Y0: 77.134, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 24990, Loss: 1.059e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25000, Loss: 1.136e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25010, Loss: 1.037e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25020, Loss: 1.050e+01, Y0: 77.040, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25030, Loss: 1.130e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 25040, Loss: 9.613e+00, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 25050, Loss: 9.347e+00, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 25060, Loss: 1.135e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25070, Loss: 1.016e+01, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25080, Loss: 1.091e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25090, Loss: 1.091e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25100, Loss: 9.747e+00, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25110, Loss: 1.010e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25120, Loss: 1.063e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25130, Loss: 9.537e+00, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25140, Loss: 1.008e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25150, Loss: 9.540e+00, Y0: 77.009, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25160, Loss: 1.055e+01, Y0: 77.122, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25170, Loss: 9.350e+00, Y0: 76.988, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25180, Loss: 1.014e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25190, Loss: 1.114e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 25200, Loss: 9.045e+00, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25210, Loss: 1.106e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25220, Loss: 1.056e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 25230, Loss: 9.584e+00, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 25240, Loss: 9.776e+00, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 25250, Loss: 1.073e+01, Y0: 77.126, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25260, Loss: 9.937e+00, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 25270, Loss: 1.042e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25280, Loss: 9.993e+00, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25290, Loss: 1.036e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25300, Loss: 1.007e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25310, Loss: 1.072e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25320, Loss: 1.056e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25330, Loss: 9.960e+00, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25340, Loss: 1.069e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25350, Loss: 1.083e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25360, Loss: 9.217e+00, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25370, Loss: 1.002e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25380, Loss: 1.030e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 25390, Loss: 9.648e+00, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25400, Loss: 9.752e+00, Y0: 77.056, Learning Rate: 1.000e-05, Time: 0.71s\n",
      "Epoch: 25410, Loss: 1.082e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 25420, Loss: 9.952e+00, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 25430, Loss: 9.190e+00, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25440, Loss: 1.075e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25450, Loss: 1.079e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25460, Loss: 9.784e+00, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25470, Loss: 1.152e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25480, Loss: 2.877e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25490, Loss: 9.088e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25500, Loss: 1.308e+01, Y0: 77.002, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25510, Loss: 1.186e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25520, Loss: 1.085e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25530, Loss: 1.124e+01, Y0: 77.029, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25540, Loss: 1.015e+01, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25550, Loss: 1.125e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25560, Loss: 9.608e+00, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25570, Loss: 1.076e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 25580, Loss: 1.100e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25590, Loss: 1.112e+01, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 25600, Loss: 1.067e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.86s\n",
      "Epoch: 25610, Loss: 9.507e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 25620, Loss: 1.049e+01, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25630, Loss: 1.045e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25640, Loss: 9.783e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25650, Loss: 1.141e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25660, Loss: 1.192e+01, Y0: 77.079, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25670, Loss: 9.809e+00, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25680, Loss: 1.171e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25690, Loss: 1.126e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25700, Loss: 9.720e+00, Y0: 77.130, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25710, Loss: 1.161e+01, Y0: 77.094, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25720, Loss: 1.316e+01, Y0: 76.971, Learning Rate: 1.000e-05, Time: 0.65s\n",
      "Epoch: 25730, Loss: 1.045e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 25740, Loss: 1.020e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25750, Loss: 9.445e+00, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25760, Loss: 9.768e+00, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25770, Loss: 9.969e+00, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 25780, Loss: 9.544e+00, Y0: 77.172, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 25790, Loss: 1.078e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 25800, Loss: 1.012e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25810, Loss: 1.013e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25820, Loss: 9.351e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25830, Loss: 9.440e+00, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 25840, Loss: 9.893e+00, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25850, Loss: 9.975e+00, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 25860, Loss: 9.745e+00, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25870, Loss: 1.083e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 25880, Loss: 9.983e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25890, Loss: 1.035e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25900, Loss: 1.059e+01, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25910, Loss: 1.041e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25920, Loss: 1.093e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 25930, Loss: 1.137e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25940, Loss: 1.072e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 25950, Loss: 1.089e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 25960, Loss: 9.327e+00, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 25970, Loss: 9.120e+00, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 25980, Loss: 1.064e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 25990, Loss: 9.351e+00, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26000, Loss: 1.004e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26010, Loss: 9.975e+00, Y0: 77.129, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26020, Loss: 1.106e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26030, Loss: 9.251e+00, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26040, Loss: 9.879e+00, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26050, Loss: 8.750e+00, Y0: 77.138, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 26060, Loss: 1.220e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26070, Loss: 1.066e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26080, Loss: 1.013e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26090, Loss: 1.052e+01, Y0: 77.134, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26100, Loss: 1.070e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 26110, Loss: 1.010e+01, Y0: 77.092, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26120, Loss: 9.470e+00, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26130, Loss: 1.091e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26140, Loss: 9.306e+00, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 26150, Loss: 9.866e+00, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 26160, Loss: 1.003e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 26170, Loss: 9.500e+00, Y0: 76.946, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26180, Loss: 1.031e+01, Y0: 77.135, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 26190, Loss: 1.042e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 26200, Loss: 9.908e+00, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26210, Loss: 9.826e+00, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26220, Loss: 1.122e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26230, Loss: 1.030e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26240, Loss: 1.066e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.56s\n",
      "Epoch: 26250, Loss: 1.099e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26260, Loss: 1.670e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 26270, Loss: 9.744e+00, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26280, Loss: 9.454e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26290, Loss: 9.751e+00, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26300, Loss: 1.052e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26310, Loss: 8.739e+00, Y0: 77.015, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26320, Loss: 1.051e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 26330, Loss: 1.050e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 26340, Loss: 1.071e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 26350, Loss: 1.166e+01, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26360, Loss: 1.344e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26370, Loss: 1.082e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26380, Loss: 9.926e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26390, Loss: 1.045e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26400, Loss: 9.756e+00, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26410, Loss: 9.960e+00, Y0: 77.022, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26420, Loss: 9.960e+00, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 26430, Loss: 1.066e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26440, Loss: 9.468e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26450, Loss: 1.104e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26460, Loss: 9.686e+00, Y0: 77.014, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26470, Loss: 1.023e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26480, Loss: 1.036e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26490, Loss: 1.142e+01, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26500, Loss: 1.080e+01, Y0: 77.037, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26510, Loss: 1.023e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 26520, Loss: 1.141e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 26530, Loss: 1.038e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 26540, Loss: 1.079e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26550, Loss: 1.027e+01, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26560, Loss: 1.038e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26570, Loss: 1.051e+01, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26580, Loss: 9.813e+00, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26590, Loss: 9.632e+00, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 26600, Loss: 1.024e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26610, Loss: 1.074e+01, Y0: 77.001, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26620, Loss: 1.092e+01, Y0: 77.114, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26630, Loss: 1.043e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26640, Loss: 1.038e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26650, Loss: 9.044e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 26660, Loss: 9.952e+00, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26670, Loss: 1.091e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26680, Loss: 1.011e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26690, Loss: 1.123e+01, Y0: 77.158, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 26700, Loss: 1.128e+01, Y0: 77.102, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 26710, Loss: 9.858e+00, Y0: 76.993, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 26720, Loss: 9.299e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26730, Loss: 1.018e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26740, Loss: 1.074e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26750, Loss: 1.031e+01, Y0: 77.097, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26760, Loss: 9.363e+00, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26770, Loss: 1.166e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26780, Loss: 1.069e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26790, Loss: 1.005e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 26800, Loss: 1.006e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26810, Loss: 1.049e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26820, Loss: 9.438e+00, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26830, Loss: 1.055e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26840, Loss: 1.040e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26850, Loss: 1.052e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26860, Loss: 1.017e+01, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26870, Loss: 1.033e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26880, Loss: 1.030e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 26890, Loss: 9.675e+00, Y0: 77.027, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 26900, Loss: 9.381e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 26910, Loss: 1.028e+01, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26920, Loss: 9.359e+00, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26930, Loss: 1.049e+01, Y0: 77.126, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26940, Loss: 1.006e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 26950, Loss: 1.045e+01, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26960, Loss: 1.071e+01, Y0: 77.031, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 26970, Loss: 1.052e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26980, Loss: 1.026e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 26990, Loss: 1.091e+01, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 27000, Loss: 1.207e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27010, Loss: 1.080e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27020, Loss: 9.399e+00, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27030, Loss: 9.358e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27040, Loss: 9.395e+00, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 27050, Loss: 9.807e+00, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27060, Loss: 1.018e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.75s\n",
      "Epoch: 27070, Loss: 9.811e+00, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 27080, Loss: 1.047e+01, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 27090, Loss: 1.027e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27100, Loss: 1.068e+01, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27110, Loss: 1.001e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27120, Loss: 1.025e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27130, Loss: 1.213e+01, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27140, Loss: 9.653e+00, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 27150, Loss: 1.016e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27160, Loss: 1.003e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 27170, Loss: 1.063e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 27180, Loss: 9.777e+00, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27190, Loss: 1.053e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27200, Loss: 9.668e+00, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27210, Loss: 1.071e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27220, Loss: 9.993e+00, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27230, Loss: 1.035e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27240, Loss: 9.873e+00, Y0: 76.978, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 27250, Loss: 1.024e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 27260, Loss: 1.181e+01, Y0: 77.045, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 27270, Loss: 1.178e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27280, Loss: 1.172e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27290, Loss: 9.505e+00, Y0: 77.008, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27300, Loss: 1.028e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27310, Loss: 9.923e+00, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.64s\n",
      "Epoch: 27320, Loss: 1.008e+01, Y0: 76.990, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27330, Loss: 1.080e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27340, Loss: 1.009e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27350, Loss: 9.933e+00, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27360, Loss: 1.094e+01, Y0: 76.976, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27370, Loss: 9.651e+00, Y0: 77.151, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27380, Loss: 9.736e+00, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27390, Loss: 1.034e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 27400, Loss: 1.255e+01, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27410, Loss: 1.104e+01, Y0: 77.038, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27420, Loss: 1.130e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 27430, Loss: 1.033e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.89s\n",
      "Epoch: 27440, Loss: 1.098e+01, Y0: 77.108, Learning Rate: 1.000e-05, Time: 0.73s\n",
      "Epoch: 27450, Loss: 9.789e+00, Y0: 77.063, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27460, Loss: 9.576e+00, Y0: 77.139, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27470, Loss: 1.119e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27480, Loss: 1.080e+01, Y0: 77.129, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27490, Loss: 1.034e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27500, Loss: 9.641e+00, Y0: 77.011, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27510, Loss: 1.038e+01, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27520, Loss: 1.011e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27530, Loss: 1.065e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27540, Loss: 1.017e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27550, Loss: 1.101e+01, Y0: 77.007, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27560, Loss: 9.197e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27570, Loss: 1.111e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27580, Loss: 1.009e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27590, Loss: 1.083e+01, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27600, Loss: 8.585e+00, Y0: 77.072, Learning Rate: 1.000e-05, Time: 0.73s\n",
      "Epoch: 27610, Loss: 9.362e+00, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 27620, Loss: 1.118e+01, Y0: 77.025, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 27630, Loss: 9.618e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27640, Loss: 9.399e+00, Y0: 77.016, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27650, Loss: 1.026e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27660, Loss: 1.084e+01, Y0: 76.986, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27670, Loss: 1.036e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 27680, Loss: 9.345e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27690, Loss: 9.919e+00, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27700, Loss: 1.036e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27710, Loss: 1.060e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27720, Loss: 1.117e+01, Y0: 77.006, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 27730, Loss: 9.225e+00, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27740, Loss: 1.079e+01, Y0: 76.977, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27750, Loss: 9.658e+00, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27760, Loss: 1.004e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27770, Loss: 1.001e+01, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27780, Loss: 9.704e+00, Y0: 77.036, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 27790, Loss: 1.221e+01, Y0: 77.110, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 27800, Loss: 1.111e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 27810, Loss: 1.231e+01, Y0: 77.146, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27820, Loss: 1.331e+01, Y0: 77.005, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27830, Loss: 1.172e+01, Y0: 77.119, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27840, Loss: 1.160e+01, Y0: 77.013, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27850, Loss: 1.073e+01, Y0: 77.096, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27860, Loss: 1.211e+01, Y0: 77.021, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27870, Loss: 1.075e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27880, Loss: 9.261e+00, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 27890, Loss: 1.041e+01, Y0: 76.947, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27900, Loss: 1.017e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27910, Loss: 1.050e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27920, Loss: 9.807e+00, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27930, Loss: 9.947e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27940, Loss: 1.015e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27950, Loss: 1.073e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 27960, Loss: 9.833e+00, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 27970, Loss: 9.662e+00, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.79s\n",
      "Epoch: 27980, Loss: 1.068e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 27990, Loss: 1.098e+01, Y0: 77.091, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 28000, Loss: 9.707e+00, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28010, Loss: 1.002e+01, Y0: 77.017, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28020, Loss: 1.013e+01, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28030, Loss: 1.031e+01, Y0: 77.062, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28040, Loss: 1.046e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28050, Loss: 1.086e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28060, Loss: 8.988e+00, Y0: 77.012, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28070, Loss: 1.056e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28080, Loss: 1.036e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 28090, Loss: 1.021e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28100, Loss: 1.005e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28110, Loss: 9.649e+00, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28120, Loss: 9.417e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28130, Loss: 8.736e+00, Y0: 77.099, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28140, Loss: 1.033e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28150, Loss: 1.049e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.69s\n",
      "Epoch: 28160, Loss: 1.103e+01, Y0: 76.997, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 28170, Loss: 1.002e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 28180, Loss: 1.004e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28190, Loss: 1.008e+01, Y0: 77.058, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 28200, Loss: 1.023e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28210, Loss: 1.098e+01, Y0: 77.067, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28220, Loss: 1.019e+01, Y0: 77.078, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28230, Loss: 9.919e+00, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28240, Loss: 1.033e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28250, Loss: 9.435e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28260, Loss: 9.617e+00, Y0: 77.117, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28270, Loss: 9.963e+00, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28280, Loss: 9.867e+00, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28290, Loss: 1.159e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28300, Loss: 1.070e+01, Y0: 77.153, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28310, Loss: 1.017e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28320, Loss: 9.515e+00, Y0: 77.060, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28330, Loss: 9.082e+00, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28340, Loss: 1.164e+01, Y0: 77.116, Learning Rate: 1.000e-05, Time: 0.85s\n",
      "Epoch: 28350, Loss: 1.044e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 28360, Loss: 1.058e+01, Y0: 77.109, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28370, Loss: 9.664e+00, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28380, Loss: 1.124e+01, Y0: 77.057, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28390, Loss: 1.182e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28400, Loss: 1.024e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 28410, Loss: 1.078e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28420, Loss: 9.786e+00, Y0: 76.998, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28430, Loss: 1.041e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28440, Loss: 1.115e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 28450, Loss: 1.026e+01, Y0: 77.068, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28460, Loss: 1.017e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28470, Loss: 2.055e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28480, Loss: 1.160e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28490, Loss: 9.734e+00, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28500, Loss: 1.044e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28510, Loss: 9.593e+00, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28520, Loss: 1.142e+01, Y0: 77.136, Learning Rate: 1.000e-05, Time: 0.77s\n",
      "Epoch: 28530, Loss: 1.073e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 28540, Loss: 8.881e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.70s\n",
      "Epoch: 28550, Loss: 1.045e+01, Y0: 77.150, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28560, Loss: 1.036e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.63s\n",
      "Epoch: 28570, Loss: 1.006e+01, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28580, Loss: 1.087e+01, Y0: 77.098, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28590, Loss: 1.021e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28600, Loss: 1.071e+01, Y0: 77.100, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28610, Loss: 1.025e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28620, Loss: 1.036e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28630, Loss: 1.074e+01, Y0: 77.141, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28640, Loss: 1.039e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28650, Loss: 9.853e+00, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28660, Loss: 9.814e+00, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 28670, Loss: 1.082e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28680, Loss: 9.305e+00, Y0: 77.129, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28690, Loss: 9.357e+00, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28700, Loss: 9.845e+00, Y0: 76.989, Learning Rate: 1.000e-05, Time: 0.67s\n",
      "Epoch: 28710, Loss: 1.075e+01, Y0: 77.127, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 28720, Loss: 1.019e+01, Y0: 77.034, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 28730, Loss: 9.921e+00, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28740, Loss: 1.019e+01, Y0: 77.059, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 28750, Loss: 9.565e+00, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28760, Loss: 9.852e+00, Y0: 77.138, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28770, Loss: 1.070e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28780, Loss: 1.030e+01, Y0: 77.035, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28790, Loss: 1.020e+01, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28800, Loss: 1.077e+01, Y0: 77.132, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 28810, Loss: 1.058e+01, Y0: 77.087, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28820, Loss: 1.003e+01, Y0: 77.054, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28830, Loss: 1.057e+01, Y0: 77.106, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28840, Loss: 1.037e+01, Y0: 77.141, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28850, Loss: 1.007e+01, Y0: 77.018, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28860, Loss: 9.003e+00, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28870, Loss: 9.766e+00, Y0: 77.175, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28880, Loss: 1.027e+01, Y0: 77.028, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 28890, Loss: 1.043e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 28900, Loss: 8.556e+00, Y0: 77.030, Learning Rate: 1.000e-05, Time: 0.88s\n",
      "Epoch: 28910, Loss: 1.037e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28920, Loss: 9.573e+00, Y0: 77.076, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28930, Loss: 1.125e+01, Y0: 77.126, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28940, Loss: 1.084e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28950, Loss: 1.054e+01, Y0: 77.122, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28960, Loss: 1.053e+01, Y0: 77.111, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 28970, Loss: 9.880e+00, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 28980, Loss: 1.064e+01, Y0: 77.143, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 28990, Loss: 1.031e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29000, Loss: 1.047e+01, Y0: 77.023, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29010, Loss: 1.044e+01, Y0: 77.003, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29020, Loss: 9.535e+00, Y0: 77.142, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29030, Loss: 1.048e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29040, Loss: 9.482e+00, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29050, Loss: 9.965e+00, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29060, Loss: 1.101e+01, Y0: 76.994, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29070, Loss: 1.062e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.76s\n",
      "Epoch: 29080, Loss: 1.027e+01, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 29090, Loss: 9.354e+00, Y0: 77.115, Learning Rate: 1.000e-05, Time: 0.74s\n",
      "Epoch: 29100, Loss: 9.783e+00, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29110, Loss: 1.033e+01, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29120, Loss: 1.095e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29130, Loss: 1.005e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.62s\n",
      "Epoch: 29140, Loss: 1.034e+01, Y0: 77.090, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29150, Loss: 1.051e+01, Y0: 77.118, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29160, Loss: 1.135e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29170, Loss: 1.085e+01, Y0: 77.019, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29180, Loss: 1.033e+01, Y0: 77.150, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29190, Loss: 9.991e+00, Y0: 77.020, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29200, Loss: 9.511e+00, Y0: 77.071, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29210, Loss: 1.061e+01, Y0: 77.081, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29220, Loss: 1.071e+01, Y0: 77.044, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29230, Loss: 1.133e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29240, Loss: 1.054e+01, Y0: 77.070, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29250, Loss: 1.061e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 29260, Loss: 9.663e+00, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.82s\n",
      "Epoch: 29270, Loss: 1.032e+01, Y0: 76.982, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 29280, Loss: 1.097e+01, Y0: 77.135, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29290, Loss: 1.096e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29300, Loss: 1.214e+01, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29310, Loss: 1.085e+01, Y0: 77.024, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29320, Loss: 1.240e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29330, Loss: 1.017e+01, Y0: 77.107, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29340, Loss: 1.052e+01, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29350, Loss: 1.055e+01, Y0: 77.077, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29360, Loss: 1.001e+01, Y0: 77.095, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29370, Loss: 1.044e+01, Y0: 77.053, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29380, Loss: 9.757e+00, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 29390, Loss: 1.011e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29400, Loss: 1.211e+01, Y0: 77.125, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29410, Loss: 1.103e+01, Y0: 77.032, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29420, Loss: 1.659e+01, Y0: 77.128, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29430, Loss: 1.040e+01, Y0: 77.000, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29440, Loss: 9.406e+00, Y0: 77.064, Learning Rate: 1.000e-05, Time: 0.78s\n",
      "Epoch: 29450, Loss: 1.035e+01, Y0: 77.123, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 29460, Loss: 8.682e+00, Y0: 77.104, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 29470, Loss: 1.030e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29480, Loss: 9.970e+00, Y0: 77.080, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29490, Loss: 1.030e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 29500, Loss: 1.075e+01, Y0: 77.047, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29510, Loss: 1.058e+01, Y0: 77.083, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 29520, Loss: 1.080e+01, Y0: 76.999, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29530, Loss: 1.058e+01, Y0: 77.050, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29540, Loss: 1.069e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29550, Loss: 1.025e+01, Y0: 77.121, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29560, Loss: 1.009e+01, Y0: 77.039, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29570, Loss: 1.033e+01, Y0: 77.082, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29580, Loss: 9.619e+00, Y0: 77.069, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29590, Loss: 9.715e+00, Y0: 77.051, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29600, Loss: 1.008e+01, Y0: 77.046, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29610, Loss: 1.020e+01, Y0: 77.065, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29620, Loss: 1.044e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.68s\n",
      "Epoch: 29630, Loss: 1.010e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.83s\n",
      "Epoch: 29640, Loss: 9.932e+00, Y0: 77.074, Learning Rate: 1.000e-05, Time: 0.80s\n",
      "Epoch: 29650, Loss: 9.864e+00, Y0: 77.133, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29660, Loss: 1.008e+01, Y0: 76.996, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29670, Loss: 1.005e+01, Y0: 77.126, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29680, Loss: 1.014e+01, Y0: 76.958, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29690, Loss: 1.019e+01, Y0: 77.052, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29700, Loss: 1.072e+01, Y0: 77.049, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29710, Loss: 1.021e+01, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29720, Loss: 1.145e+01, Y0: 76.952, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29730, Loss: 1.124e+01, Y0: 77.120, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29740, Loss: 9.841e+00, Y0: 77.043, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29750, Loss: 1.065e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29760, Loss: 1.031e+01, Y0: 77.073, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29770, Loss: 9.751e+00, Y0: 76.984, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29780, Loss: 1.026e+01, Y0: 77.088, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29790, Loss: 9.909e+00, Y0: 77.085, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29800, Loss: 9.886e+00, Y0: 77.093, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29810, Loss: 1.054e+01, Y0: 77.042, Learning Rate: 1.000e-05, Time: 0.84s\n",
      "Epoch: 29820, Loss: 1.006e+01, Y0: 77.103, Learning Rate: 1.000e-05, Time: 0.87s\n",
      "Epoch: 29830, Loss: 1.082e+01, Y0: 77.026, Learning Rate: 1.000e-05, Time: 0.66s\n",
      "Epoch: 29840, Loss: 1.078e+01, Y0: 77.066, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29850, Loss: 9.735e+00, Y0: 77.041, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29860, Loss: 1.031e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29870, Loss: 1.086e+01, Y0: 77.086, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29880, Loss: 9.423e+00, Y0: 77.033, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 29890, Loss: 1.102e+01, Y0: 77.112, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29900, Loss: 1.030e+01, Y0: 77.113, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 29910, Loss: 1.024e+01, Y0: 77.061, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29920, Loss: 1.182e+01, Y0: 77.084, Learning Rate: 1.000e-05, Time: 0.61s\n",
      "Epoch: 29930, Loss: 1.029e+01, Y0: 77.105, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29940, Loss: 1.007e+01, Y0: 76.992, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29950, Loss: 1.079e+01, Y0: 77.075, Learning Rate: 1.000e-05, Time: 0.57s\n",
      "Epoch: 29960, Loss: 9.362e+00, Y0: 77.004, Learning Rate: 1.000e-05, Time: 0.60s\n",
      "Epoch: 29970, Loss: 1.007e+01, Y0: 77.089, Learning Rate: 1.000e-05, Time: 0.58s\n",
      "Epoch: 29980, Loss: 1.064e+01, Y0: 77.055, Learning Rate: 1.000e-05, Time: 0.59s\n",
      "Epoch: 29990, Loss: 1.010e+01, Y0: 77.101, Learning Rate: 1.000e-05, Time: 0.72s\n",
      "Epoch: 0, Loss: 9.929e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.09s\n",
      "Epoch: 10, Loss: 1.036e+01, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.78s\n",
      "Epoch: 20, Loss: 1.010e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 30, Loss: 1.053e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 40, Loss: 1.202e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 50, Loss: 9.438e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 60, Loss: 1.038e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 70, Loss: 9.118e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 80, Loss: 9.761e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 90, Loss: 1.048e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 100, Loss: 1.039e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 110, Loss: 1.207e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 120, Loss: 1.058e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 130, Loss: 9.948e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 140, Loss: 1.022e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 150, Loss: 9.550e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 160, Loss: 1.033e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 170, Loss: 9.788e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 180, Loss: 1.095e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 190, Loss: 1.023e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 200, Loss: 1.011e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 210, Loss: 1.018e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 220, Loss: 1.072e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 230, Loss: 9.648e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 240, Loss: 1.026e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 250, Loss: 1.028e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 260, Loss: 1.075e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 270, Loss: 1.030e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 280, Loss: 1.178e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 290, Loss: 1.045e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 300, Loss: 1.154e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 310, Loss: 9.975e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 320, Loss: 1.020e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 330, Loss: 8.902e+00, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 340, Loss: 1.002e+01, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 350, Loss: 1.166e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 360, Loss: 1.056e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 370, Loss: 1.026e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.81s\n",
      "Epoch: 380, Loss: 9.356e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 390, Loss: 9.612e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 400, Loss: 1.109e+01, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 410, Loss: 1.024e+01, Y0: 77.038, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 420, Loss: 1.064e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.56s\n",
      "Epoch: 430, Loss: 1.010e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 440, Loss: 9.982e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 450, Loss: 9.008e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 460, Loss: 1.117e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 470, Loss: 1.039e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 480, Loss: 1.058e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 490, Loss: 1.010e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 500, Loss: 1.055e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 510, Loss: 1.034e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 520, Loss: 9.644e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 530, Loss: 9.915e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 540, Loss: 1.016e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 550, Loss: 1.028e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 560, Loss: 9.926e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 570, Loss: 9.637e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 580, Loss: 9.967e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 590, Loss: 1.250e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 600, Loss: 9.436e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 610, Loss: 1.010e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 620, Loss: 9.157e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 630, Loss: 9.401e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 640, Loss: 1.125e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 650, Loss: 1.045e+01, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 660, Loss: 9.641e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 670, Loss: 9.864e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 680, Loss: 1.028e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 690, Loss: 1.018e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 700, Loss: 9.744e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 710, Loss: 9.501e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 720, Loss: 9.657e+00, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 730, Loss: 3.262e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 740, Loss: 9.942e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 750, Loss: 9.835e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 760, Loss: 9.301e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 770, Loss: 1.006e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 780, Loss: 9.304e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 790, Loss: 1.056e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 800, Loss: 8.861e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 810, Loss: 9.344e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 820, Loss: 1.043e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 830, Loss: 8.998e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 840, Loss: 9.175e+00, Y0: 77.038, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 850, Loss: 1.066e+01, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 860, Loss: 1.018e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 870, Loss: 1.022e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 880, Loss: 1.088e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 890, Loss: 1.045e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 900, Loss: 9.776e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 910, Loss: 9.687e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 920, Loss: 9.963e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 930, Loss: 9.786e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 940, Loss: 1.015e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 950, Loss: 9.747e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 960, Loss: 1.052e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 970, Loss: 1.134e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 980, Loss: 1.066e+01, Y0: 77.112, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 990, Loss: 9.094e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1000, Loss: 1.042e+01, Y0: 77.033, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1010, Loss: 9.976e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1020, Loss: 9.437e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 1030, Loss: 1.027e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1040, Loss: 1.045e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1050, Loss: 1.248e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1060, Loss: 9.377e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1070, Loss: 1.099e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1080, Loss: 1.024e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1090, Loss: 9.794e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 1100, Loss: 1.198e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 1110, Loss: 9.981e+00, Y0: 77.118, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 1120, Loss: 9.917e+00, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1130, Loss: 9.989e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1140, Loss: 9.451e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1150, Loss: 1.027e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1160, Loss: 9.843e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 1170, Loss: 1.109e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1180, Loss: 9.492e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1190, Loss: 9.554e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1200, Loss: 9.232e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1210, Loss: 9.447e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1220, Loss: 9.902e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1230, Loss: 9.355e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1240, Loss: 1.109e+01, Y0: 77.027, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1250, Loss: 1.008e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1260, Loss: 1.230e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1270, Loss: 1.073e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 1280, Loss: 1.005e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 1290, Loss: 1.382e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 1300, Loss: 9.728e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1310, Loss: 9.721e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1320, Loss: 9.023e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1330, Loss: 1.045e+01, Y0: 77.028, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1340, Loss: 9.385e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1350, Loss: 1.027e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1360, Loss: 9.517e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1370, Loss: 9.754e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1380, Loss: 9.611e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1390, Loss: 1.062e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1400, Loss: 1.039e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1410, Loss: 1.006e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1420, Loss: 1.136e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1430, Loss: 1.057e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1440, Loss: 1.180e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1450, Loss: 1.038e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 1460, Loss: 1.014e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 1470, Loss: 9.921e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 1480, Loss: 9.514e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1490, Loss: 9.473e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1500, Loss: 1.027e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1510, Loss: 9.550e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1520, Loss: 1.037e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1530, Loss: 1.032e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1540, Loss: 9.808e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1550, Loss: 9.788e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1560, Loss: 1.003e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1570, Loss: 1.049e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1580, Loss: 9.244e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1590, Loss: 1.119e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1600, Loss: 9.618e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1610, Loss: 1.024e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1620, Loss: 9.128e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1630, Loss: 1.029e+01, Y0: 77.033, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 1640, Loss: 9.523e+00, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 1650, Loss: 1.511e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 1660, Loss: 1.081e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1670, Loss: 1.003e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1680, Loss: 1.101e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1690, Loss: 9.317e+00, Y0: 77.032, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1700, Loss: 1.003e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 1710, Loss: 1.166e+01, Y0: 77.109, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1720, Loss: 9.806e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 1730, Loss: 1.016e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1740, Loss: 1.029e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1750, Loss: 9.749e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1760, Loss: 9.173e+00, Y0: 77.034, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1770, Loss: 1.100e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1780, Loss: 1.097e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1790, Loss: 9.655e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1800, Loss: 1.007e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1810, Loss: 9.126e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1820, Loss: 9.453e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 1830, Loss: 9.793e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.89s\n",
      "Epoch: 1840, Loss: 9.811e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1850, Loss: 9.688e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1860, Loss: 1.006e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 1870, Loss: 1.011e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1880, Loss: 9.654e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1890, Loss: 1.111e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1900, Loss: 1.031e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 1910, Loss: 8.516e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1920, Loss: 9.764e+00, Y0: 77.022, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1930, Loss: 1.179e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 1940, Loss: 1.109e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 1950, Loss: 9.929e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1960, Loss: 1.102e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1970, Loss: 1.043e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1980, Loss: 1.031e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 1990, Loss: 9.608e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2000, Loss: 1.035e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 2010, Loss: 1.066e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 2020, Loss: 1.067e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2030, Loss: 9.222e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2040, Loss: 1.116e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 2050, Loss: 1.155e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2060, Loss: 9.769e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2070, Loss: 1.147e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2080, Loss: 9.780e+00, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2090, Loss: 9.004e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2100, Loss: 9.885e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2110, Loss: 9.703e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2120, Loss: 9.514e+00, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2130, Loss: 1.106e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2140, Loss: 1.052e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2150, Loss: 1.011e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2160, Loss: 1.079e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2170, Loss: 9.899e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2180, Loss: 9.611e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 2190, Loss: 9.123e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 2200, Loss: 9.263e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2210, Loss: 9.731e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 2220, Loss: 1.021e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2230, Loss: 9.672e+00, Y0: 77.015, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 2240, Loss: 1.036e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2250, Loss: 9.680e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 2260, Loss: 1.025e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2270, Loss: 1.141e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2280, Loss: 1.050e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2290, Loss: 1.053e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2300, Loss: 1.045e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2310, Loss: 1.041e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2320, Loss: 9.247e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2330, Loss: 1.410e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2340, Loss: 9.509e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2350, Loss: 1.083e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2360, Loss: 1.004e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 2370, Loss: 1.106e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 2380, Loss: 9.654e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 2390, Loss: 1.076e+01, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2400, Loss: 9.757e+00, Y0: 77.015, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2410, Loss: 8.650e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2420, Loss: 1.040e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2430, Loss: 9.457e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2440, Loss: 9.718e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2450, Loss: 1.065e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2460, Loss: 9.899e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2470, Loss: 9.781e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2480, Loss: 1.086e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2490, Loss: 1.244e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2500, Loss: 1.005e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2510, Loss: 1.173e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2520, Loss: 1.096e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2530, Loss: 1.008e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2540, Loss: 1.064e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 2550, Loss: 1.134e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 2560, Loss: 9.383e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 2570, Loss: 9.942e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2580, Loss: 1.040e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2590, Loss: 9.582e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2600, Loss: 9.168e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2610, Loss: 9.333e+00, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2620, Loss: 9.442e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2630, Loss: 1.028e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2640, Loss: 9.954e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2650, Loss: 9.746e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2660, Loss: 9.815e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2670, Loss: 1.100e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2680, Loss: 9.378e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2690, Loss: 1.057e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2700, Loss: 9.636e+00, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2710, Loss: 9.991e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2720, Loss: 8.617e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 2730, Loss: 1.029e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.91s\n",
      "Epoch: 2740, Loss: 9.770e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.65s\n",
      "Epoch: 2750, Loss: 1.020e+01, Y0: 77.028, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2760, Loss: 9.782e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2770, Loss: 1.000e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2780, Loss: 9.242e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2790, Loss: 9.857e+00, Y0: 77.038, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2800, Loss: 9.804e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2810, Loss: 1.019e+01, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2820, Loss: 1.220e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 2830, Loss: 9.428e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2840, Loss: 1.005e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2850, Loss: 1.002e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2860, Loss: 9.539e+00, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 2870, Loss: 9.315e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2880, Loss: 1.120e+01, Y0: 77.032, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2890, Loss: 1.006e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 2900, Loss: 9.813e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 2910, Loss: 9.643e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 2920, Loss: 9.531e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 2930, Loss: 1.061e+01, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2940, Loss: 1.057e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2950, Loss: 9.947e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2960, Loss: 9.682e+00, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 2970, Loss: 1.141e+01, Y0: 77.025, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 2980, Loss: 9.788e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 2990, Loss: 9.084e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 3000, Loss: 9.828e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 3010, Loss: 9.718e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3020, Loss: 1.057e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3030, Loss: 1.128e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3040, Loss: 9.706e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3050, Loss: 9.268e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3060, Loss: 9.670e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3070, Loss: 9.091e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.65s\n",
      "Epoch: 3080, Loss: 1.080e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 3090, Loss: 9.573e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 3100, Loss: 9.910e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3110, Loss: 9.998e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 3120, Loss: 9.699e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 3130, Loss: 9.633e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3140, Loss: 1.028e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3150, Loss: 9.234e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3160, Loss: 9.293e+00, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3170, Loss: 8.794e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3180, Loss: 1.013e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 3190, Loss: 1.001e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3200, Loss: 1.034e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3210, Loss: 9.369e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3220, Loss: 1.003e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3230, Loss: 1.036e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 3240, Loss: 1.067e+01, Y0: 77.035, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3250, Loss: 9.174e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 3260, Loss: 9.684e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 3270, Loss: 9.632e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.75s\n",
      "Epoch: 3280, Loss: 9.849e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3290, Loss: 9.678e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3300, Loss: 1.062e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3310, Loss: 1.042e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 3320, Loss: 1.142e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3330, Loss: 1.116e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3340, Loss: 9.112e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3350, Loss: 1.059e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3360, Loss: 9.637e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3370, Loss: 1.089e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3380, Loss: 1.000e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3390, Loss: 9.404e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3400, Loss: 1.024e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3410, Loss: 1.050e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3420, Loss: 9.789e+00, Y0: 77.028, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3430, Loss: 9.747e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 3440, Loss: 1.144e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 3450, Loss: 9.568e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 3460, Loss: 1.016e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3470, Loss: 9.113e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3480, Loss: 9.873e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3490, Loss: 9.009e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3500, Loss: 1.045e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3510, Loss: 9.565e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3520, Loss: 9.987e+00, Y0: 77.023, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3530, Loss: 1.007e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 3540, Loss: 1.052e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3550, Loss: 1.074e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3560, Loss: 9.296e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3570, Loss: 1.017e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3580, Loss: 9.771e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3590, Loss: 1.082e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 3600, Loss: 1.130e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3610, Loss: 9.422e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 3620, Loss: 1.015e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 3630, Loss: 1.005e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 3640, Loss: 9.200e+00, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3650, Loss: 9.778e+00, Y0: 77.027, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3660, Loss: 9.775e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 3670, Loss: 9.648e+00, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3680, Loss: 1.119e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3690, Loss: 1.246e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3700, Loss: 9.595e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3710, Loss: 9.888e+00, Y0: 77.043, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3720, Loss: 1.030e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3730, Loss: 1.104e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3740, Loss: 1.087e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3750, Loss: 1.071e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3760, Loss: 9.409e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3770, Loss: 9.632e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 3780, Loss: 1.272e+03, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3790, Loss: 1.228e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 3800, Loss: 1.001e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 3810, Loss: 9.972e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 3820, Loss: 1.091e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 3830, Loss: 9.340e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3840, Loss: 9.523e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3850, Loss: 9.998e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3860, Loss: 9.391e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3870, Loss: 9.985e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 3880, Loss: 1.046e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3890, Loss: 9.256e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3900, Loss: 9.256e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3910, Loss: 1.001e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 3920, Loss: 9.154e+00, Y0: 77.106, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3930, Loss: 9.513e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3940, Loss: 1.062e+01, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3950, Loss: 9.681e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 3960, Loss: 9.623e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 3970, Loss: 9.513e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 3980, Loss: 1.094e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.90s\n",
      "Epoch: 3990, Loss: 9.942e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 4000, Loss: 9.972e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4010, Loss: 1.029e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 4020, Loss: 9.829e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4030, Loss: 1.032e+01, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4040, Loss: 9.623e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4050, Loss: 1.005e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4060, Loss: 1.032e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 4070, Loss: 1.024e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4080, Loss: 9.386e+00, Y0: 77.030, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4090, Loss: 9.375e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4100, Loss: 1.008e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4110, Loss: 9.927e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4120, Loss: 1.152e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4130, Loss: 9.886e+00, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4140, Loss: 1.098e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4150, Loss: 9.809e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 4160, Loss: 9.848e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.91s\n",
      "Epoch: 4170, Loss: 1.194e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4180, Loss: 1.040e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4190, Loss: 1.066e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4200, Loss: 9.265e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4210, Loss: 9.605e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4220, Loss: 1.013e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 4230, Loss: 9.379e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4240, Loss: 1.000e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 4250, Loss: 9.763e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4260, Loss: 1.018e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4270, Loss: 1.096e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4280, Loss: 9.523e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4290, Loss: 9.548e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4300, Loss: 1.053e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4310, Loss: 1.030e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4320, Loss: 9.563e+00, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 4330, Loss: 1.047e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 4340, Loss: 9.820e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 4350, Loss: 9.911e+00, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4360, Loss: 9.277e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4370, Loss: 9.556e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4380, Loss: 9.961e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 4390, Loss: 1.139e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 4400, Loss: 1.029e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4410, Loss: 1.001e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4420, Loss: 1.027e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4430, Loss: 9.074e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4440, Loss: 9.554e+00, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4450, Loss: 1.161e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4460, Loss: 1.045e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4470, Loss: 1.005e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4480, Loss: 9.620e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4490, Loss: 1.034e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4500, Loss: 1.062e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 4510, Loss: 1.084e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 4520, Loss: 9.985e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 4530, Loss: 1.072e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4540, Loss: 9.617e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 4550, Loss: 9.761e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4560, Loss: 9.912e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4570, Loss: 1.019e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4580, Loss: 1.024e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4590, Loss: 9.951e+00, Y0: 77.029, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4600, Loss: 9.952e+00, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4610, Loss: 9.754e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4620, Loss: 9.284e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4630, Loss: 9.988e+00, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4640, Loss: 1.022e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 4650, Loss: 9.292e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4660, Loss: 1.020e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4670, Loss: 1.051e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4680, Loss: 1.071e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 4690, Loss: 1.040e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 4700, Loss: 1.040e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 4710, Loss: 9.933e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 4720, Loss: 9.315e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4730, Loss: 9.821e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4740, Loss: 9.786e+00, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4750, Loss: 9.461e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4760, Loss: 8.726e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4770, Loss: 1.062e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4780, Loss: 1.051e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4790, Loss: 1.015e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4800, Loss: 9.747e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4810, Loss: 9.415e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4820, Loss: 9.837e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4830, Loss: 1.120e+01, Y0: 77.035, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4840, Loss: 1.089e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 4850, Loss: 9.497e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 4860, Loss: 1.029e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 4870, Loss: 1.039e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 4880, Loss: 1.149e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 4890, Loss: 1.069e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4900, Loss: 9.153e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4910, Loss: 9.825e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4920, Loss: 9.515e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4930, Loss: 1.014e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4940, Loss: 1.010e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 4950, Loss: 1.002e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4960, Loss: 1.035e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 4970, Loss: 9.307e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 4980, Loss: 9.818e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 4990, Loss: 1.053e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5000, Loss: 9.692e+00, Y0: 77.117, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5010, Loss: 9.922e+00, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5020, Loss: 1.053e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5030, Loss: 1.018e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 5040, Loss: 9.512e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 5050, Loss: 1.013e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 5060, Loss: 9.225e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.69s\n",
      "Epoch: 5070, Loss: 1.002e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5080, Loss: 9.595e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5090, Loss: 9.702e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 5100, Loss: 9.489e+00, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5110, Loss: 1.071e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5120, Loss: 1.008e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5130, Loss: 1.052e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 5140, Loss: 9.643e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5150, Loss: 1.102e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5160, Loss: 1.074e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5170, Loss: 9.611e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 5180, Loss: 9.932e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5190, Loss: 9.839e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5200, Loss: 8.955e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5210, Loss: 1.001e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5220, Loss: 1.071e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 5230, Loss: 9.981e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 5240, Loss: 1.091e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 5250, Loss: 9.370e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5260, Loss: 9.379e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5270, Loss: 9.731e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5280, Loss: 9.392e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5290, Loss: 1.051e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5300, Loss: 9.281e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5310, Loss: 1.091e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5320, Loss: 9.347e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5330, Loss: 1.008e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5340, Loss: 9.858e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5350, Loss: 9.278e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5360, Loss: 9.755e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5370, Loss: 1.163e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5380, Loss: 1.005e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5390, Loss: 1.018e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 5400, Loss: 9.716e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 5410, Loss: 1.075e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 5420, Loss: 9.792e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5430, Loss: 1.112e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 5440, Loss: 9.873e+00, Y0: 77.106, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5450, Loss: 1.176e+01, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5460, Loss: 9.874e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5470, Loss: 1.023e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5480, Loss: 1.127e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5490, Loss: 1.067e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5500, Loss: 9.006e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5510, Loss: 9.971e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5520, Loss: 9.384e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5530, Loss: 1.357e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5540, Loss: 1.024e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5550, Loss: 9.869e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5560, Loss: 1.124e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5570, Loss: 9.663e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 5580, Loss: 1.102e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 5590, Loss: 9.227e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 5600, Loss: 9.732e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5610, Loss: 9.608e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5620, Loss: 9.919e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5630, Loss: 8.911e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5640, Loss: 1.014e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 5650, Loss: 1.082e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 5660, Loss: 1.074e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5670, Loss: 1.011e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 5680, Loss: 1.056e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 5690, Loss: 1.020e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 5700, Loss: 1.175e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5710, Loss: 1.113e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5720, Loss: 1.044e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5730, Loss: 1.150e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5740, Loss: 1.170e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5750, Loss: 1.105e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 5760, Loss: 1.067e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 5770, Loss: 9.764e+00, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.78s\n",
      "Epoch: 5780, Loss: 1.046e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5790, Loss: 9.545e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5800, Loss: 9.685e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5810, Loss: 1.026e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5820, Loss: 1.053e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5830, Loss: 1.054e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5840, Loss: 9.722e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5850, Loss: 9.935e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5860, Loss: 9.608e+00, Y0: 77.122, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5870, Loss: 1.042e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5880, Loss: 1.024e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5890, Loss: 1.046e+01, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5900, Loss: 1.014e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5910, Loss: 1.136e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5920, Loss: 9.796e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5930, Loss: 9.449e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 5940, Loss: 9.616e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 5950, Loss: 1.006e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 5960, Loss: 1.118e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5970, Loss: 1.045e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 5980, Loss: 9.408e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 5990, Loss: 9.009e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6000, Loss: 9.674e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6010, Loss: 9.597e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6020, Loss: 9.926e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6030, Loss: 1.026e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6040, Loss: 9.737e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6050, Loss: 1.099e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6060, Loss: 9.484e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6070, Loss: 1.050e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6080, Loss: 1.026e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6090, Loss: 1.133e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6100, Loss: 1.064e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6110, Loss: 1.001e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 6120, Loss: 1.011e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 6130, Loss: 1.093e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 6140, Loss: 9.063e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 6150, Loss: 9.657e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6160, Loss: 1.088e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6170, Loss: 9.831e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6180, Loss: 9.299e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6190, Loss: 1.151e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6200, Loss: 1.057e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6210, Loss: 9.685e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6220, Loss: 9.549e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6230, Loss: 1.046e+01, Y0: 77.043, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6240, Loss: 1.033e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6250, Loss: 9.012e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6260, Loss: 9.534e+00, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6270, Loss: 1.096e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 6280, Loss: 9.553e+00, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6290, Loss: 1.068e+01, Y0: 77.115, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 6300, Loss: 9.498e+00, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 6310, Loss: 1.202e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 6320, Loss: 9.596e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6330, Loss: 9.347e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6340, Loss: 9.780e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6350, Loss: 1.095e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6360, Loss: 9.701e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6370, Loss: 1.144e+01, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6380, Loss: 9.372e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6390, Loss: 9.498e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6400, Loss: 1.053e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6410, Loss: 1.157e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6420, Loss: 1.028e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6430, Loss: 1.102e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 6440, Loss: 1.110e+01, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6450, Loss: 9.301e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6460, Loss: 1.094e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 6470, Loss: 8.976e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 6480, Loss: 9.977e+00, Y0: 77.035, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 6490, Loss: 1.205e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 6500, Loss: 1.073e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6510, Loss: 9.985e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6520, Loss: 1.029e+01, Y0: 77.038, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6530, Loss: 9.549e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6540, Loss: 1.016e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6550, Loss: 9.369e+00, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6560, Loss: 9.205e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6570, Loss: 1.062e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6580, Loss: 1.010e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6590, Loss: 1.073e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6600, Loss: 1.031e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6610, Loss: 1.048e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6620, Loss: 9.571e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6630, Loss: 1.050e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6640, Loss: 9.857e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6650, Loss: 1.043e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 6660, Loss: 9.470e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 6670, Loss: 9.911e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6680, Loss: 1.021e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6690, Loss: 9.408e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6700, Loss: 9.896e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6710, Loss: 9.606e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6720, Loss: 9.732e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 6730, Loss: 9.251e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6740, Loss: 1.039e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6750, Loss: 9.034e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6760, Loss: 1.007e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6770, Loss: 1.029e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6780, Loss: 9.651e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6790, Loss: 1.021e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6800, Loss: 1.010e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6810, Loss: 1.025e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 6820, Loss: 9.986e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 6830, Loss: 9.464e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 6840, Loss: 1.214e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.91s\n",
      "Epoch: 6850, Loss: 1.183e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6860, Loss: 9.746e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 6870, Loss: 9.592e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6880, Loss: 9.971e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6890, Loss: 1.058e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6900, Loss: 9.808e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6910, Loss: 1.046e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6920, Loss: 9.868e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6930, Loss: 1.043e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 6940, Loss: 9.801e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6950, Loss: 9.706e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6960, Loss: 9.981e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6970, Loss: 9.963e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 6980, Loss: 1.042e+01, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 6990, Loss: 1.030e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7000, Loss: 1.013e+01, Y0: 77.107, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 7010, Loss: 9.550e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 7020, Loss: 1.029e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 7030, Loss: 1.012e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7040, Loss: 1.021e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7050, Loss: 1.062e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7060, Loss: 1.005e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7070, Loss: 1.003e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7080, Loss: 1.334e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7090, Loss: 9.180e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7100, Loss: 9.064e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7110, Loss: 1.139e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7120, Loss: 1.104e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 7130, Loss: 1.048e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 7140, Loss: 9.194e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7150, Loss: 1.169e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7160, Loss: 9.460e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7170, Loss: 9.431e+00, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7180, Loss: 8.694e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 7190, Loss: 1.027e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 7200, Loss: 1.021e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 7210, Loss: 1.095e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7220, Loss: 9.860e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7230, Loss: 8.870e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 7240, Loss: 1.036e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7250, Loss: 9.797e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7260, Loss: 1.084e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 7270, Loss: 8.512e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7280, Loss: 1.022e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7290, Loss: 1.041e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 7300, Loss: 1.013e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7310, Loss: 9.806e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7320, Loss: 1.020e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7330, Loss: 9.698e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7340, Loss: 1.022e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7350, Loss: 9.421e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7360, Loss: 9.597e+00, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 7370, Loss: 1.036e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 7380, Loss: 1.074e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 7390, Loss: 1.059e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7400, Loss: 1.020e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7410, Loss: 1.022e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7420, Loss: 1.028e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 7430, Loss: 9.822e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7440, Loss: 9.179e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7450, Loss: 1.041e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7460, Loss: 9.693e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7470, Loss: 1.057e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 7480, Loss: 9.484e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 7490, Loss: 1.058e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7500, Loss: 1.009e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7510, Loss: 9.968e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7520, Loss: 9.460e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7530, Loss: 1.023e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7540, Loss: 1.188e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 7550, Loss: 1.029e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 7560, Loss: 9.581e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 7570, Loss: 1.517e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7580, Loss: 1.013e+01, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 7590, Loss: 9.848e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7600, Loss: 1.077e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7610, Loss: 9.700e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7620, Loss: 1.166e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7630, Loss: 9.796e+00, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7640, Loss: 1.039e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7650, Loss: 9.961e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7660, Loss: 1.045e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7670, Loss: 1.051e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7680, Loss: 9.194e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7690, Loss: 9.808e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7700, Loss: 9.871e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7710, Loss: 1.044e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7720, Loss: 1.060e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 7730, Loss: 8.478e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 7740, Loss: 1.065e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 7750, Loss: 1.052e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7760, Loss: 9.384e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7770, Loss: 9.951e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7780, Loss: 8.975e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7790, Loss: 1.129e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7800, Loss: 9.493e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7810, Loss: 1.023e+01, Y0: 77.029, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7820, Loss: 1.069e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7830, Loss: 9.866e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7840, Loss: 1.027e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7850, Loss: 1.135e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 7860, Loss: 9.658e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7870, Loss: 9.971e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7880, Loss: 1.009e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 7890, Loss: 9.361e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7900, Loss: 8.990e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.81s\n",
      "Epoch: 7910, Loss: 1.053e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.89s\n",
      "Epoch: 7920, Loss: 1.081e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 7930, Loss: 1.024e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7940, Loss: 1.036e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7950, Loss: 9.347e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7960, Loss: 1.032e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 7970, Loss: 1.050e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 7980, Loss: 1.045e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 7990, Loss: 9.190e+01, Y0: 77.038, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8000, Loss: 1.036e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8010, Loss: 9.700e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8020, Loss: 1.044e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8030, Loss: 9.538e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8040, Loss: 9.171e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8050, Loss: 9.982e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8060, Loss: 9.626e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8070, Loss: 9.411e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8080, Loss: 8.981e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 8090, Loss: 1.042e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 8100, Loss: 1.037e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8110, Loss: 9.544e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8120, Loss: 1.277e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8130, Loss: 1.147e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8140, Loss: 1.209e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8150, Loss: 1.021e+01, Y0: 77.030, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8160, Loss: 9.952e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8170, Loss: 9.646e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 8180, Loss: 1.056e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8190, Loss: 1.114e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8200, Loss: 9.212e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8210, Loss: 9.772e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8220, Loss: 1.026e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 8230, Loss: 1.040e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8240, Loss: 9.973e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8250, Loss: 9.232e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.65s\n",
      "Epoch: 8260, Loss: 1.053e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 8270, Loss: 1.021e+01, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 8280, Loss: 1.056e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8290, Loss: 1.058e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8300, Loss: 1.032e+01, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8310, Loss: 1.003e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8320, Loss: 9.685e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8330, Loss: 9.773e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 8340, Loss: 9.095e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8350, Loss: 1.047e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8360, Loss: 1.050e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8370, Loss: 9.254e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8380, Loss: 1.166e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8390, Loss: 1.053e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8400, Loss: 1.001e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8410, Loss: 9.764e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8420, Loss: 9.569e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8430, Loss: 1.039e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 8440, Loss: 8.986e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 8450, Loss: 1.158e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 8460, Loss: 1.139e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8470, Loss: 9.361e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8480, Loss: 1.009e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8490, Loss: 1.005e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8500, Loss: 1.001e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8510, Loss: 1.021e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8520, Loss: 9.672e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 8530, Loss: 1.242e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8540, Loss: 1.016e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8550, Loss: 9.716e+00, Y0: 77.014, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8560, Loss: 1.014e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8570, Loss: 1.047e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8580, Loss: 9.076e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8590, Loss: 9.509e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8600, Loss: 9.241e+00, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8610, Loss: 1.022e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 8620, Loss: 1.040e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 8630, Loss: 1.052e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 8640, Loss: 1.011e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8650, Loss: 1.161e+01, Y0: 77.043, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8660, Loss: 1.154e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8670, Loss: 1.037e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8680, Loss: 1.149e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8690, Loss: 1.073e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8700, Loss: 1.025e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8710, Loss: 9.891e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8720, Loss: 1.042e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 8730, Loss: 9.649e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 8740, Loss: 9.167e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8750, Loss: 1.040e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8760, Loss: 1.019e+01, Y0: 77.123, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8770, Loss: 9.816e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8780, Loss: 9.490e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8790, Loss: 1.031e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 8800, Loss: 1.186e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 8810, Loss: 1.038e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 8820, Loss: 1.003e+01, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8830, Loss: 8.839e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8840, Loss: 1.029e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8850, Loss: 1.053e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8860, Loss: 1.242e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8870, Loss: 1.024e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8880, Loss: 1.090e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8890, Loss: 9.986e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8900, Loss: 9.777e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8910, Loss: 1.011e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8920, Loss: 1.106e+01, Y0: 77.018, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8930, Loss: 9.704e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8940, Loss: 9.854e+00, Y0: 77.109, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8950, Loss: 1.070e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 8960, Loss: 9.848e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 8970, Loss: 1.050e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 8980, Loss: 1.031e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 8990, Loss: 1.110e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 9000, Loss: 9.807e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9010, Loss: 1.112e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9020, Loss: 1.046e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9030, Loss: 9.973e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9040, Loss: 1.041e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9050, Loss: 1.153e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 9060, Loss: 8.785e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9070, Loss: 1.276e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9080, Loss: 1.002e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9090, Loss: 9.853e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9100, Loss: 9.626e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9110, Loss: 1.132e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9120, Loss: 9.266e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 9130, Loss: 1.057e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 9140, Loss: 9.910e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9150, Loss: 9.606e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 9160, Loss: 1.036e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 9170, Loss: 1.020e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 9180, Loss: 9.448e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9190, Loss: 9.654e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 9200, Loss: 1.076e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9210, Loss: 9.776e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9220, Loss: 9.488e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9230, Loss: 9.049e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9240, Loss: 9.278e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 9250, Loss: 9.422e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 9260, Loss: 9.356e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9270, Loss: 9.997e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9280, Loss: 1.085e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9290, Loss: 1.009e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9300, Loss: 9.853e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9310, Loss: 1.068e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9320, Loss: 1.015e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9330, Loss: 1.086e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 9340, Loss: 1.054e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 9350, Loss: 9.262e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 9360, Loss: 9.430e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9370, Loss: 1.035e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9380, Loss: 9.835e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9390, Loss: 9.409e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9400, Loss: 1.018e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9410, Loss: 1.014e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9420, Loss: 9.749e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9430, Loss: 1.043e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 9440, Loss: 9.988e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9450, Loss: 1.114e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9460, Loss: 9.683e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9470, Loss: 1.021e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9480, Loss: 1.001e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9490, Loss: 1.008e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 9500, Loss: 9.529e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9510, Loss: 9.837e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 9520, Loss: 9.536e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.89s\n",
      "Epoch: 9530, Loss: 9.612e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 9540, Loss: 8.920e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.65s\n",
      "Epoch: 9550, Loss: 8.949e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 9560, Loss: 9.562e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9570, Loss: 9.684e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9580, Loss: 9.465e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9590, Loss: 1.052e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9600, Loss: 1.094e+01, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9610, Loss: 9.608e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9620, Loss: 1.037e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9630, Loss: 9.984e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9640, Loss: 9.716e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9650, Loss: 1.070e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9660, Loss: 9.088e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9670, Loss: 1.102e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9680, Loss: 9.077e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 9690, Loss: 1.010e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 9700, Loss: 1.064e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 9710, Loss: 1.083e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9720, Loss: 1.029e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 9730, Loss: 1.033e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9740, Loss: 9.069e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9750, Loss: 1.037e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9760, Loss: 1.095e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 9770, Loss: 9.535e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9780, Loss: 1.185e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 9790, Loss: 1.167e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9800, Loss: 9.587e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9810, Loss: 9.360e+00, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9820, Loss: 1.095e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9830, Loss: 1.064e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9840, Loss: 1.061e+01, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9850, Loss: 9.201e+00, Y0: 77.118, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9860, Loss: 9.104e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 9870, Loss: 1.063e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 9880, Loss: 9.230e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 9890, Loss: 1.041e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9900, Loss: 1.065e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9910, Loss: 9.831e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9920, Loss: 1.059e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9930, Loss: 1.024e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9940, Loss: 8.916e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9950, Loss: 9.396e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 9960, Loss: 1.085e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9970, Loss: 9.542e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 9980, Loss: 1.051e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 9990, Loss: 9.857e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10000, Loss: 9.161e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 10010, Loss: 1.041e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10020, Loss: 1.074e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 10030, Loss: 9.525e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10040, Loss: 9.209e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 10050, Loss: 1.016e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 10060, Loss: 9.050e+00, Y0: 77.033, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10070, Loss: 1.214e+01, Y0: 77.127, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10080, Loss: 9.350e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10090, Loss: 9.699e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10100, Loss: 2.028e+02, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10110, Loss: 1.081e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10120, Loss: 1.095e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10130, Loss: 9.557e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10140, Loss: 8.853e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10150, Loss: 1.092e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 10160, Loss: 9.869e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10170, Loss: 1.054e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10180, Loss: 9.831e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10190, Loss: 9.753e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10200, Loss: 9.946e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10210, Loss: 1.282e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10220, Loss: 8.774e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 10230, Loss: 1.062e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 10240, Loss: 9.488e+00, Y0: 77.034, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10250, Loss: 9.244e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10260, Loss: 9.983e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10270, Loss: 1.013e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10280, Loss: 9.814e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10290, Loss: 9.480e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 10300, Loss: 9.945e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10310, Loss: 1.110e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10320, Loss: 9.678e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10330, Loss: 9.775e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10340, Loss: 1.001e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10350, Loss: 9.376e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10360, Loss: 1.016e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10370, Loss: 9.311e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10380, Loss: 1.030e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10390, Loss: 8.966e+00, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 10400, Loss: 1.065e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 10410, Loss: 1.157e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 10420, Loss: 9.560e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10430, Loss: 1.040e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10440, Loss: 9.308e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10450, Loss: 9.281e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10460, Loss: 1.064e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10470, Loss: 9.511e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10480, Loss: 9.627e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10490, Loss: 9.903e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10500, Loss: 1.023e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10510, Loss: 9.209e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10520, Loss: 9.739e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10530, Loss: 9.918e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10540, Loss: 1.022e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10550, Loss: 1.166e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10560, Loss: 9.449e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10570, Loss: 1.059e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.81s\n",
      "Epoch: 10580, Loss: 9.609e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 10590, Loss: 1.194e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.69s\n",
      "Epoch: 10600, Loss: 9.344e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 10610, Loss: 9.250e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10620, Loss: 1.025e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10630, Loss: 1.014e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 10640, Loss: 1.050e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10650, Loss: 1.043e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10660, Loss: 9.050e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10670, Loss: 9.821e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10680, Loss: 9.711e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10690, Loss: 1.037e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10700, Loss: 1.082e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10710, Loss: 1.029e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10720, Loss: 1.022e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10730, Loss: 1.072e+01, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10740, Loss: 9.375e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10750, Loss: 9.290e+00, Y0: 77.124, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 10760, Loss: 1.166e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 10770, Loss: 9.409e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10780, Loss: 1.029e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10790, Loss: 1.011e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 10800, Loss: 1.061e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10810, Loss: 1.052e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 10820, Loss: 1.019e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10830, Loss: 2.313e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10840, Loss: 9.822e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10850, Loss: 9.838e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10860, Loss: 9.574e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10870, Loss: 1.101e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10880, Loss: 9.719e+00, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 10890, Loss: 1.020e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10900, Loss: 9.696e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10910, Loss: 1.079e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10920, Loss: 9.380e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 10930, Loss: 9.973e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.91s\n",
      "Epoch: 10940, Loss: 1.027e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.91s\n",
      "Epoch: 10950, Loss: 1.060e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 10960, Loss: 9.265e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10970, Loss: 1.077e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 10980, Loss: 1.003e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 10990, Loss: 9.570e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11000, Loss: 9.619e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 11010, Loss: 9.180e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11020, Loss: 1.018e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11030, Loss: 1.074e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11040, Loss: 9.259e+00, Y0: 77.119, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11050, Loss: 1.024e+01, Y0: 77.023, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11060, Loss: 1.046e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 11070, Loss: 9.499e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11080, Loss: 1.074e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11090, Loss: 9.735e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11100, Loss: 9.546e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 11110, Loss: 1.095e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 11120, Loss: 9.824e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 11130, Loss: 1.192e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11140, Loss: 1.069e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11150, Loss: 2.949e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11160, Loss: 1.029e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 11170, Loss: 1.017e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11180, Loss: 9.727e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11190, Loss: 9.729e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11200, Loss: 1.068e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11210, Loss: 1.027e+01, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11220, Loss: 9.890e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11230, Loss: 1.000e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11240, Loss: 9.890e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11250, Loss: 9.813e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11260, Loss: 9.891e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11270, Loss: 1.033e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11280, Loss: 9.421e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 11290, Loss: 1.086e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 11300, Loss: 1.029e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 11310, Loss: 1.004e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 11320, Loss: 9.821e+00, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11330, Loss: 9.862e+00, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11340, Loss: 1.172e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 11350, Loss: 9.839e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11360, Loss: 9.591e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11370, Loss: 9.676e+00, Y0: 77.112, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11380, Loss: 9.751e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11390, Loss: 9.132e+00, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11400, Loss: 9.893e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11410, Loss: 1.048e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11420, Loss: 1.013e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11430, Loss: 1.099e+01, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11440, Loss: 1.053e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11450, Loss: 1.071e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11460, Loss: 9.360e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 11470, Loss: 1.126e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 11480, Loss: 1.015e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 11490, Loss: 1.078e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11500, Loss: 1.006e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11510, Loss: 1.023e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 11520, Loss: 9.420e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11530, Loss: 1.196e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11540, Loss: 1.279e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 11550, Loss: 9.025e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11560, Loss: 9.654e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11570, Loss: 1.036e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11580, Loss: 1.078e+01, Y0: 77.043, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11590, Loss: 9.607e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11600, Loss: 1.014e+01, Y0: 77.115, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11610, Loss: 8.958e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11620, Loss: 1.048e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11630, Loss: 1.051e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11640, Loss: 9.761e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 11650, Loss: 1.004e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 11660, Loss: 9.457e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 11670, Loss: 1.151e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11680, Loss: 1.057e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11690, Loss: 9.732e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11700, Loss: 9.617e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11710, Loss: 1.539e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11720, Loss: 9.377e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11730, Loss: 1.061e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11740, Loss: 9.851e+00, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11750, Loss: 1.002e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 11760, Loss: 1.186e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11770, Loss: 1.013e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11780, Loss: 9.030e+00, Y0: 77.030, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11790, Loss: 9.501e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11800, Loss: 1.099e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 11810, Loss: 9.590e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11820, Loss: 1.037e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 11830, Loss: 9.882e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 11840, Loss: 1.148e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 11850, Loss: 9.592e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11860, Loss: 9.710e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11870, Loss: 9.888e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11880, Loss: 9.842e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11890, Loss: 1.068e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11900, Loss: 9.119e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11910, Loss: 9.579e+00, Y0: 77.028, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11920, Loss: 1.212e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11930, Loss: 1.087e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11940, Loss: 1.176e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11950, Loss: 1.003e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11960, Loss: 9.458e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 11970, Loss: 9.482e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 11980, Loss: 1.021e+01, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 11990, Loss: 9.310e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12000, Loss: 1.040e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 12010, Loss: 1.058e+01, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.89s\n",
      "Epoch: 12020, Loss: 1.058e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12030, Loss: 9.871e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12040, Loss: 9.769e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12050, Loss: 1.188e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12060, Loss: 9.458e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12070, Loss: 9.965e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12080, Loss: 9.863e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12090, Loss: 1.074e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12100, Loss: 9.273e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12110, Loss: 1.035e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12120, Loss: 1.014e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12130, Loss: 1.017e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12140, Loss: 1.049e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12150, Loss: 1.105e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12160, Loss: 1.010e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12170, Loss: 9.469e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 12180, Loss: 9.537e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 12190, Loss: 1.025e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 12200, Loss: 9.446e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12210, Loss: 1.024e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12220, Loss: 9.789e+00, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12230, Loss: 1.003e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12240, Loss: 9.759e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12250, Loss: 1.026e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12260, Loss: 1.101e+01, Y0: 77.107, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12270, Loss: 9.748e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12280, Loss: 1.262e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12290, Loss: 1.021e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12300, Loss: 1.012e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12310, Loss: 9.556e+00, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12320, Loss: 9.732e+00, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12330, Loss: 9.704e+00, Y0: 77.106, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12340, Loss: 9.712e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12350, Loss: 1.148e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12360, Loss: 1.011e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 12370, Loss: 1.091e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.91s\n",
      "Epoch: 12380, Loss: 1.007e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12390, Loss: 9.621e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12400, Loss: 1.134e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12410, Loss: 1.070e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12420, Loss: 1.019e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12430, Loss: 9.608e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.64s\n",
      "Epoch: 12440, Loss: 1.029e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12450, Loss: 9.853e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12460, Loss: 9.644e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12470, Loss: 9.672e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12480, Loss: 1.043e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12490, Loss: 1.045e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12500, Loss: 9.634e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12510, Loss: 1.007e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12520, Loss: 1.068e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12530, Loss: 9.458e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12540, Loss: 9.705e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 12550, Loss: 9.994e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 12560, Loss: 9.389e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12570, Loss: 1.059e+01, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12580, Loss: 9.843e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12590, Loss: 9.684e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12600, Loss: 1.075e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12610, Loss: 1.047e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12620, Loss: 9.693e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12630, Loss: 9.743e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 12640, Loss: 9.637e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12650, Loss: 1.033e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12660, Loss: 1.063e+01, Y0: 77.114, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12670, Loss: 1.117e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12680, Loss: 1.035e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12690, Loss: 9.716e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12700, Loss: 9.702e+00, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12710, Loss: 9.842e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.69s\n",
      "Epoch: 12720, Loss: 1.052e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 12730, Loss: 1.375e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 12740, Loss: 1.043e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 12750, Loss: 9.187e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12760, Loss: 9.505e+00, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12770, Loss: 1.008e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12780, Loss: 1.149e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12790, Loss: 9.707e+00, Y0: 77.113, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12800, Loss: 1.013e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12810, Loss: 1.243e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12820, Loss: 1.007e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12830, Loss: 9.704e+00, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 12840, Loss: 9.886e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12850, Loss: 1.017e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12860, Loss: 1.032e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12870, Loss: 1.141e+01, Y0: 77.032, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12880, Loss: 1.144e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12890, Loss: 9.421e+00, Y0: 77.106, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 12900, Loss: 9.919e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 12910, Loss: 1.827e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.81s\n",
      "Epoch: 12920, Loss: 9.905e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12930, Loss: 1.050e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12940, Loss: 1.092e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12950, Loss: 1.146e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 12960, Loss: 9.430e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12970, Loss: 1.079e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 12980, Loss: 9.480e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 12990, Loss: 9.485e+00, Y0: 77.042, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13000, Loss: 9.550e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13010, Loss: 1.096e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13020, Loss: 1.023e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 13030, Loss: 1.024e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13040, Loss: 1.022e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13050, Loss: 1.048e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13060, Loss: 1.033e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13070, Loss: 8.866e+00, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 13080, Loss: 9.208e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 13090, Loss: 9.715e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 13100, Loss: 9.958e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13110, Loss: 1.026e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13120, Loss: 1.001e+01, Y0: 77.115, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13130, Loss: 9.636e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 13140, Loss: 1.037e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 13150, Loss: 1.131e+01, Y0: 77.113, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13160, Loss: 9.970e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13170, Loss: 9.566e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13180, Loss: 1.015e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 13190, Loss: 9.794e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13200, Loss: 1.017e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13210, Loss: 1.040e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13220, Loss: 9.684e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13230, Loss: 1.108e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13240, Loss: 9.804e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13250, Loss: 9.287e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.69s\n",
      "Epoch: 13260, Loss: 9.964e+00, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 13270, Loss: 9.529e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 13280, Loss: 9.912e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13290, Loss: 9.465e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13300, Loss: 9.706e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13310, Loss: 1.123e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13320, Loss: 9.530e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 13330, Loss: 8.967e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13340, Loss: 1.019e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13350, Loss: 1.008e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13360, Loss: 9.591e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13370, Loss: 9.884e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13380, Loss: 9.148e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13390, Loss: 1.111e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13400, Loss: 1.088e+01, Y0: 77.109, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13410, Loss: 9.535e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13420, Loss: 1.070e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13430, Loss: 8.993e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.70s\n",
      "Epoch: 13440, Loss: 1.032e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 13450, Loss: 9.936e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.81s\n",
      "Epoch: 13460, Loss: 1.097e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 13470, Loss: 9.127e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13480, Loss: 1.028e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13490, Loss: 9.780e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13500, Loss: 1.056e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13510, Loss: 9.036e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13520, Loss: 1.081e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 13530, Loss: 1.008e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13540, Loss: 1.036e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13550, Loss: 1.107e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13560, Loss: 1.049e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13570, Loss: 1.027e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13580, Loss: 9.238e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13590, Loss: 9.381e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13600, Loss: 1.168e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13610, Loss: 9.318e+00, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.70s\n",
      "Epoch: 13620, Loss: 9.850e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 13630, Loss: 1.003e+01, Y0: 77.024, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 13640, Loss: 8.871e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 13650, Loss: 1.050e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13660, Loss: 1.055e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 13670, Loss: 9.981e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13680, Loss: 1.071e+01, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13690, Loss: 9.479e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 13700, Loss: 1.086e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13710, Loss: 9.176e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13720, Loss: 1.183e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13730, Loss: 9.804e+00, Y0: 77.032, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13740, Loss: 9.016e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 13750, Loss: 9.754e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13760, Loss: 9.186e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 13770, Loss: 1.021e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13780, Loss: 9.809e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13790, Loss: 9.877e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 13800, Loss: 1.014e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 13810, Loss: 1.096e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.90s\n",
      "Epoch: 13820, Loss: 1.007e+01, Y0: 77.138, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 13830, Loss: 1.111e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13840, Loss: 1.088e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13850, Loss: 1.078e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 13860, Loss: 1.108e+01, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13870, Loss: 1.014e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 13880, Loss: 9.500e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13890, Loss: 9.994e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13900, Loss: 9.617e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 13910, Loss: 1.070e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13920, Loss: 8.865e+00, Y0: 77.113, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 13930, Loss: 1.056e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13940, Loss: 9.807e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 13950, Loss: 1.031e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 13960, Loss: 9.241e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 13970, Loss: 9.522e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 13980, Loss: 1.022e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 13990, Loss: 1.034e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 14000, Loss: 9.406e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 14010, Loss: 9.265e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14020, Loss: 9.427e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14030, Loss: 1.031e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14040, Loss: 1.043e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14050, Loss: 9.781e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14060, Loss: 1.071e+01, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14070, Loss: 1.035e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14080, Loss: 9.083e+00, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14090, Loss: 1.061e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14100, Loss: 1.093e+01, Y0: 77.029, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14110, Loss: 1.031e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14120, Loss: 1.018e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14130, Loss: 9.730e+00, Y0: 77.107, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14140, Loss: 1.055e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14150, Loss: 1.019e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14160, Loss: 1.022e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14170, Loss: 1.027e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 14180, Loss: 1.012e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 14190, Loss: 1.023e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 14200, Loss: 9.459e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14210, Loss: 9.519e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14220, Loss: 1.042e+01, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14230, Loss: 9.940e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14240, Loss: 1.042e+01, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14250, Loss: 1.078e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14260, Loss: 1.034e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14270, Loss: 1.020e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14280, Loss: 1.068e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 14290, Loss: 9.988e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14300, Loss: 1.101e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14310, Loss: 9.995e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14320, Loss: 9.587e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14330, Loss: 1.069e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14340, Loss: 1.116e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14350, Loss: 1.017e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 14360, Loss: 1.027e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 14370, Loss: 1.148e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 14380, Loss: 9.488e+00, Y0: 77.109, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14390, Loss: 9.905e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14400, Loss: 9.595e+00, Y0: 77.037, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14410, Loss: 1.064e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 14420, Loss: 1.063e+01, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14430, Loss: 9.335e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 14440, Loss: 1.080e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14450, Loss: 1.174e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14460, Loss: 9.828e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14470, Loss: 9.340e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14480, Loss: 1.015e+01, Y0: 77.106, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14490, Loss: 1.030e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14500, Loss: 1.051e+01, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14510, Loss: 1.027e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14520, Loss: 1.042e+01, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14530, Loss: 9.931e+00, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 14540, Loss: 8.700e+00, Y0: 77.022, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 14550, Loss: 1.158e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 14560, Loss: 1.076e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14570, Loss: 1.076e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 14580, Loss: 1.046e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14590, Loss: 1.135e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14600, Loss: 8.927e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 14610, Loss: 1.095e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14620, Loss: 9.317e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14630, Loss: 9.890e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14640, Loss: 9.912e+00, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14650, Loss: 1.008e+01, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14660, Loss: 1.037e+01, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14670, Loss: 1.017e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14680, Loss: 1.119e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14690, Loss: 9.770e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14700, Loss: 9.976e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14710, Loss: 9.069e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14720, Loss: 9.806e+00, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 14730, Loss: 1.056e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 14740, Loss: 1.039e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 14750, Loss: 9.297e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 14760, Loss: 9.310e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14770, Loss: 9.540e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 14780, Loss: 1.003e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14790, Loss: 1.074e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14800, Loss: 1.013e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14810, Loss: 9.737e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14820, Loss: 1.105e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14830, Loss: 9.826e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14840, Loss: 1.298e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14850, Loss: 1.027e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14860, Loss: 9.774e+00, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 14870, Loss: 1.059e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14880, Loss: 1.021e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14890, Loss: 9.640e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 14900, Loss: 1.002e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 14910, Loss: 9.660e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 14920, Loss: 1.023e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 14930, Loss: 9.653e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14940, Loss: 9.554e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14950, Loss: 1.054e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14960, Loss: 1.122e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 14970, Loss: 1.036e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 14980, Loss: 9.913e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 14990, Loss: 1.049e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15000, Loss: 9.265e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15010, Loss: 1.004e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15020, Loss: 9.446e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15030, Loss: 9.443e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15040, Loss: 1.081e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15050, Loss: 9.742e+00, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15060, Loss: 1.094e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15070, Loss: 1.063e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 15080, Loss: 1.079e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15090, Loss: 1.009e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 15100, Loss: 1.007e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.90s\n",
      "Epoch: 15110, Loss: 1.023e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15120, Loss: 1.033e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15130, Loss: 1.031e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15140, Loss: 1.085e+01, Y0: 77.030, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15150, Loss: 9.957e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15160, Loss: 9.451e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15170, Loss: 1.023e+01, Y0: 77.033, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15180, Loss: 1.004e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15190, Loss: 1.059e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15200, Loss: 9.084e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15210, Loss: 9.421e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15220, Loss: 1.046e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 15230, Loss: 9.659e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15240, Loss: 1.005e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15250, Loss: 1.170e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15260, Loss: 9.897e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15270, Loss: 9.765e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 15280, Loss: 1.026e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 15290, Loss: 1.016e+01, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.69s\n",
      "Epoch: 15300, Loss: 1.078e+01, Y0: 77.116, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15310, Loss: 1.045e+01, Y0: 77.051, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15320, Loss: 9.741e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15330, Loss: 1.065e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15340, Loss: 1.013e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15350, Loss: 1.059e+01, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15360, Loss: 1.021e+01, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15370, Loss: 9.891e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15380, Loss: 1.029e+01, Y0: 77.047, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15390, Loss: 9.299e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 15400, Loss: 1.132e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15410, Loss: 1.087e+01, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15420, Loss: 9.424e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15430, Loss: 1.191e+01, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 15440, Loss: 1.010e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15450, Loss: 9.828e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 15460, Loss: 1.087e+01, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 15470, Loss: 9.814e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 15480, Loss: 1.087e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15490, Loss: 9.100e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15500, Loss: 1.137e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15510, Loss: 9.602e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 15520, Loss: 9.966e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15530, Loss: 9.652e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15540, Loss: 1.018e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15550, Loss: 9.817e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15560, Loss: 1.059e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15570, Loss: 1.111e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15580, Loss: 1.011e+01, Y0: 77.123, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15590, Loss: 9.938e+00, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15600, Loss: 1.018e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15610, Loss: 9.976e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15620, Loss: 1.010e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 15630, Loss: 8.954e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15640, Loss: 1.009e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 15650, Loss: 1.005e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 15660, Loss: 8.982e+00, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 15670, Loss: 1.016e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 15680, Loss: 9.766e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15690, Loss: 9.604e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 15700, Loss: 9.876e+00, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15710, Loss: 1.057e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15720, Loss: 9.291e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15730, Loss: 1.007e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15740, Loss: 9.927e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15750, Loss: 1.003e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 15760, Loss: 9.233e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 15770, Loss: 1.171e+01, Y0: 77.057, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15780, Loss: 1.128e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15790, Loss: 1.149e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15800, Loss: 1.023e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15810, Loss: 1.021e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15820, Loss: 9.982e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 15830, Loss: 9.097e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 15840, Loss: 9.265e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 15850, Loss: 1.093e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 15860, Loss: 1.047e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15870, Loss: 9.650e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15880, Loss: 9.980e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15890, Loss: 9.552e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 15900, Loss: 1.016e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15910, Loss: 1.052e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15920, Loss: 9.969e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15930, Loss: 1.054e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15940, Loss: 8.924e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15950, Loss: 1.012e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15960, Loss: 9.804e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 15970, Loss: 9.374e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 15980, Loss: 1.147e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 15990, Loss: 9.734e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16000, Loss: 1.136e+01, Y0: 77.043, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16010, Loss: 9.948e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 16020, Loss: 1.067e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.88s\n",
      "Epoch: 16030, Loss: 1.072e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 16040, Loss: 9.136e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 16050, Loss: 1.056e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16060, Loss: 1.284e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16070, Loss: 9.978e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16080, Loss: 1.089e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16090, Loss: 1.047e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 16100, Loss: 1.045e+01, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16110, Loss: 1.045e+01, Y0: 77.114, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16120, Loss: 9.669e+00, Y0: 77.133, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16130, Loss: 1.033e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16140, Loss: 1.020e+01, Y0: 77.107, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16150, Loss: 1.004e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16160, Loss: 9.877e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16170, Loss: 1.032e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16180, Loss: 9.420e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16190, Loss: 1.177e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 16200, Loss: 9.685e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 16210, Loss: 9.543e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 16220, Loss: 1.078e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16230, Loss: 9.877e+00, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16240, Loss: 1.133e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16250, Loss: 9.531e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16260, Loss: 1.006e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16270, Loss: 1.054e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16280, Loss: 1.076e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16290, Loss: 1.040e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16300, Loss: 9.934e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16310, Loss: 1.004e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16320, Loss: 9.593e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16330, Loss: 1.017e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16340, Loss: 9.649e+00, Y0: 77.100, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 16350, Loss: 9.709e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16360, Loss: 9.827e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16370, Loss: 9.413e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 16380, Loss: 9.498e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 16390, Loss: 1.044e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 16400, Loss: 9.789e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 16410, Loss: 1.009e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16420, Loss: 9.662e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16430, Loss: 9.821e+00, Y0: 77.104, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16440, Loss: 8.847e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16450, Loss: 9.893e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16460, Loss: 9.921e+00, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16470, Loss: 1.001e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16480, Loss: 1.030e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16490, Loss: 1.048e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 16500, Loss: 9.984e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16510, Loss: 1.029e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 16520, Loss: 9.453e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16530, Loss: 1.008e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16540, Loss: 1.047e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16550, Loss: 1.142e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16560, Loss: 9.759e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 16570, Loss: 9.628e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 16580, Loss: 1.078e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 16590, Loss: 1.044e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16600, Loss: 9.995e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16610, Loss: 9.478e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16620, Loss: 1.053e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16630, Loss: 1.262e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 16640, Loss: 9.977e+00, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16650, Loss: 9.703e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 16660, Loss: 1.065e+01, Y0: 77.028, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16670, Loss: 1.093e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16680, Loss: 9.749e+00, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16690, Loss: 1.031e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16700, Loss: 1.048e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16710, Loss: 1.074e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16720, Loss: 9.127e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16730, Loss: 1.037e+01, Y0: 77.110, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16740, Loss: 9.991e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 16750, Loss: 9.303e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 16760, Loss: 9.879e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 16770, Loss: 1.021e+01, Y0: 77.040, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16780, Loss: 9.694e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16790, Loss: 1.127e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16800, Loss: 9.850e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16810, Loss: 1.018e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16820, Loss: 9.819e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16830, Loss: 9.225e+00, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16840, Loss: 1.037e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16850, Loss: 1.046e+01, Y0: 77.164, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16860, Loss: 9.198e+00, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16870, Loss: 1.012e+01, Y0: 77.024, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16880, Loss: 9.303e+00, Y0: 77.034, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 16890, Loss: 9.846e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16900, Loss: 9.998e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16910, Loss: 1.082e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16920, Loss: 1.055e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16930, Loss: 8.748e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.84s\n",
      "Epoch: 16940, Loss: 1.016e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 16950, Loss: 9.905e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 16960, Loss: 1.021e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 16970, Loss: 9.546e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 16980, Loss: 1.023e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 16990, Loss: 1.000e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17000, Loss: 1.024e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17010, Loss: 9.282e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17020, Loss: 9.656e+00, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17030, Loss: 9.433e+00, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17040, Loss: 9.589e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17050, Loss: 9.772e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17060, Loss: 1.095e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17070, Loss: 9.450e+00, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17080, Loss: 9.933e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17090, Loss: 9.996e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17100, Loss: 1.012e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 17110, Loss: 1.031e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.77s\n",
      "Epoch: 17120, Loss: 9.338e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 17130, Loss: 1.022e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 17140, Loss: 9.890e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17150, Loss: 1.095e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17160, Loss: 1.032e+01, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17170, Loss: 1.073e+01, Y0: 77.046, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17180, Loss: 1.137e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17190, Loss: 1.087e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17200, Loss: 1.032e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17210, Loss: 1.001e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 17220, Loss: 1.156e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17230, Loss: 1.110e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17240, Loss: 1.050e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17250, Loss: 9.402e+00, Y0: 77.022, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17260, Loss: 9.663e+00, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17270, Loss: 1.048e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17280, Loss: 1.046e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17290, Loss: 1.057e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17300, Loss: 1.145e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 17310, Loss: 8.888e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 17320, Loss: 1.084e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17330, Loss: 1.000e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17340, Loss: 1.167e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17350, Loss: 8.992e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17360, Loss: 1.029e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17370, Loss: 9.929e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17380, Loss: 1.075e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17390, Loss: 9.999e+00, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17400, Loss: 9.553e+00, Y0: 77.044, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17410, Loss: 1.122e+01, Y0: 77.041, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17420, Loss: 1.015e+01, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17430, Loss: 1.080e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 17440, Loss: 1.140e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17450, Loss: 1.150e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17460, Loss: 1.108e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17470, Loss: 1.015e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17480, Loss: 1.022e+01, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 17490, Loss: 9.805e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 17500, Loss: 1.029e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 17510, Loss: 1.055e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17520, Loss: 9.825e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17530, Loss: 9.845e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17540, Loss: 1.006e+01, Y0: 77.031, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17550, Loss: 1.103e+01, Y0: 77.058, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17560, Loss: 8.844e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17570, Loss: 9.673e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17580, Loss: 1.076e+01, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17590, Loss: 9.333e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17600, Loss: 1.185e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17610, Loss: 9.209e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17620, Loss: 1.215e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17630, Loss: 9.458e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17640, Loss: 1.081e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17650, Loss: 9.580e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17660, Loss: 9.723e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 17670, Loss: 1.113e+01, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 17680, Loss: 1.051e+01, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 17690, Loss: 1.025e+01, Y0: 77.099, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17700, Loss: 9.519e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17710, Loss: 1.134e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17720, Loss: 9.053e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17730, Loss: 9.473e+00, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17740, Loss: 1.061e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17750, Loss: 9.360e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17760, Loss: 9.970e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17770, Loss: 1.037e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17780, Loss: 9.759e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17790, Loss: 9.279e+00, Y0: 77.045, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17800, Loss: 1.036e+01, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17810, Loss: 9.765e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17820, Loss: 1.019e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 17830, Loss: 1.013e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17840, Loss: 9.523e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17850, Loss: 1.095e+01, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.79s\n",
      "Epoch: 17860, Loss: 1.024e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 17870, Loss: 9.592e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.66s\n",
      "Epoch: 17880, Loss: 1.009e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17890, Loss: 9.458e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17900, Loss: 1.004e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17910, Loss: 1.967e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17920, Loss: 1.101e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17930, Loss: 1.081e+01, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17940, Loss: 9.604e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17950, Loss: 1.031e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 17960, Loss: 9.515e+00, Y0: 77.029, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 17970, Loss: 9.276e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 17980, Loss: 1.116e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 17990, Loss: 9.476e+00, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18000, Loss: 9.789e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 18010, Loss: 9.533e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18020, Loss: 1.090e+01, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18030, Loss: 9.763e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.67s\n",
      "Epoch: 18040, Loss: 1.009e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 18050, Loss: 9.112e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 18060, Loss: 1.100e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 18070, Loss: 1.351e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18080, Loss: 1.042e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.56s\n",
      "Epoch: 18090, Loss: 9.522e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18100, Loss: 1.020e+01, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18110, Loss: 1.110e+01, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18120, Loss: 9.482e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18130, Loss: 1.116e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18140, Loss: 9.498e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18150, Loss: 9.929e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18160, Loss: 1.014e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18170, Loss: 9.975e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18180, Loss: 1.072e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18190, Loss: 1.119e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18200, Loss: 1.057e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18210, Loss: 9.202e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18220, Loss: 9.506e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.78s\n",
      "Epoch: 18230, Loss: 9.475e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 18240, Loss: 1.092e+01, Y0: 77.091, Learning Rate: 1.000e-06, Time: 0.68s\n",
      "Epoch: 18250, Loss: 9.361e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18260, Loss: 1.062e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18270, Loss: 9.623e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18280, Loss: 1.230e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18290, Loss: 1.103e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18300, Loss: 1.061e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18310, Loss: 1.131e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18320, Loss: 9.735e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18330, Loss: 1.026e+01, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18340, Loss: 9.978e+00, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18350, Loss: 9.601e+00, Y0: 77.106, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18360, Loss: 1.092e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18370, Loss: 9.315e+00, Y0: 77.061, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 18380, Loss: 1.163e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18390, Loss: 1.010e+01, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 18400, Loss: 9.691e+00, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.70s\n",
      "Epoch: 18410, Loss: 1.013e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 18420, Loss: 1.013e+01, Y0: 77.090, Learning Rate: 1.000e-06, Time: 0.80s\n",
      "Epoch: 18430, Loss: 1.038e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18440, Loss: 9.076e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18450, Loss: 9.650e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18460, Loss: 9.627e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18470, Loss: 9.483e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18480, Loss: 1.030e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18490, Loss: 1.065e+01, Y0: 77.103, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18500, Loss: 9.881e+00, Y0: 77.112, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 18510, Loss: 1.158e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18520, Loss: 9.673e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 18530, Loss: 1.024e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18540, Loss: 1.020e+01, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18550, Loss: 1.008e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18560, Loss: 1.015e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18570, Loss: 9.124e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 18580, Loss: 1.087e+01, Y0: 77.054, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18590, Loss: 9.306e+00, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 18600, Loss: 1.035e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 18610, Loss: 9.543e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18620, Loss: 9.732e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18630, Loss: 1.049e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18640, Loss: 1.026e+01, Y0: 77.059, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18650, Loss: 1.060e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18660, Loss: 1.002e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18670, Loss: 9.526e+00, Y0: 77.055, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18680, Loss: 9.877e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18690, Loss: 9.843e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18700, Loss: 9.350e+00, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 18710, Loss: 1.058e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18720, Loss: 9.197e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18730, Loss: 1.043e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18740, Loss: 9.682e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18750, Loss: 1.040e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18760, Loss: 9.687e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18770, Loss: 1.019e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.76s\n",
      "Epoch: 18780, Loss: 1.031e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 18790, Loss: 9.345e+00, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.72s\n",
      "Epoch: 18800, Loss: 9.775e+00, Y0: 77.063, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18810, Loss: 9.319e+00, Y0: 77.018, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18820, Loss: 9.999e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18830, Loss: 1.144e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18840, Loss: 1.071e+01, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18850, Loss: 9.667e+00, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18860, Loss: 9.519e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 18870, Loss: 1.068e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18880, Loss: 9.108e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18890, Loss: 9.807e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18900, Loss: 9.632e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 18910, Loss: 8.915e+00, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18920, Loss: 1.076e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18930, Loss: 9.800e+00, Y0: 77.098, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 18940, Loss: 9.534e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18950, Loss: 1.042e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 18960, Loss: 1.041e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.81s\n",
      "Epoch: 18970, Loss: 9.738e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 18980, Loss: 1.063e+01, Y0: 77.095, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 18990, Loss: 1.089e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.63s\n",
      "Epoch: 19000, Loss: 1.001e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19010, Loss: 1.027e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19020, Loss: 9.455e+00, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19030, Loss: 1.002e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19040, Loss: 1.014e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 19050, Loss: 1.062e+01, Y0: 77.094, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19060, Loss: 9.893e+00, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19070, Loss: 9.223e+00, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19080, Loss: 1.145e+01, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19090, Loss: 1.042e+01, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19100, Loss: 9.235e+00, Y0: 77.114, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19110, Loss: 1.025e+01, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19120, Loss: 1.128e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19130, Loss: 1.045e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19140, Loss: 1.004e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 19150, Loss: 9.697e+00, Y0: 77.081, Learning Rate: 1.000e-06, Time: 0.86s\n",
      "Epoch: 19160, Loss: 1.071e+01, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.65s\n",
      "Epoch: 19170, Loss: 1.022e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19180, Loss: 8.781e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19190, Loss: 1.086e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19200, Loss: 1.106e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19210, Loss: 1.003e+01, Y0: 77.065, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19220, Loss: 1.093e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19230, Loss: 9.022e+00, Y0: 77.112, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19240, Loss: 9.028e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 19250, Loss: 1.027e+01, Y0: 77.048, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19260, Loss: 9.247e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19270, Loss: 9.944e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19280, Loss: 8.546e+00, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19290, Loss: 9.862e+00, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19300, Loss: 9.709e+00, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19310, Loss: 1.065e+01, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 19320, Loss: 9.993e+00, Y0: 77.092, Learning Rate: 1.000e-06, Time: 0.71s\n",
      "Epoch: 19330, Loss: 1.003e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.82s\n",
      "Epoch: 19340, Loss: 1.115e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.78s\n",
      "Epoch: 19350, Loss: 9.626e+00, Y0: 77.086, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19360, Loss: 9.867e+00, Y0: 77.082, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19370, Loss: 9.697e+00, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19380, Loss: 1.039e+01, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19390, Loss: 1.110e+01, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19400, Loss: 9.761e+00, Y0: 77.111, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19410, Loss: 9.905e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19420, Loss: 8.515e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19430, Loss: 1.041e+01, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19440, Loss: 1.002e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19450, Loss: 9.911e+00, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19460, Loss: 1.104e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 19470, Loss: 8.989e+00, Y0: 77.050, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19480, Loss: 1.023e+01, Y0: 77.018, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19490, Loss: 9.895e+00, Y0: 77.075, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19500, Loss: 9.531e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19510, Loss: 9.620e+00, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.85s\n",
      "Epoch: 19520, Loss: 1.060e+01, Y0: 77.096, Learning Rate: 1.000e-06, Time: 0.87s\n",
      "Epoch: 19530, Loss: 1.024e+01, Y0: 77.093, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19540, Loss: 1.055e+01, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19550, Loss: 1.036e+01, Y0: 77.060, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19560, Loss: 1.082e+01, Y0: 77.080, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19570, Loss: 9.904e+00, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19580, Loss: 9.232e+00, Y0: 77.062, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19590, Loss: 9.522e+00, Y0: 77.064, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19600, Loss: 9.936e+00, Y0: 77.049, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19610, Loss: 9.499e+00, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19620, Loss: 1.093e+01, Y0: 77.078, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19630, Loss: 9.938e+00, Y0: 77.071, Learning Rate: 1.000e-06, Time: 0.62s\n",
      "Epoch: 19640, Loss: 9.717e+00, Y0: 77.036, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19650, Loss: 1.407e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19660, Loss: 8.993e+00, Y0: 77.088, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19670, Loss: 1.039e+01, Y0: 77.053, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19680, Loss: 9.514e+00, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19690, Loss: 1.009e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.73s\n",
      "Epoch: 19700, Loss: 9.403e+00, Y0: 77.052, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 19710, Loss: 9.813e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.74s\n",
      "Epoch: 19720, Loss: 9.658e+00, Y0: 77.105, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19730, Loss: 9.555e+00, Y0: 77.087, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19740, Loss: 1.044e+01, Y0: 77.066, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19750, Loss: 1.028e+01, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19760, Loss: 1.090e+01, Y0: 77.069, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19770, Loss: 1.006e+01, Y0: 77.113, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19780, Loss: 1.069e+01, Y0: 77.097, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19790, Loss: 1.113e+01, Y0: 77.102, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19800, Loss: 9.294e+00, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19810, Loss: 9.958e+00, Y0: 77.076, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19820, Loss: 1.030e+01, Y0: 77.089, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19830, Loss: 1.030e+01, Y0: 77.068, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19840, Loss: 9.849e+00, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19850, Loss: 1.066e+01, Y0: 77.077, Learning Rate: 1.000e-06, Time: 0.57s\n",
      "Epoch: 19860, Loss: 1.049e+01, Y0: 77.079, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19870, Loss: 1.355e+01, Y0: 77.108, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19880, Loss: 9.711e+00, Y0: 77.067, Learning Rate: 1.000e-06, Time: 0.83s\n",
      "Epoch: 19890, Loss: 9.562e+00, Y0: 77.039, Learning Rate: 1.000e-06, Time: 0.89s\n",
      "Epoch: 19900, Loss: 1.068e+01, Y0: 77.074, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19910, Loss: 9.415e+00, Y0: 77.101, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19920, Loss: 9.927e+00, Y0: 77.072, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19930, Loss: 1.039e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.61s\n",
      "Epoch: 19940, Loss: 1.061e+01, Y0: 77.085, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19950, Loss: 9.677e+00, Y0: 77.073, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19960, Loss: 1.030e+01, Y0: 77.083, Learning Rate: 1.000e-06, Time: 0.58s\n",
      "Epoch: 19970, Loss: 1.129e+01, Y0: 77.070, Learning Rate: 1.000e-06, Time: 0.60s\n",
      "Epoch: 19980, Loss: 1.041e+01, Y0: 77.056, Learning Rate: 1.000e-06, Time: 0.59s\n",
      "Epoch: 19990, Loss: 1.106e+01, Y0: 77.084, Learning Rate: 1.000e-06, Time: 0.58s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow.compat.v1 as tf \n",
    "#from FBSDENN import FBSNN\n",
    "import matplotlib.pyplot as plt \n",
    "#from plotting import newfig, savefig\n",
    "\n",
    "class BSBNN(FBSNN):\n",
    "    def __init__(self, Xi, T, M, N, D, layers):\n",
    "        super().__init__(Xi, T, M, N, D, layers)\n",
    "    \n",
    "    # IMPLEMENTAZIONE DEL GENERATORE (PHI):\n",
    "    # Definisce la dinamica dell'equazione Backward (o il termine non lineare della PDE).\n",
    "    # Per il problema Black-Scholes-Barenblatt (o simile in 100D), questa funzione definisce\n",
    "    # la relazione tra la soluzione Y, il suo gradiente Z e lo stocastico.\n",
    "    # Formula codice: 0.05 * (Y - X*Z)\n",
    "    # Nota: NON chiamiamo super() perche' nella classe base FBSNN questo metodo e' vuoto (pass).\n",
    "    # Dobbiamo fornire noi l'implementazione specifica per questo problema.\n",
    "    def phi_tf(self, t, X, Y, Z):\n",
    "        return 0.05 * (Y - tf.reduce_sum(X*Z, 1, keepdims=True))\n",
    "    \n",
    "    # IMPLEMENTAZIONE DELLA CONDIZIONE TERMINALE (G):\n",
    "    # Definisce il valore della soluzione al tempo finale T.\n",
    "    # Y_T = g(X_T) = sum(X^2)\n",
    "    # Anche qui NON usiamo super() perche' nella base e' vuoto.\n",
    "    def g_tf(self, X):\n",
    "        return tf.reduce_sum(X**2, 1, keepdims=True)\n",
    "\n",
    "    # IMPLEMENTAZIONE DEL DRIFT FORWARD (MU):\n",
    "    # Definisce il drift del processo X (prezzo dell'asset).\n",
    "    # PERCHÉ USIAMO SUPER():\n",
    "    # Nella classe genitore `FBSNN`, il metodo `mu_tf` ha già un'implementazione di default\n",
    "    # che restituisce zero (np.zeros).\n",
    "    # In questo specifico problema, assumiamo che il drift di X sia nullo (o assorbito dalla misura).\n",
    "    # Quindi, invece di riscrivere \"return np.zeros(...)\", riutilizziamo comodamente il codice\n",
    "    # già scritto nel genitore. È un esempio di \"ereditarietà\" per evitare duplicazione di codice.\n",
    "    def mu_tf(self, t, X, Y, Z):\n",
    "        return super().mu_tf(t, X, Y, Z)\n",
    "    \n",
    "    # IMPLEMENTAZIONE DELLA DIFFUSIONE FORWARD (SIGMA):\n",
    "    # Definisce la volatilità del processo X.\n",
    "    # Qui NON usiamo super() perché il default nel genitore è la matrice identità (1.0).\n",
    "    # Il nostro problema richiede una volatilità specifica: sigma = 0.4 * X.\n",
    "    # Dobbiamo quindi \"sovrascrivere\" (override) il comportamento base con la nostra formula.\n",
    "    def sigma_tf(self, t, X, Y):\n",
    "        return 0.4*tf.matrix_diag(X)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    M = 100 # numero di traiettorie (batch size)\n",
    "    N = 50 # numero di step temporali\n",
    "    D = 100 # numero delle dimensioni\n",
    "\n",
    "    layers = [D+1] + 4*[256] + [1]\n",
    "    \n",
    "    Xi = np.array([1.0,0.5]*int(D/2))[None, :]\n",
    "\n",
    "    T = 1.0\n",
    "\n",
    "    model = BSBNN(Xi, T, M, N, D, layers)\n",
    "\n",
    "    model.train(epochs=2*10**4, learning_rate=1e-3)\n",
    "    model.train(epochs=3*10**4, learning_rate=1e-4)\n",
    "    model.train(epochs=3*10**4, learning_rate=1e-5)\n",
    "    model.train(epochs=2*10**4, learning_rate=1e-6)\n",
    "\n",
    "    # Plot dei risultati\n",
    "\n",
    "    t_test, W_test = model.fetch_minibatch()\n",
    "\n",
    "    X_pred, Y_pred = model.predict(Xi, t_test, W_test)\n",
    "\n",
    "    def u_exact(t, X):\n",
    "        r = 0.05\n",
    "        sigma_max = 0.4\n",
    "        return np.exp((r+sigma_max**2)*(T-t))*np.sum(X**2, 1, keepdims=True)\n",
    "\n",
    "    Y_test = np.reshape(u_exact(np.reshape(t_test[0:M, :, :], [-1, 1]), np.reshape(X_pred[0:M, :, :], [-1, D])), [M, N+1, 1])\n",
    "    \n",
    "    samples = 5\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t_test[0:1,:,0].T,Y_pred[0:1,:,0].T,'b',label='Learned $u(t,X_t)$')\n",
    "    plt.plot(t_test[0:1,:,0].T,Y_test[0:1,:,0].T,'r--',label='Exact $u(t,X_t)$')\n",
    "    plt.plot(t_test[0:1,-1,0],Y_test[0:1,-1,0],'ko',label='$Y_T = u(T,X_T)$')\n",
    "    \n",
    "    plt.plot(t_test[1:samples,:,0].T,Y_pred[1:samples,:,0].T,'b')\n",
    "    plt.plot(t_test[1:samples,:,0].T,Y_test[1:samples,:,0].T,'r--')\n",
    "    plt.plot(t_test[1:samples,-1,0],Y_test[1:samples,-1,0],'ko')\n",
    "\n",
    "    plt.plot([0],Y_test[0,0,0],'ks',label='$Y_0 = u(0,X_0)$')\n",
    "    \n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$Y_t = u(t,X_t)$')\n",
    "    plt.title('100-dimensional Black-Scholes-Barenblatt')\n",
    "    plt.legend()\n",
    "    \n",
    "    # savefig('./figures/BSB_Apr18_50', crop = False)\n",
    "    \n",
    "    \n",
    "    errors = np.sqrt((Y_test-Y_pred)**2/Y_test**2)\n",
    "    mean_errors = np.mean(errors,0)\n",
    "    std_errors = np.std(errors,0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(t_test[0,:,0],mean_errors,'b',label='mean')\n",
    "    plt.plot(t_test[0,:,0],mean_errors+2*std_errors,'r--',label='mean + two standard deviations')\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('relative error')\n",
    "    plt.title('100-dimensional Black-Scholes-Barenblatt')\n",
    "    plt.legend()\n",
    "    \n",
    "    # savefig('./figures/BSB_Apr18_50_errors', crop = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be135261",
   "metadata": {},
   "source": [
    "## Problema da risolvere:\n",
    "Vogliamo implementare l'utilizzo della rete neurale appena testa per risolvere il sistema\n",
    "di equazioni FBSDE del tipo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14397787",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "dV_t=b(t,V_t,X_{t},Z_t)dt+\\sigma(t,V_t,X_{t})dW_t,\\\\\n",
    "dX_t=V_tdt,\\\\\n",
    "dY_t=f(t,V_t,X_{t},Z_t)dt+Z_tdW_t,\\\\\n",
    "(V_0,X_{0})=(v_{0},x_{0}),\\quad Y_T=g(V_t,X_{t}).\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from FBSDENN import FBSNN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================================================================\n",
    "# CLASSE MODELLO: LANGEVIN INERZIALE 100D\n",
    "# ==============================================================================\n",
    "class LangevinNN(FBSNN):\n",
    "    def __init__(self, Xi, T, M, N, D, layers, dim_phys):\n",
    "        self.dim_phys = dim_phys # Dimensione fisica (es. 50 particelle)\n",
    "        self.sigma_val = 1.0     # Diffusione costante\n",
    "        super().__init__(Xi, T, M, N, D, layers)\n",
    "\n",
    "    # IMPLEMENTAZIONE DEL GENERATORE (PHI):\n",
    "    # Derivato dalla soluzione esatta u(t,V,X) = exp(-t) * (|X|^2 + |V|^2)\n",
    "    # Formula teorica: f = e^-t * [ d*sigma^2 - |V|^2 + 2(X*V) - (|X|^2 + |V|^2) ]\n",
    "    def phi_tf(self, t, Xi, Y, Z):\n",
    "        # 1. Split dello stato Xi in Velocità (V) e Posizione (X)\n",
    "        V, X = tf.split(Xi, num_or_size_splits=2, axis=1)\n",
    "        \n",
    "        # 2. Calcolo termini\n",
    "        d = tf.cast(self.dim_phys, tf.float32)\n",
    "        sigma2 = self.sigma_val ** 2\n",
    "        \n",
    "        sum_X2 = tf.reduce_sum(tf.square(X), 1, keepdims=True)\n",
    "        sum_V2 = tf.reduce_sum(tf.square(V), 1, keepdims=True)\n",
    "        sum_XV = tf.reduce_sum(X * V, 1, keepdims=True)\n",
    "        \n",
    "        exp_t = tf.exp(-t)\n",
    "        \n",
    "        # 3. Composizione formula\n",
    "        term_trace = d * sigma2\n",
    "        term_kinetic = -sum_V2    # Da drift b = -0.5*V\n",
    "        term_cross = 2.0 * sum_XV # Da dX = V dt\n",
    "        term_decay = -(sum_X2 + sum_V2) # Da dt (e^-t)\n",
    "        \n",
    "        return exp_t * (term_trace + term_kinetic + term_cross + term_decay)\n",
    "\n",
    "    # IMPLEMENTAZIONE DELLA CONDIZIONE TERMINALE (G):\n",
    "    # Y_T = g(V_T, X_T) = exp(-T) * (|X|^2 + |V|^2)\n",
    "    def g_tf(self, Xi):\n",
    "        V, X = tf.split(Xi, num_or_size_splits=2, axis=1)\n",
    "        sum_X2 = tf.reduce_sum(tf.square(X), 1, keepdims=True)\n",
    "        sum_V2 = tf.reduce_sum(tf.square(V), 1, keepdims=True)\n",
    "        return tf.exp(-self.T) * (sum_X2 + sum_V2)\n",
    "\n",
    "    # IMPLEMENTAZIONE DEL DRIFT FORWARD (MU):\n",
    "    # Sistema accoppiato:\n",
    "    # dV = -0.5 * V dt\n",
    "    # dX = V dt\n",
    "    def mu_tf(self, t, Xi, Y, Z):\n",
    "        V, X = tf.split(Xi, num_or_size_splits=2, axis=1)\n",
    "        # Concateniamo i drift per formare il vettore mu totale [M, 2d]\n",
    "        return tf.concat([-0.5 * V, V], axis=1)\n",
    "\n",
    "    # IMPLEMENTAZIONE DELLA DIFFUSIONE FORWARD (SIGMA):\n",
    "    # dV ha rumore (sigma), dX non ha rumore (0).\n",
    "    # Matrice a blocchi [[Sigma*I, 0], [0, 0]]\n",
    "    def sigma_tf(self, t, Xi, Y):\n",
    "        M = self.M\n",
    "        d = self.dim_phys\n",
    "        \n",
    "        # Matrice identità scalata per V [M, d, d]\n",
    "        sigma_matrix = self.sigma_val * tf.eye(d, batch_shape=[M])\n",
    "        zeros_matrix = tf.zeros([M, d, d])\n",
    "        \n",
    "        # Costruzione blocchi\n",
    "        row1 = tf.concat([sigma_matrix, zeros_matrix], axis=2)\n",
    "        row2 = tf.concat([zeros_matrix, zeros_matrix], axis=2)\n",
    "        \n",
    "        return tf.concat([row1, row2], axis=1)\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN BLOCK & PLOTTING\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Configurazione Parametri\n",
    "    M = 100         # Numero di traiettorie (batch size)\n",
    "    N = 50          # Numero di step temporali\n",
    "    dim_phys = 50   # Dimensione fisica (50 particelle)\n",
    "    D = 2 * dim_phys # Dimensione totale (100: 50 vel + 50 pos)\n",
    "    T = 1.0\n",
    "\n",
    "    # Architettura: Input(101) -> 4x256 -> Output(1)\n",
    "    layers = [D+1] + 4*[256] + [1]\n",
    "    \n",
    "    # Inizializzazione Xi: [V0... , X0...]\n",
    "    # Usiamo 0.5 per tutto come esempio\n",
    "    Xi = np.ones((1, D)) * 0.5\n",
    "\n",
    "    # Istanziazione Modello\n",
    "    # Nota: passiamo dim_phys al costruttore personalizzato\n",
    "    model = LangevinNN(Xi, T, M, N, D, layers, dim_phys)\n",
    "\n",
    "    # 2. Addestramento (Learning Rate Schedule come nel paper)\n",
    "    print(\"Inizio Training...\")\n",
    "    model.train(epochs=2*10**4, learning_rate=1e-3) # Fase aggressiva\n",
    "    model.train(epochs=3*10**4, learning_rate=1e-4) # Fase raffinamento\n",
    "    model.train(epochs=3*10**4, learning_rate=1e-5) # Fase precisione\n",
    "    model.train(epochs=2*10**4, learning_rate=1e-6) # Fase finale\n",
    "\n",
    "    # 3. Plot dei risultati\n",
    "    \n",
    "    # Generiamo un batch di test (traiettorie nuove mai viste)\n",
    "    t_test, W_test = model.fetch_minibatch()\n",
    "    \n",
    "    # Previsione della rete neurale\n",
    "    X_pred, Y_pred = model.predict(Xi, t_test, W_test)\n",
    "\n",
    "    # Definizione della Soluzione Esatta per confronto\n",
    "    # u(t, V, X) = exp(-t) * sum(X^2 + V^2)\n",
    "    def u_exact(t, Xi_combined):\n",
    "        # Xi_combined è [M, D] -> Splittiamo in numpy\n",
    "        V = Xi_combined[:, :dim_phys]\n",
    "        X = Xi_combined[:, dim_phys:]\n",
    "        return np.exp(-t) * np.sum(X**2 + V**2, axis=1, keepdims=True)\n",
    "\n",
    "    # Calcolo della Y esatta lungo le traiettorie predette (X_pred)\n",
    "    # Reshape necessario per applicare la funzione su tutti i tempi appiattiti\n",
    "    Y_test = np.reshape(\n",
    "        u_exact(\n",
    "            np.reshape(t_test[0:M, :, :], [-1, 1]), \n",
    "            np.reshape(X_pred[0:M, :, :], [-1, D])\n",
    "        ), \n",
    "        [M, N+1, 1]\n",
    "    )\n",
    "    \n",
    "    # --- GRAFICO 1: Traiettorie ---\n",
    "    samples = 5 # Numero di traiettorie da plottare\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot prima traiettoria con etichette\n",
    "    plt.plot(t_test[0:1,:,0].T, Y_pred[0:1,:,0].T, 'b', label='Learned $u(t,V_t, X_t)$')\n",
    "    plt.plot(t_test[0:1,:,0].T, Y_test[0:1,:,0].T, 'r--', label='Exact $u(t,V_t, X_t)$')\n",
    "    plt.plot(t_test[0:1,-1,0], Y_test[0:1,-1,0], 'ko', label='$Y_T = u(T,X_T)$')\n",
    "    \n",
    "    # Plot altre traiettorie (senza etichette per pulizia)\n",
    "    plt.plot(t_test[1:samples,:,0].T, Y_pred[1:samples,:,0].T, 'b')\n",
    "    plt.plot(t_test[1:samples,:,0].T, Y_test[1:samples,:,0].T, 'r--')\n",
    "    plt.plot(t_test[1:samples,-1,0], Y_test[1:samples,-1,0], 'ko')\n",
    "\n",
    "    # Punto iniziale\n",
    "    plt.plot([0], Y_test[0,0,0], 'ks', label='$Y_0 = u(0,X_0)$')\n",
    "    \n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$Y_t$ (Total Energy)')\n",
    "    plt.title('100-dimensional Inertial Langevin System')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- GRAFICO 2: Errore Relativo ---\n",
    "    # Calcolo errore relativo punto per punto\n",
    "    errors = np.sqrt((Y_test - Y_pred)**2 / Y_test**2)\n",
    "    \n",
    "    # Statistiche sull'errore lungo il batch\n",
    "    mean_errors = np.mean(errors, 0)\n",
    "    std_errors = np.std(errors, 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(t_test[0,:,0], mean_errors, 'b', label='mean error')\n",
    "    plt.plot(t_test[0,:,0], mean_errors + 2*std_errors, 'r--', label='mean + 2 std deviations')\n",
    "    \n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('Relative Error')\n",
    "    plt.title('Error Analysis - 100D Langevin')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mostra i grafici\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62460b43",
   "metadata": {},
   "source": [
    "# Analisi dei Risultati: Sistema Langevin Inerziale in Alta Dimensionalità (100D)\n",
    "\n",
    "In questa sezione analizziamo le performance della rete neurale **FBSNN (Forward-Backward Stochastic Neural Network)** applicata alla risoluzione di un sistema stocastico accoppiato di tipo Langevin in $\\mathbb{R}^{100}$.\n",
    "\n",
    "### 1. Definizione del Problema\n",
    "Il sistema dinamico è modellato da un'equazione differenziale stocastica (SDE) accoppiata, dove lo stato è composto da **Posizione ($X_t$)** e **Velocità ($V_t$)**. Il problema è definito in **100 dimensioni** totali ($d_{phys}=50$ particelle, quindi $50$ posizioni + $50$ velocità).\n",
    "\n",
    "Il sistema Forward è governato dalle seguenti leggi del moto:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "dX_t = V_t dt \\\\\n",
    "dV_t = -\\frac{1}{2}V_t dt + \\sigma dW_t\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "L'obiettivo è apprendere la funzione soluzione $u(t, V, X)$ che rappresenta l'energia totale del sistema dissipata nel tempo. Per validare il modello, utilizziamo una **soluzione manifatturata** (Manufactured Solution) nota a priori:\n",
    "\n",
    "$$u(t, V, X) = e^{-t} \\sum_{i=1}^{50} (X_i^2 + V_i^2)$$\n",
    "\n",
    "### 2. Metodologia di Training\n",
    "La rete neurale apprende la soluzione minimizzando il residuo dell'equazione Backward associata (BSDE) e il mismatch con la condizione terminale $g(X_T, V_T)$.\n",
    "* **Architettura:** Rete Feed-Forward (Input 101 $\\to$ 4x256 $\\to$ Output 1).\n",
    "* **Strategia di Learning Rate:** Decadimento a step ($10^{-3} \\to 10^{-6}$) per raffinare progressivamente la convergenza.\n",
    "* **Batch Size:** $M=100$ traiettorie stocastiche.\n",
    "\n",
    "### 3. Discussione dei Risultati Grafici\n",
    "\n",
    "I grafici ottenuti mostrano un'eccellente capacità del modello di approssimare la soluzione in un regime ad alta dimensionalità, dove i metodi numerici classici (es. Differenze Finite) soffrirebbero della *Curse of Dimensionality*.\n",
    "\n",
    "* **Tracking delle Traiettorie ($Y_t$ vs Tempo):**\n",
    "    Il grafico delle traiettorie mostra che la soluzione appresa (linea blu continua) segue fedelmente la soluzione esatta analitica (linea rossa tratteggiata) lungo l'intera evoluzione temporale $t \\in [0, 1]$.\n",
    "    * **Punto Iniziale:** Tutte le traiettorie convergono correttamente al valore atteso $Y_0 = 25.0$. Dato che l'inizializzazione è $x_i=v_i=0.5$ per 100 dimensioni: $100 \\times (0.5)^2 = 25$.\n",
    "    * **Dinamica Stocastica:** La rete cattura correttamente le fluttuazioni indotte dal termine di diffusione $\\sigma dW_t$, dimostrando di aver appreso la relazione causale tra le variabili di stato e l'energia.\n",
    "\n",
    "* **Analisi dell'Errore Relativo:**\n",
    "    L'errore relativo medio (curva blu nel grafico degli errori) si mantiene limitato, con un picco massimo intorno al **3.3%** ($3.3 \\times 10^{-2}$) nella fase centrale della simulazione.\n",
    "    * Il profilo dell'errore assume la caratteristica forma a \"ponte\": l'errore è minimo agli estremi $t=0$ e $t=T$ (dove i vincoli sono più forti) e si accumula moderatamente nel mezzo.\n",
    "    * Considerando la complessità del dominio a 100 dimensioni, un errore percentuale di questa entità conferma la robustezza dell'approccio Deep Learning per questo tipo di PDE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
