{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b033a6",
   "metadata": {},
   "source": [
    "### Sistema Fully Coupled (Girsanov)\n",
    "$$\n",
    "\\begin{cases}\n",
    "dS_t =\\mu(c-S_t)dt + \\sigma_1dW^1_t\\\\\n",
    "\n",
    "dH_t = \\mu(c-H_t)dt + \\sigma_2 dW^2_t\\\\\n",
    "\n",
    "dV_t = a(X_t^2 + bH_t + c (e^{t} \\mathrm{const}\\, Z_t^3\\sigma_3^{-1} - X_t)/2)dt + \\sigma_3 dW^3_t\\\\\n",
    "\n",
    "dX_t = V_t dt\n",
    "\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ed563",
   "metadata": {},
   "source": [
    "### Soluzione\n",
    "$$\n",
    "    u(t,s,h,v,x) = e^{-t}(e^s + e^{s}h + v^2 + xv)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2f3ec",
   "metadata": {},
   "source": [
    "### Equazione backward\n",
    "$$\n",
    "\n",
    " dY_t = -(Y_t - e^{-t}( (1+H_t)\\mu(c-S_t)S_t + \\mu(c-H_t)S_t + (2V_t+X_t)a(X_t^2+bH_t+cV_t) +V_t^2 +\\sigma_3^2 ) + e^{t} Z_t^3\\sigma_3^{-1} a c(\\mathrm{const} - 1) Z_t^3\\sigma_3^{-1} / 2)dt + Z_t dW_t\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6148509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.12/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "## Rete neurale con normalizzazione della loss\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class FBSNN(ABC): # Forward-Backward Stochastic Neural Network\n",
    "    def __init__(self, Xi, T,\n",
    "                       M, N, D,\n",
    "                       layers):\n",
    "\n",
    "        self.Xi = Xi # initial point\n",
    "        self.T = T # terminal time\n",
    "\n",
    "        self.M = M # number of trajectories\n",
    "        self.N = N # number of time snapshots\n",
    "        self.D = D # number of dimensions\n",
    "\n",
    "        # layers\n",
    "        self.layers = layers # (D+1) --> 1\n",
    "\n",
    "        # initialize NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "\n",
    "        # tf session\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "\n",
    "        # tf placeholders and graph (training)\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[M, self.N+1, 1]) # M x (N+1) x 1\n",
    "        self.W_tf = tf.placeholder(tf.float32, shape=[M, self.N+1, self.D]) # M x (N+1) x D\n",
    "        self.Xi_tf = tf.placeholder(tf.float32, shape=[1, D]) # 1 x D\n",
    "        self.const_tf = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        self.loss, self.X_pred, self.Y_pred, self.Y0_pred, self.Z_pred = self.loss_function(self.t_tf, self.W_tf, self.Xi_tf)\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "        # initialize session and variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim],\n",
    "                                               stddev=xavier_stddev), dtype=tf.float32)\n",
    "\n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "\n",
    "        H = X\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.sin(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, t, X): # M x 1, M x D\n",
    "\n",
    "        u = self.neural_net(tf.concat([t,X], 1), self.weights, self.biases) # M x 1\n",
    "        Du = tf.gradients(u, X)[0] # M x D\n",
    "\n",
    "        return u, Du\n",
    "\n",
    "    def Dg_tf(self, X): # M x D\n",
    "        return tf.gradients(self.g_tf(X), X)[0] # M x D\n",
    "\n",
    "    def loss_function(self, t, W, Xi): # M x (N+1) x 1, M x (N+1) x D, 1 x D\n",
    "        loss = 0\n",
    "        X_list = []\n",
    "        Y_list = []\n",
    "        Z_list = []\n",
    "\n",
    "        t0 = t[:,0,:]\n",
    "        W0 = W[:,0,:]\n",
    "        X0 = tf.tile(Xi,[self.M,1]) # M x D\n",
    "        Y0, Du0 = self.net_u(t0,X0) # M x 1, M x D\n",
    "        sigma0 = self.sigma_tf(t0, X0, Y0)\n",
    "        Z0 = tf.squeeze(tf.matmul(tf.expand_dims(Du0, 1), sigma0), axis=1)\n",
    "\n",
    "        X_list.append(X0)\n",
    "        Y_list.append(Y0)\n",
    "        Z_list.append(Z0)\n",
    "\n",
    "        for n in range(0,self.N):\n",
    "            t1 = t[:,n+1,:]\n",
    "            W1 = W[:,n+1,:]\n",
    "            dW = W1 - W0\n",
    "            sigma_dW = tf.squeeze(tf.matmul(sigma0, tf.expand_dims(dW,-1)), axis=[-1])\n",
    "            X1 = X0 + self.mu_tf(t0,X0,Y0,Z0)*(t1-t0) + sigma_dW\n",
    "            # Z = Du*sigma e nella backward compare Z*dW.\n",
    "            Y1_tilde = Y0 + self.phi_tf(t0,X0,Y0,Z0)*(t1-t0) + tf.reduce_sum(Z0*dW, axis=1, keepdims = True)\n",
    "            Y1, Du1 = self.net_u(t1,X1)\n",
    "            sigma1 = self.sigma_tf(t1, X1, Y1)\n",
    "            Z1 = tf.squeeze(tf.matmul(tf.expand_dims(Du1, 1), sigma1), axis=1)\n",
    "\n",
    "            loss += tf.reduce_sum(tf.square(Y1 - Y1_tilde))\n",
    "\n",
    "            t0 = t1\n",
    "            W0 = W1\n",
    "            X0 = X1\n",
    "            Y0 = Y1\n",
    "            Z0 = Z1\n",
    "            sigma0 = sigma1\n",
    "\n",
    "            X_list.append(X0)\n",
    "            Y_list.append(Y0)\n",
    "            Z_list.append(Z0)\n",
    "\n",
    "        loss += tf.reduce_sum(tf.square(Y1 - self.g_tf(X1)))\n",
    "        Dg = self.Dg_tf(X1)\n",
    "        Z_terminal = tf.squeeze(tf.matmul(tf.expand_dims(Dg, 1), sigma1), axis=1)\n",
    "        loss += tf.reduce_sum(tf.square(Z1 - Z_terminal))\n",
    "\n",
    "        X = tf.stack(X_list,axis=1)\n",
    "        Y = tf.stack(Y_list,axis=1)\n",
    "        Z = tf.stack(Z_list,axis=1)\n",
    "\n",
    "        return loss/self.N, X, Y, Y[0,0,0], Z\n",
    "\n",
    "    def fetch_minibatch(self):\n",
    "        T = self.T\n",
    "\n",
    "        M = self.M\n",
    "        N = self.N\n",
    "        D = self.D\n",
    "\n",
    "        Dt = np.zeros((M,N+1,1)) # M x (N+1) x 1\n",
    "        DW = np.zeros((M,N+1,D)) # M x (N+1) x D\n",
    "\n",
    "        dt = T/N\n",
    "\n",
    "        Dt[:,1:,:] = dt\n",
    "        DW[:,1:,:] = np.sqrt(dt)*np.random.normal(size=(M,N,D))\n",
    "\n",
    "        t = np.cumsum(Dt,axis=1) # M x (N+1) x 1\n",
    "        W = np.cumsum(DW,axis=1) # M x (N+1) x D\n",
    "\n",
    "        return t, W\n",
    "\n",
    "    def train(self, N_Iter, learning_rate, const_value=None):\n",
    "\n",
    "        start_time = time.time()\n",
    "        last_loss = None\n",
    "        last_y0 = None\n",
    "        current_const = np.float32(self.const if const_value is None else const_value)\n",
    "        for it in range(N_Iter):\n",
    "\n",
    "            t_batch, W_batch = self.fetch_minibatch() # M x (N+1) x 1, M x (N+1) x D\n",
    "\n",
    "            tf_dict = {\n",
    "                self.Xi_tf: self.Xi,\n",
    "                self.t_tf: t_batch,\n",
    "                self.W_tf: W_batch,\n",
    "                self.learning_rate: learning_rate,\n",
    "                self.const_tf: current_const,\n",
    "            }\n",
    "\n",
    "            self.sess.run(self.train_op, tf_dict)\n",
    "\n",
    "            # Print\n",
    "            if it % 10 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value, Y0_value, learning_rate_value = self.sess.run([self.loss, self.Y0_pred, self.learning_rate], tf_dict)\n",
    "                last_loss = float(loss_value)\n",
    "                last_y0 = float(Y0_value)\n",
    "                print('It: %d, Loss: %.3e, Y0: %.3f, Time: %.2f, Learning Rate: %.3e' %\n",
    "                      (it, loss_value, Y0_value, elapsed, learning_rate_value))\n",
    "                start_time = time.time()\n",
    "\n",
    "        return {\n",
    "            'const': float(current_const),\n",
    "            'learning_rate': float(learning_rate),\n",
    "            'n_iter': int(N_Iter),\n",
    "            'last_loss': last_loss,\n",
    "            'last_y0': last_y0,\n",
    "        }\n",
    "\n",
    "    def evaluate(self, const_value=None, n_batches=5):\n",
    "        current_const = np.float32(self.const if const_value is None else const_value)\n",
    "        losses = []\n",
    "        y0s = []\n",
    "        for _ in range(n_batches):\n",
    "            t_batch, W_batch = self.fetch_minibatch()\n",
    "            tf_dict = {\n",
    "                self.Xi_tf: self.Xi,\n",
    "                self.t_tf: t_batch,\n",
    "                self.W_tf: W_batch,\n",
    "                self.const_tf: current_const,\n",
    "            }\n",
    "            loss_value, y0_value = self.sess.run([self.loss, self.Y0_pred], tf_dict)\n",
    "            losses.append(float(loss_value))\n",
    "            y0s.append(float(y0_value))\n",
    "\n",
    "        return {\n",
    "            'const': float(current_const),\n",
    "            'mean_loss': float(np.mean(losses)),\n",
    "            'std_loss': float(np.std(losses)),\n",
    "            'mean_y0': float(np.mean(y0s)),\n",
    "            'std_y0': float(np.std(y0s)),\n",
    "            'n_batches': int(n_batches),\n",
    "        }\n",
    "\n",
    "\n",
    "    def predict(self, Xi_star, t_star, W_star, const_value=None):\n",
    "\n",
    "        current_const = np.float32(self.const if const_value is None else const_value)\n",
    "        tf_dict = {\n",
    "            self.Xi_tf: Xi_star,\n",
    "            self.t_tf: t_star,\n",
    "            self.W_tf: W_star,\n",
    "            self.const_tf: current_const,\n",
    "        }\n",
    "\n",
    "        X_star = self.sess.run(self.X_pred, tf_dict)\n",
    "        Y_star = self.sess.run(self.Y_pred, tf_dict)\n",
    "        Z_star = self.sess.run(self.Z_pred, tf_dict)\n",
    "\n",
    "        return X_star, Y_star, Z_star\n",
    "\n",
    "    ###########################################################################\n",
    "    ############################# Change Here! ################################\n",
    "    ###########################################################################\n",
    "    @abstractmethod\n",
    "    def phi_tf(self, t, X, Y, Z): # M x 1, M x D, M x 1, M x D\n",
    "        pass # M x1\n",
    "\n",
    "    @abstractmethod\n",
    "    def g_tf(self, X): # M x D\n",
    "        pass # M x 1\n",
    "\n",
    "    @abstractmethod\n",
    "    def mu_tf(self, t, X, Y, Z): # M x 1, M x D, M x 1, M x D\n",
    "        M = self.M\n",
    "        D = self.D\n",
    "        return np.zeros([M,D]) # M x D\n",
    "\n",
    "    @abstractmethod\n",
    "    def sigma_tf(self, t, X, Y): # M x 1, M x D, M x 1\n",
    "        M = self.M\n",
    "        D = self.D\n",
    "        return tf.matrix_diag(tf.ones([M,D])) # M x D x D\n",
    "    ###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cea27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(FBSNN):\n",
    "    def __init__(self, Xi, T, M, N, D, layers, parameters):\n",
    "        self.mu = parameters['mu']\n",
    "        self.c = parameters['c']\n",
    "        self.b = parameters['b']\n",
    "        self.a = parameters['a']\n",
    "        self.s1 = parameters['s1']\n",
    "        self.s2 = parameters['s2']\n",
    "        self.s3 = parameters['s3']\n",
    "        self.const = parameters['const']\n",
    "        super().__init__(Xi, T, M, N, D, layers)\n",
    "    \n",
    "    def mu_tf(self, t, X, Y, Z):\n",
    "        S, H, V, X_state = tf.split(X, num_or_size_splits=4, axis=1)\n",
    "        mu = tf.cast(self.mu, tf.float32)\n",
    "        c = tf.cast(self.c, tf.float32)\n",
    "        a = tf.cast(self.a, tf.float32)\n",
    "        b = tf.cast(self.b, tf.float32)\n",
    "        s3 = tf.cast(self.s3, tf.float32)\n",
    "        const = tf.cast(self.const_tf, tf.float32)\n",
    "        #Accoppiamento\n",
    "        #Z ha dimensione [M, D]. Le colonne sono nella forma\n",
    "        #[Z_S, Z_H, Z_V, Z_X]\n",
    "        Z_V = Z[:, 2:3]\n",
    "        exp_t = tf.exp(t)\n",
    "        V_from_Z = 0.5 * ((exp_t * const * Z_V / s3) - X_state)\n",
    "        dS = mu * (c - S)\n",
    "        dH = mu * (c - H)\n",
    "        dV = self.a * (X_state**2 + b*H + c*V_from_Z)\n",
    "        dX = V\n",
    "        return tf.concat([dS, dH, dV, dX], axis=1)\n",
    "\n",
    "    def g_tf(self, X):\n",
    "        S, H, V, X_state = tf.split(X, num_or_size_splits=4, axis=1)\n",
    "        exp_T = tf.exp(-self.T)\n",
    "        exp_S = tf.exp(S)\n",
    "        val = exp_S + (exp_S * H) + (V**2) + (X_state*V)\n",
    "        return exp_T * val\n",
    "\n",
    "    def phi_tf(self, t, X, Y, Z):\n",
    "        S, H, V, X_state = tf.split(X, num_or_size_splits=4, axis=1)\n",
    "        \n",
    "        mu = tf.cast(self.mu, tf.float32)\n",
    "        c = tf.cast(self.c, tf.float32)\n",
    "        a = tf.cast(self.a, tf.float32)\n",
    "        b = tf.cast(self.b, tf.float32)\n",
    "        s1 = tf.cast(self.s1, tf.float32)\n",
    "        s3 = tf.cast(self.s3, tf.float32)\n",
    "        const = tf.cast(self.const_tf, tf.float32)\n",
    "        \n",
    "        exp_t = tf.exp(-t)\n",
    "        exp_S = tf.exp(S)\n",
    "\n",
    "        term1 = (1.0 + H) * (mu * (c - S) * exp_S)\n",
    "        term2 = mu * (c - H) * exp_S\n",
    "        Z_V = Z[:, 2:3]\n",
    "        term3 = (2.0 * V + X_state) * (a * (X_state**2 + b * H + c * V))\n",
    "        term4 = V**2 + s3**2\n",
    "        term5 = 0.5 * exp_S * (s1**2) * (1.0 + H)\n",
    "        \n",
    "        equation = term1 + term2 + term3 + term4 + term5\n",
    "        equation = tf.cast(equation, tf.float32)\n",
    "        z3_scaled = Z_V / s3\n",
    "        girsanov_corr = 0.5 * tf.exp(t) * z3_scaled * a * c * (const - 1.0) * z3_scaled\n",
    "        \n",
    "        return -(Y - (exp_t * equation) + girsanov_corr)\n",
    "    \n",
    "    def sigma_tf(self, t, X, Y):\n",
    "        S, H, V, X_state = tf.split(X, num_or_size_splits=4, axis=1)\n",
    "        s1 = tf.cast(self.s1, tf.float32)\n",
    "        s2 = tf.cast(self.s2, tf.float32)\n",
    "        s3 = tf.cast(self.s3, tf.float32)\n",
    "\n",
    "        zeros = tf.zeros_like(S)\n",
    "        ones = tf.ones_like(S)\n",
    "\n",
    "        r1 = tf.concat([s1 * ones, zeros, zeros, zeros], axis=1)\n",
    "        r2 = tf.concat([zeros, s2 * ones, zeros, zeros], axis=1)\n",
    "        r3 = tf.concat([zeros, zeros, s3 * ones, zeros], axis=1)\n",
    "        r4 = tf.concat([zeros, zeros, zeros, zeros], axis=1)\n",
    "\n",
    "        return tf.stack([r1, r2, r3, r4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a4242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "\n",
      "=== Coupling stage: const=0.0 ===\n",
      "It: 0, Loss: 4.656e+01, Y0: 1.104, Time: 57.26, Learning Rate: 1.000e-03\n",
      "It: 10, Loss: 1.070e+01, Y0: 2.948, Time: 4.56, Learning Rate: 1.000e-03\n",
      "It: 20, Loss: 8.030e+00, Y0: 3.963, Time: 4.21, Learning Rate: 1.000e-03\n",
      "It: 30, Loss: 6.509e+00, Y0: 4.819, Time: 4.19, Learning Rate: 1.000e-03\n",
      "It: 40, Loss: 5.304e+00, Y0: 4.571, Time: 4.61, Learning Rate: 1.000e-03\n",
      "It: 50, Loss: 5.091e+00, Y0: 4.673, Time: 4.22, Learning Rate: 1.000e-03\n",
      "It: 60, Loss: 4.634e+00, Y0: 4.968, Time: 4.29, Learning Rate: 1.000e-03\n",
      "It: 70, Loss: 4.139e+00, Y0: 4.913, Time: 4.53, Learning Rate: 1.000e-03\n",
      "It: 80, Loss: 4.037e+00, Y0: 4.868, Time: 4.23, Learning Rate: 1.000e-03\n",
      "It: 90, Loss: 4.213e+00, Y0: 4.915, Time: 4.70, Learning Rate: 1.000e-03\n",
      "It: 100, Loss: 4.400e+00, Y0: 4.831, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 110, Loss: 4.516e+00, Y0: 4.842, Time: 4.32, Learning Rate: 1.000e-03\n",
      "It: 120, Loss: 4.364e+00, Y0: 4.724, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 130, Loss: 4.498e+00, Y0: 4.716, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 140, Loss: 3.463e+00, Y0: 4.526, Time: 4.79, Learning Rate: 1.000e-03\n",
      "It: 150, Loss: 3.445e+00, Y0: 4.641, Time: 4.41, Learning Rate: 1.000e-03\n",
      "It: 160, Loss: 3.734e+00, Y0: 4.443, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 170, Loss: 3.287e+00, Y0: 4.397, Time: 4.75, Learning Rate: 1.000e-03\n",
      "It: 180, Loss: 3.384e+00, Y0: 4.434, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 190, Loss: 3.663e+00, Y0: 4.198, Time: 4.80, Learning Rate: 1.000e-03\n",
      "It: 200, Loss: 3.130e+00, Y0: 4.016, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 210, Loss: 3.094e+00, Y0: 3.962, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 220, Loss: 2.522e+00, Y0: 3.561, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 230, Loss: 2.469e+00, Y0: 3.264, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 240, Loss: 1.998e+00, Y0: 2.683, Time: 4.51, Learning Rate: 1.000e-03\n",
      "It: 250, Loss: 2.928e+00, Y0: 2.509, Time: 4.45, Learning Rate: 1.000e-03\n",
      "It: 260, Loss: 1.947e+00, Y0: 2.115, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 270, Loss: 1.925e+00, Y0: 1.768, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 280, Loss: 1.554e+00, Y0: 1.744, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 290, Loss: 1.258e+00, Y0: 1.511, Time: 4.51, Learning Rate: 1.000e-03\n",
      "It: 300, Loss: 9.330e-01, Y0: 1.214, Time: 4.54, Learning Rate: 1.000e-03\n",
      "It: 310, Loss: 8.884e-01, Y0: 1.313, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 320, Loss: 5.194e-01, Y0: 1.505, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 330, Loss: 6.442e-01, Y0: 1.458, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 340, Loss: 6.525e-01, Y0: 1.524, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 350, Loss: 4.470e-01, Y0: 1.560, Time: 4.63, Learning Rate: 1.000e-03\n",
      "It: 360, Loss: 3.477e-01, Y0: 1.593, Time: 4.41, Learning Rate: 1.000e-03\n",
      "It: 370, Loss: 4.129e-01, Y0: 1.581, Time: 4.69, Learning Rate: 1.000e-03\n",
      "It: 380, Loss: 3.462e-01, Y0: 1.492, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 390, Loss: 2.727e-01, Y0: 1.438, Time: 4.31, Learning Rate: 1.000e-03\n",
      "It: 400, Loss: 2.393e-01, Y0: 1.392, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 410, Loss: 2.748e-01, Y0: 1.393, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 420, Loss: 2.574e-01, Y0: 1.341, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 430, Loss: 4.095e-01, Y0: 1.412, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 440, Loss: 4.091e-01, Y0: 1.372, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 450, Loss: 2.540e-01, Y0: 1.389, Time: 4.74, Learning Rate: 1.000e-03\n",
      "It: 460, Loss: 2.023e-01, Y0: 1.329, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 470, Loss: 1.966e-01, Y0: 1.268, Time: 4.67, Learning Rate: 1.000e-03\n",
      "It: 480, Loss: 2.541e-01, Y0: 1.245, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 490, Loss: 7.434e-01, Y0: 1.399, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 500, Loss: 5.927e-01, Y0: 1.446, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 510, Loss: 2.272e-01, Y0: 1.545, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 520, Loss: 2.265e-01, Y0: 1.406, Time: 4.54, Learning Rate: 1.000e-03\n",
      "It: 530, Loss: 1.900e-01, Y0: 1.371, Time: 4.54, Learning Rate: 1.000e-03\n",
      "It: 540, Loss: 2.513e-01, Y0: 1.345, Time: 4.42, Learning Rate: 1.000e-03\n",
      "It: 550, Loss: 2.051e-01, Y0: 1.297, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 560, Loss: 2.175e-01, Y0: 1.265, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 570, Loss: 1.821e-01, Y0: 1.279, Time: 4.56, Learning Rate: 1.000e-03\n",
      "It: 580, Loss: 1.795e-01, Y0: 1.224, Time: 4.60, Learning Rate: 1.000e-03\n",
      "It: 590, Loss: 1.822e-01, Y0: 1.226, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 600, Loss: 1.808e-01, Y0: 1.184, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 610, Loss: 1.955e-01, Y0: 1.176, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 620, Loss: 1.800e-01, Y0: 1.168, Time: 4.51, Learning Rate: 1.000e-03\n",
      "It: 630, Loss: 1.846e-01, Y0: 1.143, Time: 4.64, Learning Rate: 1.000e-03\n",
      "It: 640, Loss: 1.757e-01, Y0: 1.118, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 650, Loss: 3.925e-01, Y0: 1.207, Time: 4.77, Learning Rate: 1.000e-03\n",
      "It: 660, Loss: 2.285e-01, Y0: 1.149, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 670, Loss: 1.635e-01, Y0: 1.194, Time: 4.50, Learning Rate: 1.000e-03\n",
      "It: 680, Loss: 1.590e-01, Y0: 1.201, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 690, Loss: 1.558e-01, Y0: 1.182, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 700, Loss: 2.591e-01, Y0: 1.132, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 710, Loss: 1.768e-01, Y0: 1.207, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 720, Loss: 1.902e-01, Y0: 1.233, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 730, Loss: 2.044e-01, Y0: 1.214, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 740, Loss: 1.709e-01, Y0: 1.150, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 750, Loss: 8.594e-01, Y0: 1.106, Time: 4.78, Learning Rate: 1.000e-03\n",
      "It: 760, Loss: 1.401e-01, Y0: 1.413, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 770, Loss: 2.376e-01, Y0: 1.523, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 780, Loss: 1.779e-01, Y0: 1.453, Time: 4.73, Learning Rate: 1.000e-03\n",
      "It: 790, Loss: 1.546e-01, Y0: 1.420, Time: 4.44, Learning Rate: 1.000e-03\n",
      "[StageSummary] const=0.0, lr=1.0e-03, iters=800, eval_loss=1.631e-01±2.20e-02, eval_Y0=1.331±0.000, time=449.0s\n",
      "It: 0, Loss: 1.449e-01, Y0: 1.329, Time: 0.52, Learning Rate: 5.000e-04\n",
      "It: 10, Loss: 2.305e-01, Y0: 1.314, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 20, Loss: 1.368e-01, Y0: 1.310, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 30, Loss: 1.412e-01, Y0: 1.283, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 40, Loss: 1.281e-01, Y0: 1.261, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 50, Loss: 2.528e-01, Y0: 1.233, Time: 4.50, Learning Rate: 5.000e-04\n",
      "It: 60, Loss: 1.424e-01, Y0: 1.212, Time: 4.61, Learning Rate: 5.000e-04\n",
      "It: 70, Loss: 1.557e-01, Y0: 1.202, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 80, Loss: 1.350e-01, Y0: 1.180, Time: 4.75, Learning Rate: 5.000e-04\n",
      "It: 90, Loss: 1.502e-01, Y0: 1.183, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 100, Loss: 1.333e-01, Y0: 1.168, Time: 4.45, Learning Rate: 5.000e-04\n",
      "It: 110, Loss: 1.331e-01, Y0: 1.151, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 120, Loss: 1.321e-01, Y0: 1.131, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 130, Loss: 1.342e-01, Y0: 1.140, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 140, Loss: 1.297e-01, Y0: 1.125, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 150, Loss: 1.367e-01, Y0: 1.138, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 160, Loss: 1.250e-01, Y0: 1.101, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 170, Loss: 1.215e-01, Y0: 1.102, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 180, Loss: 1.422e-01, Y0: 1.089, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 190, Loss: 1.470e-01, Y0: 1.086, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 200, Loss: 1.229e-01, Y0: 1.083, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 210, Loss: 1.221e-01, Y0: 1.068, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 220, Loss: 1.338e-01, Y0: 1.085, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 230, Loss: 1.281e-01, Y0: 1.074, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 240, Loss: 1.325e-01, Y0: 1.073, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 250, Loss: 1.293e-01, Y0: 1.052, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 260, Loss: 1.287e-01, Y0: 1.050, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 270, Loss: 1.175e-01, Y0: 1.065, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 280, Loss: 1.258e-01, Y0: 1.047, Time: 4.55, Learning Rate: 5.000e-04\n",
      "It: 290, Loss: 1.426e-01, Y0: 1.031, Time: 4.51, Learning Rate: 5.000e-04\n",
      "It: 300, Loss: 1.192e-01, Y0: 1.036, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 310, Loss: 1.271e-01, Y0: 1.028, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 320, Loss: 1.196e-01, Y0: 1.035, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 330, Loss: 1.167e-01, Y0: 1.017, Time: 4.48, Learning Rate: 5.000e-04\n",
      "It: 340, Loss: 1.243e-01, Y0: 1.020, Time: 4.52, Learning Rate: 5.000e-04\n",
      "It: 350, Loss: 1.599e-01, Y0: 1.009, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 360, Loss: 1.165e-01, Y0: 1.025, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 370, Loss: 1.267e-01, Y0: 1.006, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 380, Loss: 1.150e-01, Y0: 1.011, Time: 4.47, Learning Rate: 5.000e-04\n",
      "It: 390, Loss: 1.072e-01, Y0: 1.016, Time: 4.54, Learning Rate: 5.000e-04\n",
      "It: 400, Loss: 1.317e-01, Y0: 1.001, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 410, Loss: 1.119e-01, Y0: 1.001, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 420, Loss: 1.303e-01, Y0: 0.980, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 430, Loss: 1.158e-01, Y0: 0.973, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 440, Loss: 1.248e-01, Y0: 0.981, Time: 4.74, Learning Rate: 5.000e-04\n",
      "It: 450, Loss: 1.129e-01, Y0: 0.993, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 460, Loss: 1.109e-01, Y0: 0.961, Time: 4.75, Learning Rate: 5.000e-04\n",
      "It: 470, Loss: 1.085e-01, Y0: 0.957, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 480, Loss: 1.021e-01, Y0: 0.955, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 490, Loss: 1.204e-01, Y0: 0.949, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 500, Loss: 1.405e-01, Y0: 0.954, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 510, Loss: 1.030e-01, Y0: 0.934, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 550, Loss: 1.072e-01, Y0: 0.894, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 560, Loss: 9.906e-02, Y0: 0.891, Time: 4.62, Learning Rate: 5.000e-04\n",
      "It: 570, Loss: 1.068e-01, Y0: 0.912, Time: 4.31, Learning Rate: 5.000e-04\n",
      "It: 580, Loss: 1.120e-01, Y0: 0.885, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 590, Loss: 1.561e-01, Y0: 0.886, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 600, Loss: 1.113e-01, Y0: 0.907, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 610, Loss: 1.087e-01, Y0: 0.892, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 620, Loss: 9.679e-02, Y0: 0.893, Time: 4.43, Learning Rate: 5.000e-04\n",
      "It: 630, Loss: 9.739e-02, Y0: 0.866, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 640, Loss: 1.068e-01, Y0: 0.864, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 650, Loss: 9.803e-02, Y0: 0.862, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 660, Loss: 9.836e-02, Y0: 0.842, Time: 4.45, Learning Rate: 5.000e-04\n",
      "It: 670, Loss: 1.025e-01, Y0: 0.841, Time: 4.50, Learning Rate: 5.000e-04\n",
      "It: 680, Loss: 1.046e-01, Y0: 0.835, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 690, Loss: 9.925e-02, Y0: 0.828, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 700, Loss: 1.067e-01, Y0: 0.830, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 710, Loss: 1.011e-01, Y0: 0.822, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 720, Loss: 1.014e-01, Y0: 0.822, Time: 4.61, Learning Rate: 5.000e-04\n",
      "It: 730, Loss: 1.233e-01, Y0: 0.802, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 740, Loss: 9.629e-02, Y0: 0.809, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 750, Loss: 9.869e-02, Y0: 0.806, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 760, Loss: 1.197e-01, Y0: 0.793, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 770, Loss: 9.080e-02, Y0: 0.769, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 780, Loss: 9.421e-02, Y0: 0.748, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 790, Loss: 9.298e-02, Y0: 0.757, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 800, Loss: 1.026e-01, Y0: 0.746, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 810, Loss: 9.283e-02, Y0: 0.737, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 820, Loss: 1.032e-01, Y0: 0.717, Time: 4.63, Learning Rate: 5.000e-04\n",
      "It: 830, Loss: 1.047e-01, Y0: 0.716, Time: 4.31, Learning Rate: 5.000e-04\n",
      "It: 840, Loss: 2.324e-01, Y0: 0.654, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 850, Loss: 1.287e-01, Y0: 0.813, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 860, Loss: 1.096e-01, Y0: 0.779, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 870, Loss: 9.526e-02, Y0: 0.772, Time: 4.75, Learning Rate: 5.000e-04\n",
      "It: 880, Loss: 9.547e-02, Y0: 0.739, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 890, Loss: 9.358e-02, Y0: 0.733, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 900, Loss: 8.936e-02, Y0: 0.691, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 910, Loss: 9.102e-02, Y0: 0.680, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 920, Loss: 1.143e-01, Y0: 0.678, Time: 4.69, Learning Rate: 5.000e-04\n",
      "It: 930, Loss: 9.424e-02, Y0: 0.679, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 940, Loss: 9.486e-02, Y0: 0.673, Time: 4.52, Learning Rate: 5.000e-04\n",
      "It: 950, Loss: 1.399e-01, Y0: 0.671, Time: 4.48, Learning Rate: 5.000e-04\n",
      "It: 960, Loss: 1.135e-01, Y0: 0.688, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 970, Loss: 1.706e-01, Y0: 0.732, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 980, Loss: 9.326e-02, Y0: 0.661, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 990, Loss: 9.357e-02, Y0: 0.698, Time: 4.53, Learning Rate: 5.000e-04\n",
      "It: 1000, Loss: 8.424e-02, Y0: 0.640, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 1010, Loss: 1.415e-01, Y0: 0.576, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 1020, Loss: 9.264e-02, Y0: 0.581, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 1030, Loss: 1.283e-01, Y0: 0.620, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 1040, Loss: 9.097e-02, Y0: 0.620, Time: 4.44, Learning Rate: 5.000e-04\n",
      "It: 1050, Loss: 8.436e-02, Y0: 0.616, Time: 4.54, Learning Rate: 5.000e-04\n",
      "It: 1060, Loss: 9.387e-02, Y0: 0.601, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 1070, Loss: 1.057e-01, Y0: 0.612, Time: 4.69, Learning Rate: 5.000e-04\n",
      "It: 1080, Loss: 1.280e-01, Y0: 0.538, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 1090, Loss: 1.071e-01, Y0: 0.547, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 1100, Loss: 1.099e-01, Y0: 0.573, Time: 4.59, Learning Rate: 5.000e-04\n",
      "It: 1110, Loss: 9.552e-02, Y0: 0.538, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 1120, Loss: 8.064e-02, Y0: 0.528, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 1130, Loss: 7.979e-02, Y0: 0.488, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 1140, Loss: 7.790e-02, Y0: 0.484, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 1150, Loss: 1.001e-01, Y0: 0.486, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 1160, Loss: 5.874e-01, Y0: 0.606, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 1170, Loss: 1.763e-01, Y0: 0.655, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 1180, Loss: 1.710e-01, Y0: 0.723, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 1190, Loss: 9.523e-02, Y0: 0.630, Time: 4.34, Learning Rate: 5.000e-04\n",
      "[StageSummary] const=0.0, lr=5.0e-04, iters=1200, eval_loss=8.272e-02±4.58e-03, eval_Y0=0.556±0.000, time=556.6s\n",
      "It: 0, Loss: 7.835e-02, Y0: 0.552, Time: 0.43, Learning Rate: 1.000e-04\n",
      "It: 10, Loss: 8.377e-02, Y0: 0.545, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 20, Loss: 8.899e-02, Y0: 0.532, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 30, Loss: 1.001e-01, Y0: 0.524, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 40, Loss: 7.879e-02, Y0: 0.516, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 50, Loss: 7.853e-02, Y0: 0.508, Time: 4.65, Learning Rate: 1.000e-04\n",
      "It: 60, Loss: 8.907e-02, Y0: 0.496, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 70, Loss: 7.471e-02, Y0: 0.488, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 80, Loss: 8.216e-02, Y0: 0.483, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 90, Loss: 7.476e-02, Y0: 0.475, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 100, Loss: 7.997e-02, Y0: 0.468, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 110, Loss: 9.646e-02, Y0: 0.464, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 120, Loss: 8.458e-02, Y0: 0.459, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 130, Loss: 7.676e-02, Y0: 0.460, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 140, Loss: 7.734e-02, Y0: 0.449, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 150, Loss: 8.829e-02, Y0: 0.444, Time: 4.75, Learning Rate: 1.000e-04\n",
      "It: 160, Loss: 7.927e-02, Y0: 0.446, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 170, Loss: 7.524e-02, Y0: 0.440, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 180, Loss: 8.240e-02, Y0: 0.433, Time: 4.29, Learning Rate: 1.000e-04\n",
      "It: 190, Loss: 7.230e-02, Y0: 0.432, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 200, Loss: 8.030e-02, Y0: 0.426, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 210, Loss: 8.002e-02, Y0: 0.419, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 220, Loss: 7.573e-02, Y0: 0.409, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 230, Loss: 7.839e-02, Y0: 0.409, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 240, Loss: 7.433e-02, Y0: 0.406, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 250, Loss: 7.927e-02, Y0: 0.401, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 260, Loss: 7.157e-02, Y0: 0.400, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 270, Loss: 8.478e-02, Y0: 0.395, Time: 4.58, Learning Rate: 1.000e-04\n",
      "It: 280, Loss: 7.429e-02, Y0: 0.394, Time: 4.48, Learning Rate: 1.000e-04\n",
      "It: 290, Loss: 7.663e-02, Y0: 0.389, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 300, Loss: 7.975e-02, Y0: 0.387, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 310, Loss: 8.925e-02, Y0: 0.383, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 320, Loss: 8.872e-02, Y0: 0.382, Time: 4.60, Learning Rate: 1.000e-04\n",
      "It: 330, Loss: 1.126e-01, Y0: 0.381, Time: 4.50, Learning Rate: 1.000e-04\n",
      "It: 340, Loss: 7.102e-02, Y0: 0.380, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 350, Loss: 7.183e-02, Y0: 0.377, Time: 4.76, Learning Rate: 1.000e-04\n",
      "It: 360, Loss: 7.528e-02, Y0: 0.374, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 370, Loss: 7.241e-02, Y0: 0.376, Time: 4.51, Learning Rate: 1.000e-04\n",
      "It: 380, Loss: 8.078e-02, Y0: 0.378, Time: 4.56, Learning Rate: 1.000e-04\n",
      "It: 390, Loss: 7.295e-02, Y0: 0.376, Time: 4.31, Learning Rate: 1.000e-04\n",
      "It: 400, Loss: 7.273e-02, Y0: 0.377, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 410, Loss: 7.642e-02, Y0: 0.377, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 420, Loss: 9.657e-02, Y0: 0.372, Time: 4.42, Learning Rate: 1.000e-04\n",
      "It: 430, Loss: 7.689e-02, Y0: 0.364, Time: 4.64, Learning Rate: 1.000e-04\n",
      "It: 440, Loss: 6.624e-02, Y0: 0.360, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 450, Loss: 7.876e-02, Y0: 0.357, Time: 4.76, Learning Rate: 1.000e-04\n",
      "It: 460, Loss: 7.472e-02, Y0: 0.349, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 470, Loss: 7.978e-02, Y0: 0.344, Time: 4.42, Learning Rate: 1.000e-04\n",
      "It: 480, Loss: 7.361e-02, Y0: 0.350, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 490, Loss: 7.091e-02, Y0: 0.342, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 500, Loss: 6.718e-02, Y0: 0.335, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 510, Loss: 7.403e-02, Y0: 0.331, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 520, Loss: 7.442e-02, Y0: 0.329, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 530, Loss: 6.513e-02, Y0: 0.329, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 540, Loss: 9.115e-02, Y0: 0.329, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 550, Loss: 7.379e-02, Y0: 0.325, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 560, Loss: 7.087e-02, Y0: 0.317, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 570, Loss: 6.642e-02, Y0: 0.317, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 580, Loss: 7.781e-02, Y0: 0.312, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 590, Loss: 7.015e-02, Y0: 0.310, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 600, Loss: 6.927e-02, Y0: 0.304, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 610, Loss: 9.465e-02, Y0: 0.303, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 620, Loss: 6.911e-02, Y0: 0.305, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 630, Loss: 6.813e-02, Y0: 0.308, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 640, Loss: 7.367e-02, Y0: 0.301, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 650, Loss: 7.581e-02, Y0: 0.294, Time: 4.56, Learning Rate: 1.000e-04\n",
      "It: 660, Loss: 7.374e-02, Y0: 0.292, Time: 4.46, Learning Rate: 1.000e-04\n",
      "It: 670, Loss: 6.758e-02, Y0: 0.283, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 680, Loss: 6.900e-02, Y0: 0.283, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 690, Loss: 7.640e-02, Y0: 0.278, Time: 4.30, Learning Rate: 1.000e-04\n",
      "It: 700, Loss: 6.947e-02, Y0: 0.277, Time: 4.42, Learning Rate: 1.000e-04\n",
      "It: 710, Loss: 7.161e-02, Y0: 0.270, Time: 4.55, Learning Rate: 1.000e-04\n",
      "It: 720, Loss: 7.830e-02, Y0: 0.267, Time: 4.30, Learning Rate: 1.000e-04\n",
      "It: 730, Loss: 8.578e-02, Y0: 0.273, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 740, Loss: 6.747e-02, Y0: 0.270, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 750, Loss: 6.673e-02, Y0: 0.269, Time: 4.41, Learning Rate: 1.000e-04\n",
      "It: 760, Loss: 7.149e-02, Y0: 0.259, Time: 4.63, Learning Rate: 1.000e-04\n",
      "It: 770, Loss: 7.518e-02, Y0: 0.260, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 780, Loss: 7.407e-02, Y0: 0.260, Time: 4.67, Learning Rate: 1.000e-04\n",
      "It: 790, Loss: 7.383e-02, Y0: 0.256, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 800, Loss: 7.674e-02, Y0: 0.255, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 810, Loss: 7.000e-02, Y0: 0.249, Time: 4.78, Learning Rate: 1.000e-04\n",
      "It: 820, Loss: 6.452e-02, Y0: 0.248, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 830, Loss: 7.146e-02, Y0: 0.249, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 840, Loss: 9.074e-02, Y0: 0.241, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 850, Loss: 7.536e-02, Y0: 0.238, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 860, Loss: 6.717e-02, Y0: 0.235, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 870, Loss: 7.035e-02, Y0: 0.235, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 880, Loss: 6.401e-02, Y0: 0.231, Time: 4.67, Learning Rate: 1.000e-04\n",
      "It: 890, Loss: 6.000e-02, Y0: 0.231, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 900, Loss: 6.895e-02, Y0: 0.227, Time: 4.31, Learning Rate: 1.000e-04\n",
      "It: 910, Loss: 7.325e-02, Y0: 0.223, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 920, Loss: 7.806e-02, Y0: 0.207, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 930, Loss: 8.451e-02, Y0: 0.203, Time: 4.65, Learning Rate: 1.000e-04\n",
      "It: 940, Loss: 7.017e-02, Y0: 0.204, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 950, Loss: 8.123e-02, Y0: 0.201, Time: 4.32, Learning Rate: 1.000e-04\n",
      "It: 960, Loss: 7.850e-02, Y0: 0.205, Time: 4.65, Learning Rate: 1.000e-04\n",
      "It: 970, Loss: 5.943e-02, Y0: 0.200, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 980, Loss: 7.077e-02, Y0: 0.196, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 990, Loss: 6.836e-02, Y0: 0.189, Time: 4.59, Learning Rate: 1.000e-04\n",
      "It: 1000, Loss: 6.870e-02, Y0: 0.192, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 1010, Loss: 6.341e-02, Y0: 0.189, Time: 4.84, Learning Rate: 1.000e-04\n",
      "It: 1020, Loss: 7.631e-02, Y0: 0.185, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1030, Loss: 7.718e-02, Y0: 0.179, Time: 4.53, Learning Rate: 1.000e-04\n",
      "It: 1040, Loss: 6.432e-02, Y0: 0.170, Time: 4.55, Learning Rate: 1.000e-04\n",
      "It: 1050, Loss: 6.645e-02, Y0: 0.161, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 1060, Loss: 6.630e-02, Y0: 0.159, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 1070, Loss: 7.813e-02, Y0: 0.157, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 1080, Loss: 6.932e-02, Y0: 0.154, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1090, Loss: 6.444e-02, Y0: 0.149, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 1100, Loss: 8.574e-02, Y0: 0.149, Time: 4.43, Learning Rate: 1.000e-04\n",
      "It: 1110, Loss: 6.305e-02, Y0: 0.142, Time: 4.81, Learning Rate: 1.000e-04\n",
      "It: 1120, Loss: 6.195e-02, Y0: 0.149, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 1130, Loss: 6.989e-02, Y0: 0.155, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 1140, Loss: 6.187e-02, Y0: 0.147, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 1150, Loss: 6.409e-02, Y0: 0.136, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 1160, Loss: 6.632e-02, Y0: 0.126, Time: 4.66, Learning Rate: 1.000e-04\n",
      "It: 1170, Loss: 6.651e-02, Y0: 0.123, Time: 4.32, Learning Rate: 1.000e-04\n",
      "It: 1180, Loss: 6.183e-02, Y0: 0.118, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1190, Loss: 7.860e-02, Y0: 0.120, Time: 4.71, Learning Rate: 1.000e-04\n",
      "[StageSummary] const=0.0, lr=1.0e-04, iters=1200, eval_loss=6.882e-02±7.43e-03, eval_Y0=0.110±0.000, time=558.3s\n",
      "=== Coupling stage: const=0.2 ===\n",
      "It: 0, Loss: 9.471e-02, Y0: 0.113, Time: 0.44, Learning Rate: 1.000e-03\n",
      "It: 10, Loss: 1.953e+01, Y0: 1.554, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 20, Loss: 3.296e+00, Y0: 0.029, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 30, Loss: 1.936e+00, Y0: -0.970, Time: 4.41, Learning Rate: 1.000e-03\n",
      "It: 40, Loss: 1.125e+00, Y0: -0.330, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 50, Loss: 5.668e-01, Y0: 0.055, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 60, Loss: 4.788e-01, Y0: -0.011, Time: 4.70, Learning Rate: 1.000e-03\n",
      "It: 70, Loss: 3.602e-01, Y0: -0.189, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 80, Loss: 2.678e-01, Y0: -0.514, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 90, Loss: 2.469e-01, Y0: -0.676, Time: 4.78, Learning Rate: 1.000e-03\n",
      "It: 100, Loss: 2.508e-01, Y0: -0.710, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 110, Loss: 2.733e-01, Y0: -0.720, Time: 4.84, Learning Rate: 1.000e-03\n",
      "It: 120, Loss: 3.048e-01, Y0: -0.779, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 130, Loss: 2.070e-01, Y0: -0.806, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 140, Loss: 2.035e-01, Y0: -0.832, Time: 4.69, Learning Rate: 1.000e-03\n",
      "It: 150, Loss: 2.070e-01, Y0: -0.901, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 160, Loss: 1.804e-01, Y0: -0.968, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 170, Loss: 2.156e-01, Y0: -0.957, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 180, Loss: 3.180e-01, Y0: -1.038, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 190, Loss: 2.042e-01, Y0: -1.094, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 200, Loss: 1.857e-01, Y0: -1.134, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 210, Loss: 1.443e-01, Y0: -1.112, Time: 4.54, Learning Rate: 1.000e-03\n",
      "It: 220, Loss: 1.850e-01, Y0: -1.179, Time: 4.45, Learning Rate: 1.000e-03\n",
      "It: 230, Loss: 1.451e-01, Y0: -1.169, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 240, Loss: 1.283e-01, Y0: -1.233, Time: 4.69, Learning Rate: 1.000e-03\n",
      "It: 250, Loss: 1.874e-01, Y0: -1.258, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 260, Loss: 1.291e-01, Y0: -1.251, Time: 4.44, Learning Rate: 1.000e-03\n",
      "It: 270, Loss: 1.516e-01, Y0: -1.270, Time: 4.53, Learning Rate: 1.000e-03\n",
      "It: 280, Loss: 1.802e-01, Y0: -1.287, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 290, Loss: 1.520e-01, Y0: -1.253, Time: 4.74, Learning Rate: 1.000e-03\n",
      "It: 300, Loss: 1.170e-01, Y0: -1.310, Time: 4.32, Learning Rate: 1.000e-03\n",
      "It: 310, Loss: 1.236e-01, Y0: -1.328, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 320, Loss: 1.185e-01, Y0: -1.350, Time: 4.62, Learning Rate: 1.000e-03\n",
      "It: 330, Loss: 1.159e-01, Y0: -1.367, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 340, Loss: 1.181e-01, Y0: -1.267, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 350, Loss: 1.017e-01, Y0: -1.338, Time: 4.32, Learning Rate: 1.000e-03\n",
      "It: 360, Loss: 1.085e-01, Y0: -1.383, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 370, Loss: 1.221e-01, Y0: -1.416, Time: 4.67, Learning Rate: 1.000e-03\n",
      "It: 380, Loss: 1.006e-01, Y0: -1.423, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 390, Loss: 1.209e-01, Y0: -1.453, Time: 4.69, Learning Rate: 1.000e-03\n",
      "It: 400, Loss: 9.302e-02, Y0: -1.445, Time: 4.32, Learning Rate: 1.000e-03\n",
      "It: 410, Loss: 8.578e-02, Y0: -1.416, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 420, Loss: 9.809e-02, Y0: -1.374, Time: 4.67, Learning Rate: 1.000e-03\n",
      "It: 430, Loss: 8.926e-02, Y0: -1.362, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 440, Loss: 1.046e-01, Y0: -1.384, Time: 4.58, Learning Rate: 1.000e-03\n",
      "It: 450, Loss: 7.824e-02, Y0: -1.428, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 460, Loss: 8.668e-02, Y0: -1.424, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 470, Loss: 9.531e-02, Y0: -1.451, Time: 4.68, Learning Rate: 1.000e-03\n",
      "It: 480, Loss: 7.882e-02, Y0: -1.469, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 490, Loss: 8.612e-02, Y0: -1.444, Time: 4.46, Learning Rate: 1.000e-03\n",
      "It: 500, Loss: 7.625e-02, Y0: -1.454, Time: 4.51, Learning Rate: 1.000e-03\n",
      "It: 510, Loss: 7.324e-02, Y0: -1.456, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 520, Loss: 7.012e-02, Y0: -1.478, Time: 4.65, Learning Rate: 1.000e-03\n",
      "It: 530, Loss: 7.396e-02, Y0: -1.502, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 540, Loss: 6.901e-02, Y0: -1.500, Time: 4.31, Learning Rate: 1.000e-03\n",
      "It: 550, Loss: 7.150e-02, Y0: -1.509, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 560, Loss: 6.542e-02, Y0: -1.508, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 570, Loss: 5.829e-02, Y0: -1.472, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 580, Loss: 7.078e-02, Y0: -1.487, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 590, Loss: 6.762e-02, Y0: -1.485, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 600, Loss: 6.963e-02, Y0: -1.475, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 610, Loss: 6.026e-02, Y0: -1.453, Time: 4.31, Learning Rate: 1.000e-03\n",
      "It: 620, Loss: 7.854e-02, Y0: -1.492, Time: 4.68, Learning Rate: 1.000e-03\n",
      "It: 630, Loss: 6.751e-02, Y0: -1.538, Time: 4.31, Learning Rate: 1.000e-03\n",
      "It: 640, Loss: 6.494e-02, Y0: -1.553, Time: 4.32, Learning Rate: 1.000e-03\n",
      "It: 650, Loss: 5.958e-02, Y0: -1.520, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 660, Loss: 5.651e-02, Y0: -1.542, Time: 4.31, Learning Rate: 1.000e-03\n",
      "It: 670, Loss: 6.765e-02, Y0: -1.559, Time: 4.56, Learning Rate: 1.000e-03\n",
      "It: 680, Loss: 5.234e-02, Y0: -1.565, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 690, Loss: 5.424e-02, Y0: -1.583, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 700, Loss: 6.151e-02, Y0: -1.600, Time: 4.84, Learning Rate: 1.000e-03\n",
      "It: 710, Loss: 5.288e-02, Y0: -1.658, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 720, Loss: 6.845e-02, Y0: -1.626, Time: 4.62, Learning Rate: 1.000e-03\n",
      "It: 730, Loss: 4.363e-02, Y0: -1.587, Time: 4.53, Learning Rate: 1.000e-03\n",
      "It: 740, Loss: 4.698e-02, Y0: -1.545, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 750, Loss: 7.053e-02, Y0: -1.526, Time: 4.79, Learning Rate: 1.000e-03\n",
      "It: 760, Loss: 4.667e-02, Y0: -1.592, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 770, Loss: 5.171e-02, Y0: -1.670, Time: 4.55, Learning Rate: 1.000e-03\n",
      "It: 780, Loss: 6.394e-02, Y0: -1.713, Time: 4.60, Learning Rate: 1.000e-03\n",
      "It: 790, Loss: 4.921e-02, Y0: -1.719, Time: 4.41, Learning Rate: 1.000e-03\n",
      "[StageSummary] const=0.2, lr=1.0e-03, iters=800, eval_loss=5.269e-02±7.12e-03, eval_Y0=-1.709±0.000, time=371.6s\n",
      "It: 0, Loss: 7.167e-02, Y0: -1.710, Time: 0.44, Learning Rate: 5.000e-04\n",
      "It: 10, Loss: 4.064e-02, Y0: -1.682, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 20, Loss: 4.289e-02, Y0: -1.691, Time: 4.74, Learning Rate: 5.000e-04\n",
      "It: 30, Loss: 6.283e-02, Y0: -1.701, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 40, Loss: 4.428e-02, Y0: -1.700, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 50, Loss: 4.647e-02, Y0: -1.724, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 60, Loss: 6.788e-02, Y0: -1.728, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 70, Loss: 7.588e-02, Y0: -1.732, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 80, Loss: 4.544e-02, Y0: -1.755, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 90, Loss: 4.661e-02, Y0: -1.756, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 100, Loss: 4.154e-02, Y0: -1.745, Time: 4.75, Learning Rate: 5.000e-04\n",
      "It: 110, Loss: 4.765e-02, Y0: -1.738, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 120, Loss: 4.165e-02, Y0: -1.734, Time: 4.55, Learning Rate: 5.000e-04\n",
      "It: 130, Loss: 6.164e-02, Y0: -1.733, Time: 4.50, Learning Rate: 5.000e-04\n",
      "It: 140, Loss: 5.469e-02, Y0: -1.742, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 150, Loss: 4.706e-02, Y0: -1.728, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 160, Loss: 4.242e-02, Y0: -1.724, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 170, Loss: 4.676e-02, Y0: -1.713, Time: 4.45, Learning Rate: 5.000e-04\n",
      "It: 180, Loss: 4.150e-02, Y0: -1.713, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 190, Loss: 3.891e-02, Y0: -1.742, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 200, Loss: 4.030e-02, Y0: -1.748, Time: 4.76, Learning Rate: 5.000e-04\n",
      "It: 210, Loss: 3.981e-02, Y0: -1.760, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 220, Loss: 2.020e-01, Y0: -1.758, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 230, Loss: 3.698e-02, Y0: -1.748, Time: 4.62, Learning Rate: 5.000e-04\n",
      "It: 240, Loss: 4.718e-02, Y0: -1.779, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 250, Loss: 4.483e-02, Y0: -1.791, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 260, Loss: 4.176e-02, Y0: -1.803, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 270, Loss: 3.655e-02, Y0: -1.811, Time: 4.31, Learning Rate: 5.000e-04\n",
      "It: 280, Loss: 3.646e-02, Y0: -1.814, Time: 4.80, Learning Rate: 5.000e-04\n",
      "It: 290, Loss: 4.081e-02, Y0: -1.806, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 300, Loss: 3.941e-02, Y0: -1.810, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 310, Loss: 3.719e-02, Y0: -1.807, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 320, Loss: 3.930e-02, Y0: -1.816, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 330, Loss: 4.038e-02, Y0: -1.810, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 340, Loss: 3.441e-02, Y0: -1.800, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 350, Loss: 3.964e-02, Y0: -1.780, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 360, Loss: 5.651e-02, Y0: -1.762, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 370, Loss: 3.586e-02, Y0: -1.773, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 380, Loss: 3.627e-02, Y0: -1.782, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 390, Loss: 4.846e-02, Y0: -1.777, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 400, Loss: 4.038e-02, Y0: -1.783, Time: 4.57, Learning Rate: 5.000e-04\n",
      "It: 410, Loss: 3.610e-02, Y0: -1.800, Time: 4.52, Learning Rate: 5.000e-04\n",
      "It: 420, Loss: 4.026e-02, Y0: -1.813, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 430, Loss: 3.793e-02, Y0: -1.814, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 440, Loss: 3.419e-02, Y0: -1.867, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 450, Loss: 3.750e-02, Y0: -1.885, Time: 4.51, Learning Rate: 5.000e-04\n",
      "It: 460, Loss: 4.927e-02, Y0: -1.890, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 470, Loss: 4.522e-02, Y0: -1.917, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 480, Loss: 4.266e-02, Y0: -1.932, Time: 4.66, Learning Rate: 5.000e-04\n",
      "It: 490, Loss: 3.686e-02, Y0: -1.915, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 500, Loss: 3.483e-02, Y0: -1.912, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 510, Loss: 3.434e-02, Y0: -1.907, Time: 4.61, Learning Rate: 5.000e-04\n",
      "It: 520, Loss: 4.880e-02, Y0: -1.908, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 530, Loss: 3.918e-02, Y0: -1.910, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 540, Loss: 3.695e-02, Y0: -1.895, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 550, Loss: 4.891e-02, Y0: -1.883, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 560, Loss: 3.367e-02, Y0: -1.888, Time: 4.75, Learning Rate: 5.000e-04\n",
      "It: 570, Loss: 3.301e-02, Y0: -1.904, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 580, Loss: 3.467e-02, Y0: -1.904, Time: 4.78, Learning Rate: 5.000e-04\n",
      "It: 590, Loss: 3.483e-02, Y0: -1.911, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 600, Loss: 3.753e-02, Y0: -1.910, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 610, Loss: 3.729e-02, Y0: -1.910, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 620, Loss: 4.010e-02, Y0: -1.911, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 630, Loss: 4.646e-02, Y0: -1.912, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 640, Loss: 3.217e-02, Y0: -1.901, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 650, Loss: 3.502e-02, Y0: -1.911, Time: 4.29, Learning Rate: 5.000e-04\n",
      "It: 660, Loss: 3.193e-02, Y0: -1.915, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 670, Loss: 3.381e-02, Y0: -1.940, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 680, Loss: 3.077e-02, Y0: -1.953, Time: 4.59, Learning Rate: 5.000e-04\n",
      "It: 690, Loss: 3.269e-02, Y0: -1.957, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 700, Loss: 4.014e-02, Y0: -1.957, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 710, Loss: 3.952e-02, Y0: -1.945, Time: 4.77, Learning Rate: 5.000e-04\n",
      "It: 720, Loss: 6.466e-02, Y0: -1.934, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 730, Loss: 3.377e-02, Y0: -1.919, Time: 4.53, Learning Rate: 5.000e-04\n",
      "It: 740, Loss: 3.379e-02, Y0: -1.914, Time: 4.53, Learning Rate: 5.000e-04\n",
      "It: 750, Loss: 3.312e-02, Y0: -1.922, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 760, Loss: 3.251e-02, Y0: -1.935, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 770, Loss: 3.092e-02, Y0: -1.939, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 780, Loss: 3.270e-02, Y0: -1.916, Time: 4.52, Learning Rate: 5.000e-04\n",
      "It: 790, Loss: 3.357e-02, Y0: -1.930, Time: 4.56, Learning Rate: 5.000e-04\n",
      "It: 800, Loss: 3.387e-02, Y0: -1.935, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 810, Loss: 5.992e-02, Y0: -1.939, Time: 4.76, Learning Rate: 5.000e-04\n",
      "It: 820, Loss: 3.597e-02, Y0: -1.947, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 830, Loss: 2.938e-02, Y0: -1.972, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 840, Loss: 3.448e-02, Y0: -1.973, Time: 4.69, Learning Rate: 5.000e-04\n",
      "It: 850, Loss: 3.287e-02, Y0: -1.958, Time: 4.43, Learning Rate: 5.000e-04\n",
      "It: 860, Loss: 3.211e-02, Y0: -1.940, Time: 4.76, Learning Rate: 5.000e-04\n",
      "It: 870, Loss: 4.438e-02, Y0: -1.938, Time: 4.44, Learning Rate: 5.000e-04\n",
      "It: 880, Loss: 3.498e-02, Y0: -1.941, Time: 4.43, Learning Rate: 5.000e-04\n",
      "It: 890, Loss: 3.064e-02, Y0: -1.984, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 900, Loss: 3.383e-02, Y0: -1.967, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 910, Loss: 4.509e-02, Y0: -1.976, Time: 4.79, Learning Rate: 5.000e-04\n",
      "It: 920, Loss: 2.893e-02, Y0: -1.975, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 930, Loss: 3.430e-02, Y0: -1.970, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 940, Loss: 4.936e-02, Y0: -1.944, Time: 4.76, Learning Rate: 5.000e-04\n",
      "It: 950, Loss: 3.029e-02, Y0: -1.957, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 960, Loss: 3.010e-02, Y0: -1.969, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 970, Loss: 3.128e-02, Y0: -1.978, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 980, Loss: 3.693e-02, Y0: -1.991, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 990, Loss: 3.742e-02, Y0: -2.011, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 1000, Loss: 2.991e-02, Y0: -2.000, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 1010, Loss: 3.530e-02, Y0: -2.005, Time: 4.77, Learning Rate: 5.000e-04\n",
      "It: 1020, Loss: 3.123e-02, Y0: -1.990, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 1030, Loss: 3.444e-02, Y0: -1.971, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 1040, Loss: 3.054e-02, Y0: -1.963, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 1050, Loss: 3.948e-02, Y0: -1.975, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 1060, Loss: 2.789e-02, Y0: -1.975, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 1070, Loss: 4.000e-02, Y0: -1.981, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 1080, Loss: 2.795e-02, Y0: -1.966, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 1090, Loss: 3.538e-02, Y0: -1.966, Time: 4.75, Learning Rate: 5.000e-04\n",
      "It: 1100, Loss: 3.788e-02, Y0: -1.985, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 1110, Loss: 3.271e-02, Y0: -1.988, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 1120, Loss: 2.813e-02, Y0: -2.000, Time: 4.54, Learning Rate: 5.000e-04\n",
      "It: 1130, Loss: 3.020e-02, Y0: -2.002, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 1140, Loss: 2.821e-02, Y0: -1.992, Time: 4.79, Learning Rate: 5.000e-04\n",
      "It: 1150, Loss: 3.118e-02, Y0: -1.997, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 1160, Loss: 2.917e-02, Y0: -1.984, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 1170, Loss: 2.728e-02, Y0: -1.989, Time: 4.59, Learning Rate: 5.000e-04\n",
      "It: 1180, Loss: 5.259e-02, Y0: -1.968, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 1190, Loss: 4.507e-02, Y0: -1.959, Time: 4.78, Learning Rate: 5.000e-04\n",
      "[StageSummary] const=0.2, lr=5.0e-04, iters=1200, eval_loss=2.890e-02±1.60e-03, eval_Y0=-1.974±0.000, time=558.6s\n",
      "It: 0, Loss: 2.879e-02, Y0: -1.974, Time: 0.44, Learning Rate: 1.000e-04\n",
      "It: 10, Loss: 3.006e-02, Y0: -1.973, Time: 4.64, Learning Rate: 1.000e-04\n",
      "It: 20, Loss: 2.775e-02, Y0: -1.972, Time: 4.51, Learning Rate: 1.000e-04\n",
      "It: 30, Loss: 3.236e-02, Y0: -1.972, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 40, Loss: 3.228e-02, Y0: -1.967, Time: 4.76, Learning Rate: 1.000e-04\n",
      "It: 50, Loss: 4.011e-02, Y0: -1.964, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 60, Loss: 2.896e-02, Y0: -1.966, Time: 4.57, Learning Rate: 1.000e-04\n",
      "It: 70, Loss: 3.249e-02, Y0: -1.967, Time: 4.55, Learning Rate: 1.000e-04\n",
      "It: 80, Loss: 2.705e-02, Y0: -1.970, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 90, Loss: 3.692e-02, Y0: -1.970, Time: 4.78, Learning Rate: 1.000e-04\n",
      "It: 100, Loss: 2.919e-02, Y0: -1.967, Time: 4.44, Learning Rate: 1.000e-04\n",
      "It: 110, Loss: 2.934e-02, Y0: -1.974, Time: 4.59, Learning Rate: 1.000e-04\n",
      "It: 120, Loss: 3.062e-02, Y0: -1.977, Time: 4.59, Learning Rate: 1.000e-04\n",
      "It: 130, Loss: 4.185e-02, Y0: -1.978, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 140, Loss: 2.994e-02, Y0: -1.979, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 150, Loss: 3.094e-02, Y0: -1.976, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 160, Loss: 4.399e-02, Y0: -1.975, Time: 4.50, Learning Rate: 1.000e-04\n",
      "It: 170, Loss: 3.054e-02, Y0: -1.977, Time: 4.59, Learning Rate: 1.000e-04\n",
      "It: 180, Loss: 5.012e-02, Y0: -1.977, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 190, Loss: 3.053e-02, Y0: -1.977, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 200, Loss: 4.144e-02, Y0: -1.979, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 210, Loss: 2.636e-02, Y0: -1.982, Time: 4.45, Learning Rate: 1.000e-04\n",
      "It: 220, Loss: 4.320e-02, Y0: -1.986, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 230, Loss: 3.191e-02, Y0: -1.988, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 240, Loss: 3.233e-02, Y0: -1.988, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 250, Loss: 3.307e-02, Y0: -1.984, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 260, Loss: 2.906e-02, Y0: -1.986, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 270, Loss: 3.072e-02, Y0: -1.982, Time: 4.66, Learning Rate: 1.000e-04\n",
      "It: 280, Loss: 3.539e-02, Y0: -1.978, Time: 4.31, Learning Rate: 1.000e-04\n",
      "It: 290, Loss: 2.594e-02, Y0: -1.983, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 300, Loss: 2.730e-02, Y0: -1.979, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 310, Loss: 2.804e-02, Y0: -1.977, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 320, Loss: 2.596e-02, Y0: -1.977, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 330, Loss: 5.647e-02, Y0: -1.976, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 340, Loss: 2.709e-02, Y0: -1.976, Time: 4.81, Learning Rate: 1.000e-04\n",
      "It: 350, Loss: 3.191e-02, Y0: -1.977, Time: 4.41, Learning Rate: 1.000e-04\n",
      "It: 360, Loss: 3.250e-02, Y0: -1.979, Time: 4.44, Learning Rate: 1.000e-04\n",
      "It: 370, Loss: 3.108e-02, Y0: -1.982, Time: 4.80, Learning Rate: 1.000e-04\n",
      "It: 380, Loss: 2.861e-02, Y0: -1.985, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 390, Loss: 2.692e-02, Y0: -1.986, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 400, Loss: 2.820e-02, Y0: -1.986, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 410, Loss: 2.705e-02, Y0: -1.991, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 420, Loss: 3.239e-02, Y0: -1.994, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 430, Loss: 2.717e-02, Y0: -1.987, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 440, Loss: 2.821e-02, Y0: -1.988, Time: 4.58, Learning Rate: 1.000e-04\n",
      "It: 450, Loss: 3.135e-02, Y0: -1.987, Time: 4.44, Learning Rate: 1.000e-04\n",
      "It: 460, Loss: 2.750e-02, Y0: -1.991, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 470, Loss: 2.930e-02, Y0: -1.993, Time: 4.66, Learning Rate: 1.000e-04\n",
      "It: 480, Loss: 3.118e-02, Y0: -1.991, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 490, Loss: 2.932e-02, Y0: -1.987, Time: 4.50, Learning Rate: 1.000e-04\n",
      "It: 500, Loss: 2.662e-02, Y0: -1.987, Time: 4.58, Learning Rate: 1.000e-04\n",
      "It: 510, Loss: 3.226e-02, Y0: -1.986, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 520, Loss: 2.575e-02, Y0: -1.991, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 530, Loss: 3.021e-02, Y0: -1.999, Time: 4.41, Learning Rate: 1.000e-04\n",
      "It: 540, Loss: 4.668e-02, Y0: -2.002, Time: 4.44, Learning Rate: 1.000e-04\n",
      "It: 550, Loss: 3.132e-02, Y0: -2.002, Time: 4.61, Learning Rate: 1.000e-04\n",
      "It: 560, Loss: 2.750e-02, Y0: -2.005, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 570, Loss: 3.733e-02, Y0: -2.006, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 580, Loss: 2.854e-02, Y0: -2.009, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 590, Loss: 2.705e-02, Y0: -1.999, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 600, Loss: 2.593e-02, Y0: -1.992, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 610, Loss: 3.711e-02, Y0: -1.987, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 620, Loss: 3.202e-02, Y0: -1.986, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 630, Loss: 2.748e-02, Y0: -1.985, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 640, Loss: 2.954e-02, Y0: -1.987, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 650, Loss: 3.016e-02, Y0: -1.994, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 660, Loss: 2.830e-02, Y0: -2.002, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 670, Loss: 2.972e-02, Y0: -2.002, Time: 4.66, Learning Rate: 1.000e-04\n",
      "It: 680, Loss: 2.590e-02, Y0: -2.001, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 690, Loss: 2.975e-02, Y0: -1.994, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 700, Loss: 3.884e-02, Y0: -1.989, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 710, Loss: 2.803e-02, Y0: -1.989, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 720, Loss: 2.619e-02, Y0: -1.987, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 730, Loss: 2.693e-02, Y0: -1.979, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 740, Loss: 3.293e-02, Y0: -1.975, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 750, Loss: 3.170e-02, Y0: -1.981, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 760, Loss: 2.979e-02, Y0: -1.987, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 770, Loss: 2.826e-02, Y0: -1.989, Time: 4.63, Learning Rate: 1.000e-04\n",
      "It: 780, Loss: 2.567e-02, Y0: -1.985, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 790, Loss: 2.925e-02, Y0: -1.979, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 800, Loss: 2.906e-02, Y0: -1.981, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 810, Loss: 2.691e-02, Y0: -1.984, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 820, Loss: 2.585e-02, Y0: -1.988, Time: 4.58, Learning Rate: 1.000e-04\n",
      "It: 830, Loss: 2.870e-02, Y0: -1.986, Time: 4.52, Learning Rate: 1.000e-04\n",
      "It: 840, Loss: 2.870e-02, Y0: -1.987, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 850, Loss: 3.874e-02, Y0: -1.982, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 860, Loss: 2.685e-02, Y0: -1.984, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 870, Loss: 3.238e-02, Y0: -1.990, Time: 4.45, Learning Rate: 1.000e-04\n",
      "It: 880, Loss: 3.237e-02, Y0: -1.995, Time: 4.62, Learning Rate: 1.000e-04\n",
      "It: 890, Loss: 5.840e-02, Y0: -1.993, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 900, Loss: 2.744e-02, Y0: -1.990, Time: 4.76, Learning Rate: 1.000e-04\n",
      "It: 910, Loss: 3.464e-02, Y0: -1.986, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 920, Loss: 3.206e-02, Y0: -1.982, Time: 4.46, Learning Rate: 1.000e-04\n",
      "It: 930, Loss: 2.924e-02, Y0: -1.978, Time: 4.67, Learning Rate: 1.000e-04\n",
      "It: 940, Loss: 3.160e-02, Y0: -1.975, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 950, Loss: 2.821e-02, Y0: -1.966, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 960, Loss: 2.538e-02, Y0: -1.971, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 970, Loss: 3.170e-02, Y0: -1.966, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 980, Loss: 3.003e-02, Y0: -1.962, Time: 4.78, Learning Rate: 1.000e-04\n",
      "It: 990, Loss: 2.648e-02, Y0: -1.960, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1000, Loss: 3.073e-02, Y0: -1.961, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 1010, Loss: 2.780e-02, Y0: -1.970, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1020, Loss: 2.548e-02, Y0: -1.972, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1030, Loss: 2.851e-02, Y0: -1.972, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 1040, Loss: 4.296e-02, Y0: -1.965, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 1050, Loss: 2.686e-02, Y0: -1.963, Time: 4.75, Learning Rate: 1.000e-04\n",
      "It: 1060, Loss: 2.839e-02, Y0: -1.968, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1070, Loss: 3.169e-02, Y0: -1.968, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1080, Loss: 2.906e-02, Y0: -1.976, Time: 4.75, Learning Rate: 1.000e-04\n",
      "It: 1090, Loss: 3.317e-02, Y0: -1.982, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1100, Loss: 2.646e-02, Y0: -1.983, Time: 4.67, Learning Rate: 1.000e-04\n",
      "It: 1110, Loss: 2.774e-02, Y0: -1.975, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 1120, Loss: 2.706e-02, Y0: -1.970, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1130, Loss: 2.811e-02, Y0: -1.968, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 1140, Loss: 2.540e-02, Y0: -1.968, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1150, Loss: 3.626e-02, Y0: -1.966, Time: 4.55, Learning Rate: 1.000e-04\n",
      "It: 1160, Loss: 2.699e-02, Y0: -1.967, Time: 4.45, Learning Rate: 1.000e-04\n",
      "It: 1170, Loss: 2.677e-02, Y0: -1.967, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 1180, Loss: 3.490e-02, Y0: -1.965, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 1190, Loss: 6.168e-02, Y0: -1.963, Time: 4.42, Learning Rate: 1.000e-04\n",
      "[StageSummary] const=0.2, lr=1.0e-04, iters=1200, eval_loss=2.721e-02±7.61e-04, eval_Y0=-1.966±0.000, time=560.0s\n",
      "=== Coupling stage: const=0.4 ===\n",
      "It: 0, Loss: 2.908e-01, Y0: -1.789, Time: 0.50, Learning Rate: 1.000e-03\n",
      "It: 10, Loss: 1.032e+01, Y0: 0.479, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 20, Loss: 2.896e+00, Y0: 0.876, Time: 4.41, Learning Rate: 1.000e-03\n",
      "It: 30, Loss: 1.400e+00, Y0: 2.003, Time: 4.83, Learning Rate: 1.000e-03\n",
      "It: 40, Loss: 8.835e-01, Y0: 2.189, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 50, Loss: 4.821e-01, Y0: 1.507, Time: 4.80, Learning Rate: 1.000e-03\n",
      "It: 60, Loss: 4.152e-01, Y0: 0.937, Time: 4.42, Learning Rate: 1.000e-03\n",
      "It: 70, Loss: 3.036e-01, Y0: 0.683, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 80, Loss: 3.007e-01, Y0: 0.631, Time: 4.75, Learning Rate: 1.000e-03\n",
      "It: 90, Loss: 2.192e-01, Y0: 0.597, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 100, Loss: 2.377e-01, Y0: 0.444, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 110, Loss: 2.637e-01, Y0: 0.303, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 120, Loss: 2.157e-01, Y0: 0.234, Time: 4.41, Learning Rate: 1.000e-03\n",
      "It: 130, Loss: 2.081e-01, Y0: 0.141, Time: 4.84, Learning Rate: 1.000e-03\n",
      "It: 140, Loss: 1.901e-01, Y0: 0.010, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 150, Loss: 1.569e-01, Y0: -0.100, Time: 4.60, Learning Rate: 1.000e-03\n",
      "It: 160, Loss: 1.497e-01, Y0: -0.189, Time: 4.57, Learning Rate: 1.000e-03\n",
      "It: 170, Loss: 1.416e-01, Y0: -0.275, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 180, Loss: 1.228e-01, Y0: -0.370, Time: 4.79, Learning Rate: 1.000e-03\n",
      "It: 190, Loss: 1.236e-01, Y0: -0.416, Time: 4.46, Learning Rate: 1.000e-03\n",
      "It: 200, Loss: 1.147e-01, Y0: -0.445, Time: 4.58, Learning Rate: 1.000e-03\n",
      "It: 210, Loss: 1.077e-01, Y0: -0.456, Time: 4.54, Learning Rate: 1.000e-03\n",
      "It: 220, Loss: 1.088e-01, Y0: -0.469, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 230, Loss: 8.560e-02, Y0: -0.501, Time: 4.70, Learning Rate: 1.000e-03\n",
      "It: 240, Loss: 1.095e-01, Y0: -0.530, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 250, Loss: 9.132e-02, Y0: -0.564, Time: 4.52, Learning Rate: 1.000e-03\n",
      "It: 260, Loss: 8.594e-02, Y0: -0.577, Time: 4.60, Learning Rate: 1.000e-03\n",
      "It: 270, Loss: 8.894e-02, Y0: -0.569, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 280, Loss: 7.542e-02, Y0: -0.575, Time: 4.66, Learning Rate: 1.000e-03\n",
      "It: 290, Loss: 1.073e-01, Y0: -0.573, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 300, Loss: 8.124e-02, Y0: -0.582, Time: 4.42, Learning Rate: 1.000e-03\n",
      "It: 310, Loss: 6.984e-02, Y0: -0.577, Time: 4.67, Learning Rate: 1.000e-03\n",
      "It: 320, Loss: 7.055e-02, Y0: -0.577, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 330, Loss: 7.823e-02, Y0: -0.572, Time: 4.74, Learning Rate: 1.000e-03\n",
      "It: 340, Loss: 7.372e-02, Y0: -0.577, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 350, Loss: 6.014e-02, Y0: -0.577, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 360, Loss: 7.486e-02, Y0: -0.572, Time: 4.67, Learning Rate: 1.000e-03\n",
      "It: 370, Loss: 6.528e-02, Y0: -0.570, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 380, Loss: 5.978e-02, Y0: -0.559, Time: 4.79, Learning Rate: 1.000e-03\n",
      "It: 390, Loss: 5.865e-02, Y0: -0.538, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 400, Loss: 5.142e-02, Y0: -0.515, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 410, Loss: 5.847e-02, Y0: -0.508, Time: 4.73, Learning Rate: 1.000e-03\n",
      "It: 420, Loss: 5.218e-02, Y0: -0.492, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 430, Loss: 5.516e-02, Y0: -0.469, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 440, Loss: 5.710e-02, Y0: -0.449, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 450, Loss: 5.008e-02, Y0: -0.433, Time: 4.41, Learning Rate: 1.000e-03\n",
      "It: 460, Loss: 4.843e-02, Y0: -0.439, Time: 4.76, Learning Rate: 1.000e-03\n",
      "It: 470, Loss: 5.244e-02, Y0: -0.435, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 480, Loss: 6.541e-02, Y0: -0.400, Time: 4.69, Learning Rate: 1.000e-03\n",
      "It: 490, Loss: 6.107e-02, Y0: -0.391, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 500, Loss: 6.880e-02, Y0: -0.362, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 510, Loss: 5.849e-02, Y0: -0.362, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 520, Loss: 5.578e-02, Y0: -0.351, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 530, Loss: 4.458e-02, Y0: -0.345, Time: 4.65, Learning Rate: 1.000e-03\n",
      "It: 540, Loss: 4.728e-02, Y0: -0.331, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 550, Loss: 4.188e-02, Y0: -0.306, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 560, Loss: 5.260e-02, Y0: -0.292, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 570, Loss: 5.113e-02, Y0: -0.242, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 580, Loss: 4.575e-02, Y0: -0.216, Time: 4.56, Learning Rate: 1.000e-03\n",
      "It: 590, Loss: 4.423e-02, Y0: -0.235, Time: 4.52, Learning Rate: 1.000e-03\n",
      "It: 600, Loss: 1.332e-01, Y0: -0.251, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 610, Loss: 9.443e-02, Y0: -0.158, Time: 4.75, Learning Rate: 1.000e-03\n",
      "It: 620, Loss: 4.182e-02, Y0: -0.160, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 630, Loss: 6.276e-02, Y0: -0.154, Time: 4.46, Learning Rate: 1.000e-03\n",
      "It: 640, Loss: 7.082e-02, Y0: -0.146, Time: 4.59, Learning Rate: 1.000e-03\n",
      "It: 650, Loss: 4.362e-02, Y0: -0.166, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 660, Loss: 3.673e-02, Y0: -0.157, Time: 4.78, Learning Rate: 1.000e-03\n",
      "It: 670, Loss: 4.001e-02, Y0: -0.122, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 680, Loss: 5.532e-02, Y0: -0.084, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 690, Loss: 5.464e-02, Y0: -0.056, Time: 4.61, Learning Rate: 1.000e-03\n",
      "It: 700, Loss: 4.067e-02, Y0: -0.057, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 710, Loss: 6.245e-02, Y0: -0.036, Time: 4.80, Learning Rate: 1.000e-03\n",
      "It: 720, Loss: 2.369e-01, Y0: 0.077, Time: 4.39, Learning Rate: 1.000e-03\n",
      "It: 730, Loss: 7.129e-02, Y0: 0.086, Time: 4.43, Learning Rate: 1.000e-03\n",
      "It: 740, Loss: 5.842e-02, Y0: 0.077, Time: 4.75, Learning Rate: 1.000e-03\n",
      "It: 750, Loss: 4.199e-02, Y0: 0.045, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 760, Loss: 5.682e-02, Y0: 0.028, Time: 4.74, Learning Rate: 1.000e-03\n",
      "It: 770, Loss: 3.174e-02, Y0: 0.017, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 780, Loss: 3.915e-02, Y0: 0.002, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 790, Loss: 3.396e-02, Y0: 0.012, Time: 4.68, Learning Rate: 1.000e-03\n",
      "[StageSummary] const=0.4, lr=1.0e-03, iters=800, eval_loss=3.726e-02±1.96e-03, eval_Y0=0.023±0.000, time=373.4s\n",
      "It: 0, Loss: 3.428e-02, Y0: 0.026, Time: 0.44, Learning Rate: 5.000e-04\n",
      "It: 10, Loss: 3.811e-02, Y0: 0.029, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 20, Loss: 3.651e-02, Y0: 0.017, Time: 4.28, Learning Rate: 5.000e-04\n",
      "It: 30, Loss: 3.558e-02, Y0: 0.027, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 40, Loss: 3.590e-02, Y0: 0.051, Time: 4.79, Learning Rate: 5.000e-04\n",
      "It: 50, Loss: 3.292e-02, Y0: 0.058, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 60, Loss: 3.553e-02, Y0: 0.059, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 70, Loss: 3.598e-02, Y0: 0.076, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 80, Loss: 3.833e-02, Y0: 0.081, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 90, Loss: 3.578e-02, Y0: 0.074, Time: 4.77, Learning Rate: 5.000e-04\n",
      "It: 100, Loss: 3.495e-02, Y0: 0.080, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 110, Loss: 3.494e-02, Y0: 0.083, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 120, Loss: 3.277e-02, Y0: 0.106, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 130, Loss: 3.335e-02, Y0: 0.125, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 140, Loss: 3.691e-02, Y0: 0.129, Time: 4.69, Learning Rate: 5.000e-04\n",
      "It: 150, Loss: 3.768e-02, Y0: 0.145, Time: 4.44, Learning Rate: 5.000e-04\n",
      "It: 160, Loss: 3.323e-02, Y0: 0.166, Time: 4.63, Learning Rate: 5.000e-04\n",
      "It: 170, Loss: 4.132e-02, Y0: 0.171, Time: 4.43, Learning Rate: 5.000e-04\n",
      "It: 180, Loss: 3.304e-02, Y0: 0.171, Time: 4.56, Learning Rate: 5.000e-04\n",
      "It: 190, Loss: 5.011e-02, Y0: 0.178, Time: 4.82, Learning Rate: 5.000e-04\n",
      "It: 200, Loss: 6.023e-02, Y0: 0.185, Time: 4.44, Learning Rate: 5.000e-04\n",
      "It: 210, Loss: 3.283e-02, Y0: 0.182, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 220, Loss: 3.880e-02, Y0: 0.191, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 230, Loss: 4.299e-02, Y0: 0.204, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 240, Loss: 3.872e-02, Y0: 0.211, Time: 4.82, Learning Rate: 5.000e-04\n",
      "It: 250, Loss: 3.307e-02, Y0: 0.217, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 260, Loss: 3.280e-02, Y0: 0.222, Time: 4.74, Learning Rate: 5.000e-04\n",
      "It: 270, Loss: 3.363e-02, Y0: 0.237, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 280, Loss: 4.719e-02, Y0: 0.246, Time: 4.44, Learning Rate: 5.000e-04\n",
      "It: 290, Loss: 3.272e-02, Y0: 0.272, Time: 4.81, Learning Rate: 5.000e-04\n",
      "It: 300, Loss: 3.285e-02, Y0: 0.284, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 310, Loss: 1.830e-01, Y0: 0.281, Time: 4.68, Learning Rate: 5.000e-04\n",
      "It: 320, Loss: 3.623e-02, Y0: 0.275, Time: 4.43, Learning Rate: 5.000e-04\n",
      "It: 330, Loss: 3.041e-02, Y0: 0.272, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 340, Loss: 4.726e-02, Y0: 0.266, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 350, Loss: 3.412e-02, Y0: 0.253, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 360, Loss: 3.036e-02, Y0: 0.272, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 370, Loss: 3.256e-02, Y0: 0.279, Time: 4.50, Learning Rate: 5.000e-04\n",
      "It: 380, Loss: 3.608e-02, Y0: 0.308, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 390, Loss: 6.369e-02, Y0: 0.325, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 400, Loss: 2.679e-02, Y0: 0.330, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 410, Loss: 3.150e-02, Y0: 0.337, Time: 4.48, Learning Rate: 5.000e-04\n",
      "It: 420, Loss: 2.966e-02, Y0: 0.349, Time: 4.54, Learning Rate: 5.000e-04\n",
      "It: 430, Loss: 2.965e-02, Y0: 0.372, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 440, Loss: 3.334e-02, Y0: 0.373, Time: 4.74, Learning Rate: 5.000e-04\n",
      "It: 450, Loss: 3.111e-02, Y0: 0.359, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 460, Loss: 3.294e-02, Y0: 0.361, Time: 4.47, Learning Rate: 5.000e-04\n",
      "It: 470, Loss: 2.900e-02, Y0: 0.377, Time: 4.60, Learning Rate: 5.000e-04\n",
      "It: 480, Loss: 3.142e-02, Y0: 0.397, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 490, Loss: 2.859e-02, Y0: 0.417, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 500, Loss: 2.880e-02, Y0: 0.435, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 510, Loss: 3.835e-02, Y0: 0.443, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 520, Loss: 3.250e-02, Y0: 0.455, Time: 4.66, Learning Rate: 5.000e-04\n",
      "It: 530, Loss: 3.049e-02, Y0: 0.473, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 540, Loss: 3.055e-02, Y0: 0.487, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 550, Loss: 4.713e-02, Y0: 0.496, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 560, Loss: 4.166e-02, Y0: 0.495, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 570, Loss: 3.527e-02, Y0: 0.486, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 580, Loss: 3.022e-02, Y0: 0.501, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 590, Loss: 3.150e-02, Y0: 0.515, Time: 4.72, Learning Rate: 5.000e-04\n",
      "It: 600, Loss: 8.201e-02, Y0: 0.521, Time: 4.32, Learning Rate: 5.000e-04\n",
      "It: 610, Loss: 2.810e-02, Y0: 0.499, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 620, Loss: 2.862e-02, Y0: 0.478, Time: 4.76, Learning Rate: 5.000e-04\n",
      "It: 630, Loss: 3.218e-02, Y0: 0.504, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 640, Loss: 4.109e-02, Y0: 0.471, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 650, Loss: 3.174e-02, Y0: 0.456, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 660, Loss: 2.548e-02, Y0: 0.490, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 670, Loss: 2.931e-02, Y0: 0.514, Time: 4.67, Learning Rate: 5.000e-04\n",
      "It: 680, Loss: 2.813e-02, Y0: 0.533, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 690, Loss: 3.844e-02, Y0: 0.541, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 700, Loss: 3.098e-02, Y0: 0.550, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 710, Loss: 3.017e-02, Y0: 0.547, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 720, Loss: 2.697e-02, Y0: 0.559, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 730, Loss: 3.070e-02, Y0: 0.570, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 740, Loss: 2.846e-02, Y0: 0.588, Time: 4.55, Learning Rate: 5.000e-04\n",
      "It: 750, Loss: 2.739e-02, Y0: 0.609, Time: 4.52, Learning Rate: 5.000e-04\n",
      "It: 760, Loss: 3.101e-02, Y0: 0.613, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 770, Loss: 2.809e-02, Y0: 0.616, Time: 4.81, Learning Rate: 5.000e-04\n",
      "It: 780, Loss: 2.995e-02, Y0: 0.621, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 790, Loss: 2.523e-02, Y0: 0.626, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 800, Loss: 2.756e-02, Y0: 0.657, Time: 4.51, Learning Rate: 5.000e-04\n",
      "It: 810, Loss: 2.693e-02, Y0: 0.668, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 820, Loss: 2.591e-02, Y0: 0.688, Time: 4.78, Learning Rate: 5.000e-04\n",
      "It: 830, Loss: 2.626e-02, Y0: 0.709, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 840, Loss: 2.986e-02, Y0: 0.730, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 850, Loss: 2.727e-02, Y0: 0.742, Time: 4.58, Learning Rate: 5.000e-04\n",
      "It: 860, Loss: 2.523e-02, Y0: 0.741, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 870, Loss: 2.912e-02, Y0: 0.773, Time: 4.76, Learning Rate: 5.000e-04\n",
      "It: 880, Loss: 3.435e-02, Y0: 0.764, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 890, Loss: 2.725e-02, Y0: 0.762, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 900, Loss: 2.717e-02, Y0: 0.770, Time: 4.65, Learning Rate: 5.000e-04\n",
      "It: 910, Loss: 2.734e-02, Y0: 0.773, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 920, Loss: 2.386e-02, Y0: 0.791, Time: 4.66, Learning Rate: 5.000e-04\n",
      "It: 930, Loss: 3.061e-02, Y0: 0.809, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 940, Loss: 2.604e-02, Y0: 0.831, Time: 4.39, Learning Rate: 5.000e-04\n",
      "It: 950, Loss: 3.918e-02, Y0: 0.835, Time: 4.77, Learning Rate: 5.000e-04\n",
      "It: 960, Loss: 2.958e-02, Y0: 0.848, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 970, Loss: 2.575e-02, Y0: 0.836, Time: 4.81, Learning Rate: 5.000e-04\n",
      "It: 980, Loss: 2.757e-02, Y0: 0.842, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 990, Loss: 2.524e-02, Y0: 0.853, Time: 4.35, Learning Rate: 5.000e-04\n",
      "It: 1000, Loss: 2.976e-02, Y0: 0.852, Time: 4.71, Learning Rate: 5.000e-04\n",
      "It: 1010, Loss: 2.385e-02, Y0: 0.855, Time: 4.38, Learning Rate: 5.000e-04\n",
      "It: 1020, Loss: 2.352e-02, Y0: 0.858, Time: 4.70, Learning Rate: 5.000e-04\n",
      "It: 1030, Loss: 2.935e-02, Y0: 0.845, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 1040, Loss: 2.775e-02, Y0: 0.833, Time: 4.42, Learning Rate: 5.000e-04\n",
      "It: 1050, Loss: 2.613e-02, Y0: 0.870, Time: 4.73, Learning Rate: 5.000e-04\n",
      "It: 1060, Loss: 7.941e-02, Y0: 0.864, Time: 4.37, Learning Rate: 5.000e-04\n",
      "It: 1070, Loss: 3.519e-02, Y0: 0.836, Time: 4.77, Learning Rate: 5.000e-04\n",
      "It: 1080, Loss: 3.310e-02, Y0: 0.829, Time: 4.36, Learning Rate: 5.000e-04\n",
      "It: 1090, Loss: 3.446e-02, Y0: 0.843, Time: 4.33, Learning Rate: 5.000e-04\n",
      "It: 1100, Loss: 2.596e-02, Y0: 0.844, Time: 4.74, Learning Rate: 5.000e-04\n",
      "It: 1110, Loss: 2.730e-02, Y0: 0.877, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 1120, Loss: 3.099e-02, Y0: 0.905, Time: 4.74, Learning Rate: 5.000e-04\n",
      "It: 1130, Loss: 2.691e-02, Y0: 0.914, Time: 4.34, Learning Rate: 5.000e-04\n",
      "It: 1140, Loss: 2.555e-02, Y0: 0.934, Time: 4.40, Learning Rate: 5.000e-04\n",
      "It: 1150, Loss: 4.271e-02, Y0: 0.923, Time: 4.69, Learning Rate: 5.000e-04\n",
      "It: 1160, Loss: 2.674e-02, Y0: 0.967, Time: 4.41, Learning Rate: 5.000e-04\n",
      "It: 1170, Loss: 2.416e-02, Y0: 0.981, Time: 4.57, Learning Rate: 5.000e-04\n",
      "It: 1180, Loss: 2.442e-02, Y0: 0.986, Time: 4.50, Learning Rate: 5.000e-04\n",
      "It: 1190, Loss: 2.558e-02, Y0: 0.987, Time: 4.37, Learning Rate: 5.000e-04\n",
      "[StageSummary] const=0.4, lr=5.0e-04, iters=1200, eval_loss=3.008e-02±1.41e-03, eval_Y0=1.004±0.000, time=559.7s\n",
      "It: 0, Loss: 2.876e-02, Y0: 1.007, Time: 0.46, Learning Rate: 1.000e-04\n",
      "It: 10, Loss: 2.605e-02, Y0: 1.012, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 20, Loss: 2.481e-02, Y0: 1.005, Time: 4.75, Learning Rate: 1.000e-04\n",
      "It: 30, Loss: 2.403e-02, Y0: 1.013, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 40, Loss: 2.639e-02, Y0: 1.011, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 50, Loss: 2.461e-02, Y0: 1.008, Time: 4.80, Learning Rate: 1.000e-04\n",
      "It: 60, Loss: 2.521e-02, Y0: 1.007, Time: 4.41, Learning Rate: 1.000e-04\n",
      "It: 70, Loss: 3.813e-02, Y0: 1.007, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 80, Loss: 2.516e-02, Y0: 1.007, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 90, Loss: 2.236e-02, Y0: 1.002, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 100, Loss: 2.833e-02, Y0: 0.996, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 110, Loss: 2.238e-02, Y0: 0.993, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 120, Loss: 2.682e-02, Y0: 0.997, Time: 4.64, Learning Rate: 1.000e-04\n",
      "It: 130, Loss: 2.404e-02, Y0: 1.001, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 140, Loss: 2.489e-02, Y0: 1.004, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 150, Loss: 2.411e-02, Y0: 1.006, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 160, Loss: 2.391e-02, Y0: 1.010, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 170, Loss: 2.288e-02, Y0: 1.015, Time: 4.53, Learning Rate: 1.000e-04\n",
      "It: 180, Loss: 2.223e-02, Y0: 1.018, Time: 4.46, Learning Rate: 1.000e-04\n",
      "It: 190, Loss: 2.283e-02, Y0: 1.025, Time: 4.41, Learning Rate: 1.000e-04\n",
      "It: 200, Loss: 2.266e-02, Y0: 1.033, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 210, Loss: 3.413e-02, Y0: 1.036, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 220, Loss: 2.984e-02, Y0: 1.035, Time: 4.48, Learning Rate: 1.000e-04\n",
      "It: 230, Loss: 2.516e-02, Y0: 1.035, Time: 4.51, Learning Rate: 1.000e-04\n",
      "It: 240, Loss: 2.613e-02, Y0: 1.036, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 250, Loss: 2.653e-02, Y0: 1.038, Time: 4.65, Learning Rate: 1.000e-04\n",
      "It: 260, Loss: 2.373e-02, Y0: 1.039, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 270, Loss: 2.166e-02, Y0: 1.040, Time: 4.47, Learning Rate: 1.000e-04\n",
      "It: 280, Loss: 2.684e-02, Y0: 1.040, Time: 4.59, Learning Rate: 1.000e-04\n",
      "It: 290, Loss: 2.367e-02, Y0: 1.039, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 300, Loss: 2.444e-02, Y0: 1.039, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 310, Loss: 2.422e-02, Y0: 1.044, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 320, Loss: 2.190e-02, Y0: 1.052, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 330, Loss: 2.730e-02, Y0: 1.057, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 340, Loss: 2.286e-02, Y0: 1.055, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 350, Loss: 2.612e-02, Y0: 1.054, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 360, Loss: 2.437e-02, Y0: 1.049, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 370, Loss: 2.391e-02, Y0: 1.050, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 380, Loss: 2.787e-02, Y0: 1.055, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 390, Loss: 2.396e-02, Y0: 1.060, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 400, Loss: 2.607e-02, Y0: 1.061, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 410, Loss: 2.457e-02, Y0: 1.066, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 420, Loss: 2.974e-02, Y0: 1.067, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 430, Loss: 2.236e-02, Y0: 1.069, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 440, Loss: 2.537e-02, Y0: 1.076, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 450, Loss: 3.022e-02, Y0: 1.083, Time: 4.78, Learning Rate: 1.000e-04\n",
      "It: 460, Loss: 2.286e-02, Y0: 1.086, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 470, Loss: 2.841e-02, Y0: 1.091, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 480, Loss: 2.857e-02, Y0: 1.097, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 490, Loss: 2.322e-02, Y0: 1.099, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 500, Loss: 2.661e-02, Y0: 1.106, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 510, Loss: 2.160e-02, Y0: 1.107, Time: 4.33, Learning Rate: 1.000e-04\n",
      "It: 520, Loss: 2.394e-02, Y0: 1.103, Time: 4.42, Learning Rate: 1.000e-04\n",
      "It: 530, Loss: 2.141e-02, Y0: 1.103, Time: 4.67, Learning Rate: 1.000e-04\n",
      "It: 540, Loss: 2.202e-02, Y0: 1.104, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 550, Loss: 2.316e-02, Y0: 1.107, Time: 4.55, Learning Rate: 1.000e-04\n",
      "It: 560, Loss: 2.429e-02, Y0: 1.111, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 570, Loss: 2.239e-02, Y0: 1.119, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 580, Loss: 2.215e-02, Y0: 1.128, Time: 4.67, Learning Rate: 1.000e-04\n",
      "It: 590, Loss: 2.220e-02, Y0: 1.126, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 600, Loss: 2.467e-02, Y0: 1.129, Time: 4.49, Learning Rate: 1.000e-04\n",
      "It: 610, Loss: 2.513e-02, Y0: 1.133, Time: 4.51, Learning Rate: 1.000e-04\n",
      "It: 620, Loss: 2.289e-02, Y0: 1.131, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 630, Loss: 3.037e-02, Y0: 1.130, Time: 4.65, Learning Rate: 1.000e-04\n",
      "It: 640, Loss: 2.583e-02, Y0: 1.133, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 650, Loss: 2.308e-02, Y0: 1.140, Time: 4.47, Learning Rate: 1.000e-04\n",
      "It: 660, Loss: 2.462e-02, Y0: 1.144, Time: 4.64, Learning Rate: 1.000e-04\n",
      "It: 670, Loss: 2.779e-02, Y0: 1.145, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 680, Loss: 2.560e-02, Y0: 1.137, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 690, Loss: 2.719e-02, Y0: 1.136, Time: 4.38, Learning Rate: 1.000e-04\n",
      "It: 700, Loss: 2.648e-02, Y0: 1.137, Time: 4.40, Learning Rate: 1.000e-04\n",
      "It: 710, Loss: 2.937e-02, Y0: 1.130, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 720, Loss: 2.187e-02, Y0: 1.127, Time: 4.41, Learning Rate: 1.000e-04\n",
      "It: 730, Loss: 2.695e-02, Y0: 1.131, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 740, Loss: 2.291e-02, Y0: 1.129, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 750, Loss: 4.283e-02, Y0: 1.129, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 760, Loss: 2.445e-02, Y0: 1.135, Time: 4.78, Learning Rate: 1.000e-04\n",
      "It: 770, Loss: 2.248e-02, Y0: 1.133, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 780, Loss: 2.794e-02, Y0: 1.137, Time: 4.77, Learning Rate: 1.000e-04\n",
      "It: 790, Loss: 2.178e-02, Y0: 1.140, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 800, Loss: 2.099e-02, Y0: 1.149, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 810, Loss: 2.187e-02, Y0: 1.157, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 820, Loss: 2.448e-02, Y0: 1.162, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 830, Loss: 2.253e-02, Y0: 1.167, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 840, Loss: 2.132e-02, Y0: 1.166, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 850, Loss: 2.487e-02, Y0: 1.171, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 860, Loss: 2.413e-02, Y0: 1.173, Time: 4.73, Learning Rate: 1.000e-04\n",
      "It: 870, Loss: 2.195e-02, Y0: 1.176, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 880, Loss: 2.187e-02, Y0: 1.158, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 890, Loss: 3.260e-02, Y0: 1.143, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 900, Loss: 2.383e-02, Y0: 1.147, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 910, Loss: 4.021e-02, Y0: 1.151, Time: 4.74, Learning Rate: 1.000e-04\n",
      "It: 920, Loss: 2.300e-02, Y0: 1.155, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 930, Loss: 2.416e-02, Y0: 1.159, Time: 4.55, Learning Rate: 1.000e-04\n",
      "It: 940, Loss: 2.213e-02, Y0: 1.161, Time: 4.43, Learning Rate: 1.000e-04\n",
      "It: 950, Loss: 2.298e-02, Y0: 1.160, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 960, Loss: 2.228e-02, Y0: 1.156, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 970, Loss: 2.516e-02, Y0: 1.161, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 980, Loss: 3.294e-02, Y0: 1.169, Time: 4.56, Learning Rate: 1.000e-04\n",
      "It: 990, Loss: 2.737e-02, Y0: 1.158, Time: 4.51, Learning Rate: 1.000e-04\n",
      "It: 1000, Loss: 2.222e-02, Y0: 1.153, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1010, Loss: 2.362e-02, Y0: 1.150, Time: 4.62, Learning Rate: 1.000e-04\n",
      "It: 1020, Loss: 2.373e-02, Y0: 1.157, Time: 4.34, Learning Rate: 1.000e-04\n",
      "It: 1030, Loss: 2.332e-02, Y0: 1.161, Time: 4.39, Learning Rate: 1.000e-04\n",
      "It: 1040, Loss: 2.256e-02, Y0: 1.160, Time: 4.64, Learning Rate: 1.000e-04\n",
      "It: 1050, Loss: 2.361e-02, Y0: 1.161, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 1060, Loss: 2.464e-02, Y0: 1.167, Time: 4.69, Learning Rate: 1.000e-04\n",
      "It: 1070, Loss: 2.106e-02, Y0: 1.166, Time: 4.30, Learning Rate: 1.000e-04\n",
      "It: 1080, Loss: 2.278e-02, Y0: 1.169, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 1090, Loss: 2.643e-02, Y0: 1.170, Time: 4.70, Learning Rate: 1.000e-04\n",
      "It: 1100, Loss: 2.198e-02, Y0: 1.182, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1110, Loss: 2.317e-02, Y0: 1.182, Time: 4.72, Learning Rate: 1.000e-04\n",
      "It: 1120, Loss: 2.431e-02, Y0: 1.180, Time: 4.37, Learning Rate: 1.000e-04\n",
      "It: 1130, Loss: 2.071e-02, Y0: 1.186, Time: 4.30, Learning Rate: 1.000e-04\n",
      "It: 1140, Loss: 2.299e-02, Y0: 1.190, Time: 4.68, Learning Rate: 1.000e-04\n",
      "It: 1150, Loss: 2.434e-02, Y0: 1.195, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1160, Loss: 2.303e-02, Y0: 1.206, Time: 4.71, Learning Rate: 1.000e-04\n",
      "It: 1170, Loss: 6.202e-02, Y0: 1.210, Time: 4.35, Learning Rate: 1.000e-04\n",
      "It: 1180, Loss: 2.326e-02, Y0: 1.202, Time: 4.36, Learning Rate: 1.000e-04\n",
      "It: 1190, Loss: 2.383e-02, Y0: 1.200, Time: 4.74, Learning Rate: 1.000e-04\n",
      "[StageSummary] const=0.4, lr=1.0e-04, iters=1200, eval_loss=2.342e-02±1.76e-03, eval_Y0=1.208±0.000, time=557.2s\n",
      "=== Coupling stage: const=0.6 ===\n",
      "It: 0, Loss: 3.107e-01, Y0: 1.426, Time: 0.45, Learning Rate: 1.000e-03\n",
      "It: 10, Loss: 2.151e+01, Y0: -4.561, Time: 4.70, Learning Rate: 1.000e-03\n",
      "It: 20, Loss: 3.540e+00, Y0: 0.445, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 30, Loss: 2.274e+00, Y0: 2.937, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 40, Loss: 1.255e+00, Y0: 2.288, Time: 4.76, Learning Rate: 1.000e-03\n",
      "It: 50, Loss: 7.254e-01, Y0: 2.064, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 60, Loss: 5.757e-01, Y0: 1.588, Time: 4.64, Learning Rate: 1.000e-03\n",
      "It: 70, Loss: 4.955e-01, Y0: 1.766, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 80, Loss: 4.269e-01, Y0: 1.781, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 90, Loss: 3.541e-01, Y0: 1.799, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 100, Loss: 3.084e-01, Y0: 1.577, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 110, Loss: 3.469e-01, Y0: 1.349, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 120, Loss: 5.005e-01, Y0: 1.278, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 130, Loss: 2.931e-01, Y0: 1.395, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 140, Loss: 2.814e-01, Y0: 1.320, Time: 4.67, Learning Rate: 1.000e-03\n",
      "It: 150, Loss: 4.377e-01, Y0: 1.118, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 160, Loss: 2.798e-01, Y0: 0.947, Time: 4.70, Learning Rate: 1.000e-03\n",
      "It: 170, Loss: 2.662e-01, Y0: 0.985, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 180, Loss: 2.487e-01, Y0: 0.959, Time: 4.37, Learning Rate: 1.000e-03\n",
      "It: 190, Loss: 2.562e-01, Y0: 0.885, Time: 4.78, Learning Rate: 1.000e-03\n",
      "It: 200, Loss: 2.170e-01, Y0: 0.823, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 210, Loss: 2.516e-01, Y0: 0.735, Time: 4.56, Learning Rate: 1.000e-03\n",
      "It: 220, Loss: 2.610e-01, Y0: 0.645, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 230, Loss: 2.838e-01, Y0: 0.596, Time: 4.40, Learning Rate: 1.000e-03\n",
      "It: 240, Loss: 2.285e-01, Y0: 0.738, Time: 4.64, Learning Rate: 1.000e-03\n",
      "It: 250, Loss: 1.989e-01, Y0: 1.117, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 260, Loss: 2.076e-01, Y0: 1.128, Time: 4.43, Learning Rate: 1.000e-03\n",
      "It: 270, Loss: 1.943e-01, Y0: 0.814, Time: 4.53, Learning Rate: 1.000e-03\n",
      "It: 280, Loss: 1.645e-01, Y0: 0.585, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 290, Loss: 1.509e-01, Y0: 0.513, Time: 4.70, Learning Rate: 1.000e-03\n",
      "It: 300, Loss: 1.784e-01, Y0: 0.411, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 310, Loss: 1.376e-01, Y0: 0.390, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 320, Loss: 1.769e-01, Y0: 0.352, Time: 4.65, Learning Rate: 1.000e-03\n",
      "It: 330, Loss: 1.364e-01, Y0: 0.255, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 340, Loss: 1.338e-01, Y0: 0.246, Time: 4.63, Learning Rate: 1.000e-03\n",
      "It: 350, Loss: 2.051e-01, Y0: 0.246, Time: 4.33, Learning Rate: 1.000e-03\n",
      "It: 360, Loss: 1.702e-01, Y0: 0.217, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 370, Loss: 1.360e-01, Y0: 0.277, Time: 4.71, Learning Rate: 1.000e-03\n",
      "It: 380, Loss: 1.213e-01, Y0: 0.260, Time: 4.35, Learning Rate: 1.000e-03\n",
      "It: 390, Loss: 1.120e-01, Y0: 0.168, Time: 4.68, Learning Rate: 1.000e-03\n",
      "It: 400, Loss: 1.280e-01, Y0: 0.104, Time: 4.38, Learning Rate: 1.000e-03\n",
      "It: 410, Loss: 1.334e-01, Y0: 0.004, Time: 4.30, Learning Rate: 1.000e-03\n",
      "It: 420, Loss: 9.603e-02, Y0: -0.023, Time: 4.69, Learning Rate: 1.000e-03\n",
      "It: 430, Loss: 1.188e-01, Y0: -0.002, Time: 4.32, Learning Rate: 1.000e-03\n",
      "It: 440, Loss: 1.119e-01, Y0: 0.020, Time: 4.65, Learning Rate: 1.000e-03\n",
      "It: 450, Loss: 1.270e-01, Y0: 0.003, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 460, Loss: 1.072e-01, Y0: -0.035, Time: 4.30, Learning Rate: 1.000e-03\n",
      "It: 470, Loss: 9.858e-02, Y0: -0.080, Time: 4.72, Learning Rate: 1.000e-03\n",
      "It: 480, Loss: 1.119e-01, Y0: -0.109, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 490, Loss: 1.080e-01, Y0: -0.080, Time: 4.61, Learning Rate: 1.000e-03\n",
      "It: 500, Loss: 1.154e-01, Y0: -0.049, Time: 4.46, Learning Rate: 1.000e-03\n",
      "It: 510, Loss: 8.937e-02, Y0: -0.089, Time: 4.36, Learning Rate: 1.000e-03\n",
      "It: 520, Loss: 1.497e-01, Y0: -0.070, Time: 4.68, Learning Rate: 1.000e-03\n",
      "It: 530, Loss: 1.199e-01, Y0: 0.015, Time: 4.34, Learning Rate: 1.000e-03\n",
      "It: 540, Loss: 9.921e-02, Y0: -0.012, Time: 4.55, Learning Rate: 1.000e-03\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://8080-gpu-t4-s-1pq8hye3u5pz9-a.us-west4-2.prod.colab.dev/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    M = 1024\n",
    "    N = 200\n",
    "    D = 4\n",
    "    T = 1.0\n",
    "\n",
    "    params = {\n",
    "        'mu': np.float32(1.0),\n",
    "        'c': np.float32(1.0),\n",
    "        'b': np.float32(1.0),\n",
    "        'a': np.float32(1.0),\n",
    "        's1': np.float32(0.5),\n",
    "        's2': np.float32(0.5),\n",
    "        's3': np.float32(0.5),\n",
    "        # Soft-init: partenza disaccoppiata\n",
    "        'const': np.float32(0.0),\n",
    "    }\n",
    "\n",
    "    Xi = np.array([1.5, 0.5, 0.5, 0.5]).reshape(1, D)\n",
    "\n",
    "    layers = [D+1] + 4*[256] + [1]\n",
    "\n",
    "    model = NN(Xi, T, M, N, D, layers, params)\n",
    "\n",
    "    # Curriculum sull'accoppiamento: const cresce gradualmente fino a 1.0\n",
    "    coupling_step = 0.2\n",
    "    coupling_levels = np.arange(0.0, 1.0 + coupling_step, coupling_step, dtype=np.float32)\n",
    "\n",
    "    stage_plan = [\n",
    "        (800, 1e-3),\n",
    "        (1200, 5e-4),\n",
    "        (1200, 1e-4),\n",
    "    ]\n",
    "    stage_logs = []\n",
    "\n",
    "    for level in coupling_levels:\n",
    "        model.const = np.float32(level)\n",
    "        print(f\"=== Coupling stage: const={float(level):.1f} ===\")\n",
    "        for n_iter, lr in stage_plan:\n",
    "            t0 = time.time()\n",
    "            train_stats = model.train(N_Iter=n_iter, learning_rate=lr, const_value=level)\n",
    "            eval_stats = model.evaluate(const_value=level, n_batches=5)\n",
    "            elapsed = time.time() - t0\n",
    "            log_row = {\n",
    "                'phase': 'curriculum',\n",
    "                'const': float(level),\n",
    "                'lr': float(lr),\n",
    "                'n_iter': int(n_iter),\n",
    "                'train_last_loss': train_stats['last_loss'],\n",
    "                'train_last_y0': train_stats['last_y0'],\n",
    "                'eval_mean_loss': eval_stats['mean_loss'],\n",
    "                'eval_std_loss': eval_stats['std_loss'],\n",
    "                'eval_mean_y0': eval_stats['mean_y0'],\n",
    "                'eval_std_y0': eval_stats['std_y0'],\n",
    "                'elapsed_sec': float(elapsed),\n",
    "            }\n",
    "            stage_logs.append(log_row)\n",
    "            print(\n",
    "                f\"[StageSummary] const={level:.1f}, lr={lr:.1e}, iters={n_iter}, \"\n",
    "                f\"eval_loss={eval_stats['mean_loss']:.3e}±{eval_stats['std_loss']:.2e}, \"\n",
    "                f\"eval_Y0={eval_stats['mean_y0']:.3f}±{eval_stats['std_y0']:.3f}, \"\n",
    "                f\"time={elapsed:.1f}s\"\n",
    "            )\n",
    "\n",
    "    # Fine-tuning finale fully coupled\n",
    "    model.const = np.float32(1.0)\n",
    "    print(\"=== Final fine-tuning at const=1.0 ===\")\n",
    "    for n_iter, lr in [(2000, 1e-5), (1500, 1e-6)]:\n",
    "        t0 = time.time()\n",
    "        train_stats = model.train(N_Iter=n_iter, learning_rate=lr, const_value=1.0)\n",
    "        eval_stats = model.evaluate(const_value=1.0, n_batches=5)\n",
    "        elapsed = time.time() - t0\n",
    "        log_row = {\n",
    "            'phase': 'final_finetune',\n",
    "            'const': 1.0,\n",
    "            'lr': float(lr),\n",
    "            'n_iter': int(n_iter),\n",
    "            'train_last_loss': train_stats['last_loss'],\n",
    "            'train_last_y0': train_stats['last_y0'],\n",
    "            'eval_mean_loss': eval_stats['mean_loss'],\n",
    "            'eval_std_loss': eval_stats['std_loss'],\n",
    "            'eval_mean_y0': eval_stats['mean_y0'],\n",
    "            'eval_std_y0': eval_stats['std_y0'],\n",
    "            'elapsed_sec': float(elapsed),\n",
    "        }\n",
    "        stage_logs.append(log_row)\n",
    "        print(\n",
    "            f\"[FinalSummary] const=1.0, lr={lr:.1e}, iters={n_iter}, \"\n",
    "            f\"eval_loss={eval_stats['mean_loss']:.3e}±{eval_stats['std_loss']:.2e}, \"\n",
    "            f\"eval_Y0={eval_stats['mean_y0']:.3f}±{eval_stats['std_y0']:.3f}, \"\n",
    "            f\"time={elapsed:.1f}s\"\n",
    "        )\n",
    "\n",
    "    print(\"=== Curriculum Log (compact) ===\")\n",
    "    for row in stage_logs:\n",
    "        print(\n",
    "            f\"phase={row['phase']}, const={row['const']:.1f}, lr={row['lr']:.1e}, iters={row['n_iter']}, \"\n",
    "            f\"eval_loss={row['eval_mean_loss']:.3e}, eval_y0={row['eval_mean_y0']:.3f}\"\n",
    "        )\n",
    "\n",
    "    # --- PLOTTING ---\n",
    "    t_test, W_test = model.fetch_minibatch()\n",
    "    X_pred, Y_pred, Z_pred = model.predict(Xi, t_test, W_test)\n",
    "\n",
    "    def u_exact(t, Xi_arr):\n",
    "        S = Xi_arr[:, 0:1]\n",
    "        H = Xi_arr[:, 1:2]\n",
    "        V = Xi_arr[:, 2:3]\n",
    "        X_state = Xi_arr[:, 3:4]\n",
    "        return np.exp(-t) * (np.exp(S) + np.exp(S)*H + V**2 + X_state*V)\n",
    "\n",
    "    def z_exact(t, Xi_arr):\n",
    "        S = Xi_arr[:, 0:1]\n",
    "        H = Xi_arr[:, 1:2]\n",
    "        V = Xi_arr[:, 2:3]\n",
    "        X_state = Xi_arr[:, 3:4]\n",
    "\n",
    "        s1 = params['s1']\n",
    "        s2 = params['s2']\n",
    "        s3 = params['s3']\n",
    "\n",
    "        common = np.exp(-t)\n",
    "        z_s = common * np.exp(S) * (1.0 + H) * s1\n",
    "        z_h = common * np.exp(S) * s2\n",
    "        z_v = common * (2.0 * V + X_state) * s3\n",
    "        z_x = np.zeros_like(z_s)\n",
    "\n",
    "        return np.concatenate([z_s, z_h, z_v, z_x], axis=1)\n",
    "\n",
    "    Xi_reshaped = X_pred.reshape(-1, D)\n",
    "    t_reshaped = t_test.reshape(-1, 1)\n",
    "\n",
    "    Y_exact = u_exact(t_reshaped, Xi_reshaped).reshape(M, N+1, 1)\n",
    "    Z_exact = z_exact(t_reshaped, Xi_reshaped).reshape(M, N+1, D)\n",
    "\n",
    "    exact_Y0 = u_exact(np.array([[0.0]]), Xi)[0, 0]\n",
    "    print(f\"\\nPredicted Y0: {Y_pred[0,0,0]:.4f}\")\n",
    "    print(f\"Exact Y0:     {exact_Y0:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(t_test[0,:,0], Y_pred[0,:,0], 'b', label='Learned Y')\n",
    "    plt.plot(t_test[0,:,0], Y_exact[0,:,0], 'r--', label='Exact Y')\n",
    "    plt.plot(t_test[1:5,:,0].T, Y_pred[1:5,:,0].T, 'b')\n",
    "    plt.plot(t_test[1:5,:,0].T, Y_exact[1:5,:,0].T, 'r--')\n",
    "    plt.title(\"Soluzione Sistema Pienamente Accoppiato 4D\")\n",
    "    plt.xlabel(\"Tempo t\")\n",
    "    plt.ylabel(\"Y_t\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Errore relativo medio sui componenti di Z (stile log_z, ma corretto per ogni componente)\n",
    "    eps = 1e-8\n",
    "    rel_err_Z = np.abs((Z_pred - Z_exact) / (np.abs(Z_exact) + eps))\n",
    "    mean_rel_err_Z = np.mean(rel_err_Z, axis=0)  # (N+1, D)\n",
    "\n",
    "    labels = ['Z_S', 'Z_H', 'Z_V', 'Z_X']\n",
    "    colors = ['b', 'g', 'r', 'm']\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for d in range(D):\n",
    "        plt.plot(t_test[0,:,0], mean_rel_err_Z[:, d], colors[d], label=f'Mean Rel Error {labels[d]}')\n",
    "    plt.yscale('log')\n",
    "    plt.title('Errore relativo medio di Z (scala log)')\n",
    "    plt.xlabel('Tempo t')\n",
    "    plt.ylabel('Errore relativo medio')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
